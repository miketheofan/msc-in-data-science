{"cells":[{"cell_type":"markdown","metadata":{"id":"vfEpHS6hJr-B"},"source":["## Intro"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"2nlFTejCJrr7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745957344405,"user_tz":-180,"elapsed":8340,"user":{"displayName":"Marios Mantzaris","userId":"03416491895175165913"}},"outputId":"6897e88a-f84e-43ed-ff74-9c3a4a293da5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n","Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (3.1.0)\n","Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n","Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.13.0)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package reuters to /root/nltk_data...\n","[nltk_data]   Package reuters is already up-to-date!\n","[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Package brown is already up-to-date!\n","[nltk_data] Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]   Package gutenberg is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":8}],"source":["!pip install evaluate\n","!pip install jiwer\n","\n","import nltk\n","import re\n","import math\n","import random\n","import numpy as np\n","from nltk.corpus import reuters\n","from collections import defaultdict, Counter\n","from typing import List, Tuple, Set\n","from tqdm import tqdm\n","from nltk import sent_tokenize, word_tokenize\n","import heapq\n","import string\n","from nltk.tokenize import RegexpTokenizer\n","import evaluate\n","\n","\n","nltk.download('reuters')\n","nltk.download('brown')\n","nltk.download('gutenberg')\n","nltk.download('punkt')\n","nltk.download('punkt_tab')"]},{"cell_type":"markdown","metadata":{"id":"HnoQvXCdJwkx"},"source":["## Part 1"]},{"cell_type":"markdown","source":["We create a class that will contain all the methods necessary for training the model"],"metadata":{"id":"7AC0gqnIKY9u"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"d92pT_pLJyrZ","executionInfo":{"status":"ok","timestamp":1745957344499,"user_tz":-180,"elapsed":2,"user":{"displayName":"Marios Mantzaris","userId":"03416491895175165913"}}},"outputs":[],"source":["# PART 1: N-GRAM LANGUAGE MODEL IMPLEMENTATION\n","# ===========================================\n","\n","class NGramLanguageModel:\n","    def __init__(self, n: int, min_freq: int = 10, tokenizer: str = 'nltk'):\n","        \"\"\"\n","        Initialize an n-gram language model.\n","\n","        Args:\n","            n: The size of n-grams (2 for bigram, 3 for trigram)\n","            min_freq: Minimum frequency to include a word in vocabulary\n","        \"\"\"\n","        self.n = n\n","        self.min_freq = min_freq\n","        self.tokenizer = tokenizer\n","\n","        if tokenizer == 'regexp':\n","          self.regexp_tokenizer = RegexpTokenizer(pattern=r'\\w+|\\(|\\)|\\.|\\,')\n","\n","        # Main model components\n","        self.vocabulary = set()  # Words in the vocabulary\n","        self.word_counts = Counter()  # Counts of individual words\n","        self.ngram_counts = defaultdict(Counter)  # Counts of n-grams\n","        self.context_counts = defaultdict(int)  # Counts of (n-1)-grams (contexts)\n","\n","        # Model constants\n","        self.UNK = \"<UNK>\"  # Out-of-vocabulary token\n","        self.END = \"<end>\"  # End of sentence token\n","\n","        # Different start tokens for different n values\n","        if n == 2:\n","            self.START = [\"<start>\"]\n","        elif n == 3:\n","            self.START = [\"<start1>\", \"<start2>\"]\n","        else:\n","            self.START = [f\"<start{i}>\" for i in range(1, n)]\n","\n","        # Statistics\n","        self.total_sentences = 0\n","        self.total_tokens = 0\n","        self.vocabulary_size = 0\n","\n","    def custom_tokenize(self, text):\n","            \"\"\"\n","            Custom tokenizer using regex to find word tokens.\n","\n","            Args:\n","                text: Input text string\n","\n","            Returns:\n","                List of tokens\n","            \"\"\"\n","            return re.findall(r\"\\b\\w+\\b\", text.lower())\n","\n","    def preprocess_text(self, corpus: List[str]) -> List[List[str]]:\n","        \"\"\"\n","        Preprocess raw text into tokenized sentences.\n","\n","        Args:\n","            corpus: List of text passages (paragraphs, documents, etc.)\n","\n","        Returns:\n","            List of tokenized sentences\n","        \"\"\"\n","        tokenized_sentences = []\n","\n","        for text in corpus:\n","            # First split the text into sentences\n","            sentences = sent_tokenize(text)\n","\n","            for sentence in sentences:\n","                # Clean the sentence\n","                clean_sentence = sentence.lower().strip()\n","\n","                # Apply selected tokenizer\n","                if self.tokenizer == \"nltk\":\n","                    tokens = word_tokenize(clean_sentence)\n","                elif self.tokenizer == \"custom\":\n","                    tokens = self.custom_tokenize(clean_sentence)\n","                elif self.tokenizer == \"regexp\":\n","                    tokens = self.regexp_tokenizer.tokenize(clean_sentence)\n","                else:\n","                    raise ValueError(f\"Unknown tokenizer: {self.tokenizer}\")\n","\n","                # Only add non-empty sentences\n","                if tokens:\n","                    tokenized_sentences.append(tokens)\n","\n","        return tokenized_sentences\n","\n","    def build_vocabulary(self, tokenized_sentences: List[List[str]]) -> Set[str]:\n","        \"\"\"\n","        Build vocabulary from tokenized sentences based on minimum frequency.\n","\n","        Args:\n","            tokenized_sentences: List of tokenized sentences\n","\n","        Returns:\n","            Set of vocabulary words\n","        \"\"\"\n","        # Count word occurrences\n","        word_counter = Counter()\n","        for sentence in tokenized_sentences:\n","            word_counter.update(sentence)\n","\n","        # Create vocabulary with words that meet minimum frequency\n","        vocabulary = {word for word, count in word_counter.items()\n","                     if count >= self.min_freq}\n","\n","        # Always add special tokens to vocabulary\n","        vocabulary.add(self.UNK)\n","        vocabulary.add(self.END)\n","        for token in self.START:\n","            vocabulary.add(token)\n","\n","        return vocabulary\n","\n","    def replace_oov_words(self, tokenized_sentences: List[List[str]]) -> List[List[str]]:\n","        \"\"\"\n","        Replace out-of-vocabulary words with UNK token.\n","\n","        Args:\n","            tokenized_sentences: List of tokenized sentences\n","\n","        Returns:\n","            List of tokenized sentences with OOV words replaced\n","        \"\"\"\n","        processed_sentences = []\n","\n","        for sentence in tokenized_sentences:\n","            processed_sentence = []\n","            for token in sentence:\n","                if token in self.vocabulary:\n","                    processed_sentence.append(token)\n","                else:\n","                    processed_sentence.append(self.UNK)\n","            processed_sentences.append(processed_sentence)\n","\n","        return processed_sentences\n","\n","    def extract_ngrams(self, tokenized_sentences: List[List[str]]) -> None:\n","        \"\"\"\n","        Extract n-grams from tokenized sentences and count their occurrences.\n","\n","        Args:\n","            tokenized_sentences: List of tokenized sentences with OOV words replaced\n","        \"\"\"\n","        for sentence in tokenized_sentences:\n","            # Add start and end tokens\n","            augmented_sentence = self.START + sentence + [self.END]\n","            self.total_tokens += len(sentence) + 1  # +1 for END token\n","\n","            # Count individual words (unigrams)\n","            self.word_counts.update(augmented_sentence)\n","\n","            # Extract and count n-grams\n","            for i in range(len(augmented_sentence) - self.n + 1):\n","                ngram = tuple(augmented_sentence[i:i + self.n])\n","                prefix = ngram[:-1]  # Context (n-1 gram)\n","                word = ngram[-1]     # Word being predicted\n","\n","                self.ngram_counts[prefix][word] += 1\n","                self.context_counts[prefix] += 1\n","\n","    def train(self, corpus: List[str]) -> None:\n","        \"\"\"\n","        Train the n-gram language model on the provided corpus.\n","\n","        Args:\n","            corpus: List of text passages that may contain multiple sentences\n","        \"\"\"\n","        print(f\"Training {self.n}-gram model on corpus...\")\n","\n","        # Preprocess corpus\n","        tokenized_sentences = self.preprocess_text(corpus)\n","        self.total_sentences = len(tokenized_sentences)\n","        print(f\"Extracted {self.total_sentences} sentences from corpus\")\n","\n","        # Build vocabulary\n","        self.vocabulary = self.build_vocabulary(tokenized_sentences)\n","        self.vocabulary_size = len(self.vocabulary)\n","        print(f\"Vocabulary size: {self.vocabulary_size} words\")\n","\n","        # Replace OOV words\n","        processed_sentences = self.replace_oov_words(tokenized_sentences)\n","\n","        # Extract n-grams\n","        self.extract_ngrams(processed_sentences)\n","\n","        print(f\"Extracted {sum(len(counts) for counts in self.ngram_counts.values())} unique {self.n}-grams\")\n","        print(f\"Total tokens in corpus: {self.total_tokens}\")\n","\n","    def get_laplace_probability(self, word: str, context: tuple, alpha: float = 0.01) -> float:\n","        \"\"\"\n","        Calculate Laplace-smoothed probability P(word|context).\n","\n","        Args:\n","            word: The word to calculate probability for\n","            context: The preceding (n-1) words\n","\n","        Returns:\n","            The conditional probability P(word|context)\n","        \"\"\"\n","        count_ngram = self.ngram_counts[context][word]\n","        count_context = self.context_counts[context]\n","\n","        # Apply Laplace smoothing\n","        probability = (count_ngram + alpha) / (count_context + alpha * self.vocabulary_size)\n","\n","        return probability\n","\n","    def get_log_probability(self, word: str, context: tuple) -> float:\n","      \"\"\"\n","      Calculate log probability log(P(word|context)).\n","\n","      Args:\n","          word: The word to calculate probability for\n","          context: The preceding (n-1) words\n","\n","      Returns:\n","          The log probability log(P(word|context))\n","      \"\"\"\n","      probability = self.get_laplace_probability(word, context)\n","      return math.log2(probability)\n","\n","    def get_sentence_log_probability(self, sentence: List[str]) -> float:\n","        \"\"\"\n","        Calculate the log probability of a sentence.\n","\n","        Args:\n","            sentence: List of tokens in the sentence\n","\n","        Returns:\n","            The log probability of the sentence\n","        \"\"\"\n","        # Replace OOV words with UNK\n","        processed_sentence = [token if token in self.vocabulary else self.UNK for token in sentence]\n","\n","        # Add start and end tokens\n","        augmented_sentence = self.START + processed_sentence + [self.END]\n","\n","        log_prob = 0.0\n","\n","        # Calculate log probability for each word given its context\n","        for i in range(len(self.START), len(augmented_sentence)):\n","            word = augmented_sentence[i]\n","            context = tuple(augmented_sentence[i - self.n + 1:i])\n","\n","            log_prob += self.get_log_probability(word, context)\n","\n","        return log_prob"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"FuuTEY2kJjgw","executionInfo":{"status":"ok","timestamp":1745957344501,"user_tz":-180,"elapsed":1,"user":{"displayName":"Marios Mantzaris","userId":"03416491895175165913"}}},"outputs":[],"source":["def load_and_split_corpus(corpus_name='reuters', min_sentences=100000):\n","    \"\"\"\n","    Load and split a corpus from NLTK into train, validation, and test sets.\n","\n","    Args:\n","        corpus_name: Name of the corpus to load\n","        min_sentences: Minimum number of sentences to include\n","\n","    Returns:\n","        Tuple of (train_corpus, val_corpus, test_corpus)\n","    \"\"\"\n","    print(f\"Loading {corpus_name} corpus...\")\n","\n","    if corpus_name == 'reuters':\n","        from nltk.corpus import reuters\n","        sentences = [\" \".join(reuters.words(fileid)) for fileid in reuters.fileids()]\n","\n","        # Break into actual sentences\n","        all_sentences = []\n","        for text in sentences:\n","            all_sentences.extend(nltk.sent_tokenize(text))\n","\n","    elif corpus_name == 'brown':\n","        from nltk.corpus import brown\n","        sentences = [\" \".join(brown.words(fileid)) for fileid in brown.fileids()]\n","\n","        # Break into actual sentences\n","        all_sentences = []\n","        for text in sentences:\n","            all_sentences.extend(nltk.sent_tokenize(text))\n","\n","    else:\n","        raise ValueError(f\"Unknown corpus: {corpus_name}\")\n","\n","    # Ensure we have enough sentences\n","    if len(all_sentences) < min_sentences:\n","        raise ValueError(f\"Corpus {corpus_name} has only {len(all_sentences)} sentences, \"\n","                         f\"which is less than the required {min_sentences}.\")\n","\n","    # Shuffle sentences\n","    random.seed(42)\n","    random.shuffle(all_sentences)\n","\n","    # Take a subset for faster processing if needed\n","    sentences_subset = all_sentences[:min_sentences]\n","\n","    # Split into train, validation, and test sets (70%, 15%, 15%)\n","    train_size = int(0.7 * len(sentences_subset))\n","    val_size = int(0.15 * len(sentences_subset))\n","\n","    train_corpus = sentences_subset[:train_size]\n","    val_corpus = sentences_subset[train_size:train_size + val_size]\n","    test_corpus = sentences_subset[train_size + val_size:]\n","\n","    print(f\"Corpus split: {len(train_corpus)} train, {len(val_corpus)} validation, {len(test_corpus)} test sentences\")\n","\n","    return train_corpus, val_corpus, test_corpus"]},{"cell_type":"markdown","metadata":{"id":"r6tEY9p9J2Vr"},"source":["## Part 2"]},{"cell_type":"markdown","source":["Methods that will be used for calculating the cross entropy and perplexity"],"metadata":{"id":"8-Er45jtKm_1"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"8ZGOfJ8XJ386","executionInfo":{"status":"ok","timestamp":1745957344502,"user_tz":-180,"elapsed":1,"user":{"displayName":"Marios Mantzaris","userId":"03416491895175165913"}}},"outputs":[],"source":["# PART 2: CROSS-ENTROPY AND PERPLEXITY EVALUATION\n","# ==============================================\n","def calculate_cross_entropy(model: NGramLanguageModel, test_corpus: List[str]) -> Tuple[float, float]:\n","    \"\"\"\n","    Calculate cross-entropy of a language model on a test corpus.\n","\n","    Args:\n","        model: Trained language model\n","        test_corpus: List of test sentences\n","\n","    Returns:\n","        Cross-entropy value\n","    \"\"\"\n","    # Preprocess and handle OOV words\n","    tokenized_sentences = model.preprocess_text(test_corpus)\n","    processed_sentences = model.replace_oov_words(tokenized_sentences)\n","\n","    total_log_prob = 0.0\n","    total_words = 0  # N in cross-entropy formula (include <end> tokens, exclude <start> tokens)\n","\n","    for sentence in processed_sentences:\n","        # Add start and end tokens\n","        augmented_sentence = model.START + sentence + [model.END]\n","\n","        for i in range(len(model.START), len(augmented_sentence)):\n","            word = augmented_sentence[i]\n","            context = tuple(augmented_sentence[i - model.n + 1:i])\n","\n","            # Get log probability\n","            log_prob = model.get_log_probability(word, context)\n","\n","            total_log_prob += log_prob\n","            total_words += 1\n","\n","    cross_entropy = - (total_log_prob) / total_words\n","\n","    return cross_entropy"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"U9XFeldBJ4DD","executionInfo":{"status":"ok","timestamp":1745957344599,"user_tz":-180,"elapsed":96,"user":{"displayName":"Marios Mantzaris","userId":"03416491895175165913"}}},"outputs":[],"source":["def calculate_perplexity(cross_entropy: float) -> float:\n","    \"\"\"\n","    Calculate perplexity from cross-entropy.\n","\n","    Args:\n","        cross_entropy: Cross-entropy value\n","\n","    Returns:\n","        Perplexity value\n","    \"\"\"\n","    return 2 ** cross_entropy"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"3NMy-rcBJjgx","outputId":"85ad91b3-9f7f-4516-cdba-c05bec25429d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745957401120,"user_tz":-180,"elapsed":54166,"user":{"displayName":"Marios Mantzaris","userId":"03416491895175165913"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading brown corpus...\n","Corpus split: 35000 train, 7500 validation, 7500 test sentences\n","Training 2-gram model on corpus...\n","Extracted 35000 sentences from corpus\n","Vocabulary size: 6091 words\n","Extracted 186764 unique 2-grams\n","Total tokens in corpus: 760914\n","Training 3-gram model on corpus...\n","Extracted 35000 sentences from corpus\n","Vocabulary size: 6092 words\n","Extracted 459477 unique 3-grams\n","Total tokens in corpus: 760914\n","Common vocabulary size: 6090\n","\n","Evaluating on validation set...\n","Bigram model - Cross-entropy: 7.3274, Perplexity: 160.6073\n","Trigram model - Cross-entropy: 9.2053, Perplexity: 590.3171\n","\n","Evaluating on test set...\n","Bigram model - Cross-entropy: 7.3027, Perplexity: 157.8820\n","Trigram model - Cross-entropy: 9.1658, Perplexity: 574.3561\n"]}],"source":["# Part 1\n","# Load and split corpus\n","train_corpus, val_corpus, test_corpus = load_and_split_corpus(corpus_name='brown', min_sentences=50000)\n","\n","# Initialize and train models\n","bigram_model = NGramLanguageModel(n=2, min_freq=10, tokenizer='nltk')\n","bigram_model.train(train_corpus)\n","\n","trigram_model = NGramLanguageModel(n=3, min_freq=10, tokenizer='nltk')\n","trigram_model.train(train_corpus)\n","\n","# Ensure both models use the same vocabulary\n","common_vocab = bigram_model.vocabulary.intersection(trigram_model.vocabulary)\n","bigram_model.vocabulary = common_vocab\n","trigram_model.vocabulary = common_vocab\n","bigram_model.vocabulary_size = len(common_vocab)\n","trigram_model.vocabulary_size = len(common_vocab)\n","\n","print(f\"Common vocabulary size: {len(common_vocab)}\")\n","\n","# Part 2\n","# Calculate cross-entropy and perplexity on validation set\n","print(\"\\nEvaluating on validation set...\")\n","\n","bigram_ce_val = calculate_cross_entropy(bigram_model, val_corpus)\n","bigram_ppl_val = calculate_perplexity(bigram_ce_val)\n","\n","trigram_ce_val = calculate_cross_entropy(trigram_model, val_corpus)\n","trigram_ppl_val = calculate_perplexity(trigram_ce_val)\n","\n","print(f\"Bigram model - Cross-entropy: {bigram_ce_val:.4f}, Perplexity: {bigram_ppl_val:.4f}\")\n","print(f\"Trigram model - Cross-entropy: {trigram_ce_val:.4f}, Perplexity: {trigram_ppl_val:.4f}\")\n","\n","# Calculate cross-entropy and perplexity on test set\n","print(\"\\nEvaluating on test set...\")\n","\n","bigram_ce_test = calculate_cross_entropy(bigram_model, test_corpus)\n","bigram_ppl_test = calculate_perplexity(bigram_ce_test)\n","\n","trigram_ce_test = calculate_cross_entropy(trigram_model, test_corpus)\n","trigram_ppl_test = calculate_perplexity(trigram_ce_test)\n","\n","print(f\"Bigram model - Cross-entropy: {bigram_ce_test:.4f}, Perplexity: {bigram_ppl_test:.4f}\")\n","print(f\"Trigram model - Cross-entropy: {trigram_ce_test:.4f}, Perplexity: {trigram_ppl_test:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"ZjjrSzAMJ7Ej"},"source":["## Part 3"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"T_XE7epLJ4H0","executionInfo":{"status":"ok","timestamp":1745957451175,"user_tz":-180,"elapsed":51,"user":{"displayName":"Marios Mantzaris","userId":"03416491895175165913"}}},"outputs":[],"source":["def get_next_word_greedy(model: NGramLanguageModel, context: tuple) -> str:\n","    \"\"\"\n","    Get the most probable next word given the context.\n","\n","    Args:\n","        model: Trained language model\n","        context: Current context ((n-1) preceding words)\n","\n","    Returns:\n","        Most probable next word\n","    \"\"\"\n","    # Get probabilities for all words in the vocabulary\n","    candidates = {}\n","\n","    for word in model.vocabulary:\n","        # Skip UNK token for generation\n","        if word == model.UNK:\n","            continue\n","\n","        prob = model.get_laplace_probability(word, context)\n","        candidates[word] = prob\n","\n","    # Return the word with the highest probability\n","    return max(candidates.items(), key=lambda x: x[1])[0]"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"GPNhm9RaJ-8S","executionInfo":{"status":"ok","timestamp":1745957451995,"user_tz":-180,"elapsed":4,"user":{"displayName":"Marios Mantzaris","userId":"03416491895175165913"}}},"outputs":[],"source":["def get_next_word_topk(model: NGramLanguageModel,\n","                      context: tuple,\n","                      k: int = 5,\n","                      temperature: float = 1.0) -> str:\n","    \"\"\"\n","    Sample next word from top-k most probable words.\n","\n","    Args:\n","        model: Trained language model\n","        context: Current context ((n-1) preceding words)\n","        k: Number of top candidates to consider\n","        temperature: Controls randomness (higher = more random)\n","\n","    Returns:\n","        Sampled next word\n","    \"\"\"\n","    # Get probabilities for all words in the vocabulary\n","    candidates = {}\n","\n","    for word in model.vocabulary:\n","        # Skip UNK token for generation\n","        if word == model.UNK:\n","            continue\n","\n","        prob = model.get_laplace_probability(word, context)\n","        candidates[word] = prob\n","\n","    # Get top-k candidates\n","    top_candidates = sorted(candidates.items(), key=lambda x: x[1], reverse=True)[:k]\n","\n","    # Apply temperature scaling\n","    if temperature != 1.0:\n","        probs = np.array([prob for _, prob in top_candidates])\n","        probs = np.power(probs, 1.0 / temperature)\n","        probs = probs / np.sum(probs)\n","    else:\n","        probs = np.array([prob for _, prob in top_candidates])\n","        probs = probs / np.sum(probs)\n","\n","    # Sample from the distribution\n","    words = [word for word, _ in top_candidates]\n","    next_word = np.random.choice(words, p=probs)\n","\n","    return next_word"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"s2cTq7csKA2b","executionInfo":{"status":"ok","timestamp":1745957453136,"user_tz":-180,"elapsed":1,"user":{"displayName":"Marios Mantzaris","userId":"03416491895175165913"}}},"outputs":[],"source":["def beam_search(model: NGramLanguageModel,\n","               prompt: List[str],\n","               beam_width: int = 5,\n","               max_length: int = 20) -> List[List[str]]:\n","    \"\"\"\n","    Beam search for text generation.\n","\n","    Args:\n","        model: Trained language model\n","        prompt: Initial words to continue from\n","        beam_width: Beam width\n","        max_length: Maximum length of the generated sequence\n","\n","    Returns:\n","        List of generated sequences (beams)\n","    \"\"\"\n","    # Process the prompt\n","    processed_prompt = [word if word in model.vocabulary else model.UNK for word in prompt]\n","\n","    # Initialize beams with start tokens + prompt\n","    initial_sequence = model.START + processed_prompt\n","    beams = [(initial_sequence, 0.0)]  # (sequence, log_prob)\n","\n","    # Generate for max_length steps\n","    for _ in range(max_length):\n","        new_beams = []\n","\n","        # Expand each beam\n","        for sequence, score in beams:\n","            # If the sequence ended, keep it as is\n","            if sequence[-1] == model.END:\n","                new_beams.append((sequence, score))\n","                continue\n","\n","            # Get context\n","            context = tuple(sequence[-(model.n - 1):])\n","\n","            # Calculate probabilities for all possible next words\n","            candidates = {}\n","            for word in model.vocabulary:\n","                # Skip UNK token for generation\n","                if word == model.UNK:\n","                    continue\n","\n","                log_prob = model.get_log_probability(word, context)\n","                candidates[word] = log_prob\n","\n","            # Get top candidates\n","            top_candidates = sorted(candidates.items(), key=lambda x: x[1], reverse=True)[:beam_width]\n","\n","            # Create new beams with expanded sequences\n","            for word, log_prob in top_candidates:\n","                new_sequence = sequence + [word]\n","                new_score = score + log_prob\n","                new_beams.append((new_sequence, new_score))\n","\n","        # Select top beams\n","        beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_width]\n","\n","        # Check if all beams have ended\n","        if all(sequence[-1] == model.END for sequence, _ in beams):\n","            break\n","\n","    # Return only the newly generated parts (excluding start tokens and prompt)\n","    start_len = len(model.START) + len(processed_prompt)\n","    return [sequence[start_len:] for sequence, _ in beams]"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"S_iamUVrJ4Fh","executionInfo":{"status":"ok","timestamp":1745957455985,"user_tz":-180,"elapsed":12,"user":{"displayName":"Marios Mantzaris","userId":"03416491895175165913"}}},"outputs":[],"source":["def generate_text(model: NGramLanguageModel,\n","                 prompt: List[str],\n","                 max_length: int = 20,\n","                 method: str = \"greedy\",\n","                 top_k: int = 5,\n","                 temperature: float = 1.0) -> List[str]:\n","    \"\"\"\n","    Generate text continuation based on the prompt.\n","\n","    Args:\n","        model: Trained language model\n","        prompt: Initial words to continue from\n","        max_length: Maximum length of the generated sequence\n","        method: Generation method - \"greedy\", \"topk\", or \"nucleus\"\n","        top_k: Number of top candidates to consider for sampling\n","        temperature: Controls randomness (higher = more random)\n","\n","    Returns:\n","        List of words completing the prompt\n","    \"\"\"\n","    # Process the prompt\n","    processed_prompt = [word if word in model.vocabulary else model.UNK for word in prompt]\n","\n","    # Initialize with start tokens + prompt\n","    generated_text = model.START + processed_prompt\n","\n","    # Generate text until we reach max_length or end token\n","    for _ in range(max_length):\n","        # Get the most recent (n-1) words as context\n","        context = tuple(generated_text[-(model.n - 1):])\n","\n","        # Get next word based on the specified method\n","        if method == \"greedy\":\n","            next_word = get_next_word_greedy(model, context)\n","        elif method == \"topk\":\n","            next_word = get_next_word_topk(model, context, top_k, temperature)\n","        else:\n","            raise ValueError(f\"Unknown generation method: {method}\")\n","\n","        # Add the generated word to the sequence\n","        generated_text.append(next_word)\n","\n","        # Stop if we generated the end token\n","        if next_word == model.END:\n","            break\n","\n","    # Return only the newly generated part (excluding start tokens and prompt)\n","    return generated_text[len(model.START) + len(processed_prompt):]"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"IHbghVQsJjgz","outputId":"bf8de661-4a4d-4652-ad96-7a7c6ac7c50d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745957485418,"user_tz":-180,"elapsed":4355,"user":{"displayName":"Marios Mantzaris","userId":"03416491895175165913"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Generating text completions:\n","\n","Bigram model completions:\n","[Greedy] I would like to commend the same time , and the same time , and the same time , and the same time , and the\n","[Top-K] I would like to commend the other side in the first , and i had a little more than a good .\n","[Beam] I would like to commend the `` .\n","\n","[Greedy] The president of the same time , and the same time , and the same time , and the same time , and\n","[Top-K] The president of the other , the first time of the first two years ago .\n","[Beam] The president of the `` .\n","\n","[Greedy] According to recent years , and the same time , and the same time , and the same time , and the same\n","[Top-K] According to recent history .\n","[Beam] According to recent years .\n","\n","[Greedy] In the last few days , and the same time , and the same time , and the same time , and the same\n","[Top-K] In the last few days in the most of the first time .\n","[Beam] In the last few days .\n","\n","[Greedy] Experts say that the same time , and the same time , and the same time , and the same time , and\n","[Top-K] Experts say that he could see the same way to a few minutes , the other than the `` , the first .\n","[Beam] Experts say that he had been a few days .\n","\n","\n","Trigram model completions:\n","[Greedy] I would like to commend the world .\n","[Top-K] I would like to commend the united states of america in the world of the most part , come on , his wife , mrs. robert\n","[Beam] I would like to commend the world .\n","\n","[Greedy] The president of the united states , and the other hand , the `` public `` leaves the hospital and the other hand\n","[Top-K] The president of the united states , and the other .\n","[Beam] The president of the united states .\n","\n","[Greedy] According to recent determining determining determining determining determining determining determining determining determining determining determining determining determining determining determining determining determining determining determining determining\n","[Top-K] According to recent twentieth determining twentieth twentieth savage determining determining savage assembled determining assembled feasible assembled twentieth feasible twentieth feasible twentieth determining assembled\n","[Beam] According to recent determining determining determining determining determining determining determining determining determining determining determining determining determining determining determining determining determining determining determining determining\n","\n","[Greedy] In the last few days , and the other hand , the `` public `` leaves the hospital and the other hand , the\n","[Top-K] In the last few centuries ago .\n","[Beam] In the last few years .\n","\n","[Greedy] Experts say that the united states , and the other hand , the `` public `` leaves the hospital and the other hand\n","[Top-K] Experts say that this is not to be a very good , firm determining twentieth twentieth determining determining twentieth savage determining feasible feasible\n","[Beam] Experts say that it is not the only one of the united states .\n","\n"]}],"source":["# Part 3\n","# Generate text completions\n","print(\"\\nGenerating text completions:\")\n","\n","prompts = [\n","\"I would like to commend the\",\n","\"The president of\",\n","\"According to recent\",\n","\"In the last few\",\n","\"Experts say that\"\n","]\n","\n","print(\"\\nBigram model completions:\")\n","for prompt in prompts:\n","  if bigram_model.tokenizer == \"nltk\":\n","    prompt_tokens = nltk.word_tokenize(prompt.lower())\n","  elif bigram_model.tokenizer == \"custom\":\n","    prompt_tokens = bigram_model.custom_tokenize(prompt)\n","  elif bigram_model.tokenizer==\"regexp\":\n","    prompt_tokens = bigram_model.regexp_tokenizer.tokenize(prompt.lower())\n","\n","  # Generate with greedy decoding\n","  completion_greedy = generate_text(bigram_model, prompt_tokens, method=\"greedy\")\n","  completion_text_greedy = prompt + \" \" + \" \".join([w for w in completion_greedy if w != bigram_model.END])\n","  print(f\"[Greedy] {completion_text_greedy}\")\n","\n","  # Generate with top-k sampling\n","  completion_topk = generate_text(bigram_model, prompt_tokens, method=\"topk\", top_k=5, temperature=1.5)\n","  completion_text_topk = prompt + \" \" + \" \".join([w for w in completion_topk if w != bigram_model.END])\n","  print(f\"[Top-K] {completion_text_topk}\")\n","\n","  # Generate with beam search\n","  beam_completions = beam_search(bigram_model, prompt_tokens, beam_width=3)\n","  top_beam = beam_completions[0]\n","  completion_text_beam = prompt + \" \" + \" \".join([w for w in top_beam if w != bigram_model.END])\n","  print(f\"[Beam] {completion_text_beam}\")\n","  print()\n","\n","print(\"\\nTrigram model completions:\")\n","for prompt in prompts:\n","  if trigram_model.tokenizer == \"nltk\":\n","      prompt_tokens = nltk.word_tokenize(prompt.lower())\n","  elif trigram_model.tokenizer == \"custom\":\n","      prompt_tokens = bigram_model.custom_tokenize(prompt)\n","  elif trigram_model.tokenizer==\"regexp\":\n","    prompt_tokens = trigram_model.regexp_tokenizer.tokenize(prompt.lower())\n","\n","  # Generate with greedy decoding\n","  completion_greedy = generate_text(trigram_model, prompt_tokens, method=\"greedy\")\n","  completion_text_greedy = prompt + \" \" + \" \".join([w for w in completion_greedy if w != trigram_model.END])\n","  print(f\"[Greedy] {completion_text_greedy}\")\n","\n","  # Generate with top-k sampling\n","  completion_topk = generate_text(trigram_model, prompt_tokens, method=\"topk\", top_k=5, temperature=1.5)\n","  completion_text_topk = prompt + \" \" + \" \".join([w for w in completion_topk if w != trigram_model.END])\n","  print(f\"[Top-K] {completion_text_topk}\")\n","\n","  # Generate with beam search\n","  beam_completions = beam_search(trigram_model, prompt_tokens, beam_width=3)\n","  top_beam = beam_completions[0]\n","  completion_text_beam = prompt + \" \" + \" \".join([w for w in top_beam if w != trigram_model.END])\n","  print(f\"[Beam] {completion_text_beam}\")\n","  print()"]},{"cell_type":"markdown","metadata":{"id":"yKd5_0WaJjgz"},"source":["## Part 4"]},{"cell_type":"markdown","metadata":{"id":"mfmRey_lJjgz"},"source":["### _Context- Aware Spelling Correction using Beam Search_\n","\n","The goal is to implement a context-aware spelling corrector for noisy sentences.\n","The corrector should:\n","  * Use an **N-gram Language Model** to evaluate how natural candidate corrections are given the context.\n","  * Use an **error model** based on **edit distance** to penalize corrections that are far from the original noisy token.\n","  * Use **beam search** to explore multiple possible corrections at each step, keeping only the most promising sequences.\n","  * Implement an option to **proserve tokens already in the vocabulary** (`skip_oov=True`), without generating unecessary candidates.\n","  * Allow **verbose control**:\n","    - If `verbose=True`, log detailed steps per token (candidates, scores, best selections).\n","    - If `verbose=False`, do not show any logging, return only the corrected tokens."]},{"cell_type":"markdown","metadata":{"id":"FQc2TtZqJjg0"},"source":["We firstly initialize our Context Aware Spelling Corrector class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uNb-ma0bJjg0"},"outputs":[],"source":["class ContextAwareSpellingCorrector:\n","    \"\"\"\n","    A context-aware spelling corrector using beam search,\n","    organized as a class without instance variables.\n","    \"\"\"\n","\n","    def log_prob(self, p: float) -> float:\n","        \"\"\"\n","        Compute log-probability with safe handling for zero.\n","        \"\"\"\n","        return math.log(p) if p > 0 else float('-inf')\n","\n","    def calculate_lm_score(self, candidate: str, context: Tuple[str, ...], model) -> float:\n","        \"\"\"\n","        Get the language model log-probability of a candidate given context.\n","        \"\"\"\n","        return model.get_log_probability(candidate, context)\n","\n","    def calculate_error_score(self, noisy_token: str, candidate: str) -> float:\n","        \"\"\"\n","        Compute the log-probability of a candidate based on its edit distance.\n","        \"\"\"\n","        edit_dist = nltk.edit_distance(noisy_token, candidate)\n","        return self.log_prob(1 / (edit_dist + 1))\n","\n","    def combine_scores(self, lm_score: float, error_score: float, lambda_lm: float = 0.8, lambda_err: float = 0.2) -> float:\n","        \"\"\"\n","        Combine language model and error model scores using weighted sum.\n","        \"\"\"\n","        return lambda_lm * lm_score + lambda_err * error_score\n","\n","    def generate_candidates(\n","        self,\n","        noisy_token: str,\n","        vocabulary: Set[str],\n","        max_edit_distance: int = 2,\n","        skip_oov: bool = True\n","    ) -> List[str]:\n","        \"\"\"\n","        Generate candidate corrections within a max edit distance.\n","        \"\"\"\n","        if skip_oov and noisy_token in vocabulary:\n","            return [noisy_token]\n","\n","        candidates = []\n","        for word in vocabulary:\n","            if word == \"<UNK>\":\n","                continue\n","            if nltk.edit_distance(noisy_token, word) <= max_edit_distance:\n","                candidates.append(word)\n","\n","        return candidates or [noisy_token]\n","\n","    def beam_search_step(\n","        self,\n","        beams: List[Tuple[List[str], float]],\n","        noisy_token: str,\n","        model,\n","        vocabulary: Set[str],\n","        beam_width: int = 5,\n","        lambda_lm: float = 0.8,\n","        lambda_err: float = 0.2,\n","        max_edit_distance: int = 2,\n","        skip_oov: bool = True,\n","        verbose: bool = True\n","    ) -> List[Tuple[List[str], float]]:\n","        \"\"\"\n","        Expand beam sequences with possible corrections for the next token.\n","        \"\"\"\n","        new_beams = []\n","        candidate_info = []\n","\n","        for sequence, score in beams:\n","            context = tuple(sequence[-(model.n - 1):])\n","            candidates = self.generate_candidates(noisy_token, vocabulary, max_edit_distance, skip_oov)\n","\n","            for candidate in candidates:\n","                lm_score = self.calculate_lm_score(candidate, context, model)\n","                err_score = self.calculate_error_score(noisy_token, candidate)\n","                total_score = self.combine_scores(lm_score, err_score, lambda_lm, lambda_err)\n","\n","                candidate_info.append((candidate, lm_score, err_score, total_score))\n","\n","                new_sequence = sequence + [candidate]\n","                new_score = score + total_score\n","                new_beams.append((new_sequence, new_score))\n","\n","        if not new_beams:\n","            if verbose:\n","                print(f\"Warning: No valid candidates for '{noisy_token}'. Using fallback.\")\n","            for sequence, score in beams:\n","                new_sequence = sequence + [noisy_token]\n","                new_beams.append((new_sequence, score))\n","\n","        top_beams = heapq.nlargest(beam_width, new_beams, key=lambda x: x[1])\n","        top_tokens = [beam[0][-1] for beam in top_beams]\n","\n","        if verbose:\n","            print(f\"\\nToken: '{noisy_token}' | Context: {context}\")\n","            print(\"Top candidates:\")\n","            print(f\"{'Candidate':<15} {'LM Score':>10} {'Error Score':>12} {'Combined':>12}\")\n","            print(\"-\" * 55)\n","\n","            for token in top_tokens:\n","                for cand, lm, err, combined in candidate_info:\n","                    if cand == token:\n","                        print(f\"{cand:<15} {lm:>+10.4f} {err:>+12.4f} {combined:>+12.4f}\")\n","                        break\n","\n","            print(f\"Best candidate selected: {top_tokens[0]}\")\n","            print(\"-\" * 55)\n","\n","        return top_beams\n","\n","    def correct(\n","        self,\n","        model,\n","        noisy_sentence: List[str],\n","        beam_width: int = 5,\n","        lambda_lm: float = 0.8,\n","        lambda_err: float = 0.2,\n","        max_edit_distance: int = 2,\n","        skip_oov: bool = True,\n","        verbose: bool = True\n","    ) -> List[str]:\n","        \"\"\"\n","        Perform context-aware spelling correction on a noisy sentence using beam search.\n","        \"\"\"\n","        if verbose:\n","            print(f\"\\nStarting correction for sentence: {' '.join(noisy_sentence)}\\n\")\n","\n","        beams = [(model.START, 0.0)]\n","\n","        for noisy_token in noisy_sentence:\n","            if skip_oov and noisy_token in model.vocabulary:\n","                if verbose:\n","                    print(f\"\\nToken: '{noisy_token}' (in vocabulary, skipping correction)\")\n","                new_beams = []\n","                for sequence, score in beams:\n","                    new_sequence = sequence + [noisy_token]\n","                    new_beams.append((new_sequence, score))\n","                beams = new_beams\n","                continue\n","\n","            beams = self.beam_search_step(\n","                beams, noisy_token, model, model.vocabulary,\n","                beam_width, lambda_lm, lambda_err, max_edit_distance, skip_oov, verbose\n","            )\n","\n","        best_sequence = max(beams, key=lambda x: x[1])[0]\n","        corrected = best_sequence[len(model.START):]\n","\n","        if verbose:\n","            print(f\"\\nFinal corrected sentence: {' '.join(corrected)}\")\n","\n","        return corrected"]},{"cell_type":"markdown","metadata":{"id":"GGSDBNx-Jjg0"},"source":["We initialize our bigram and trigram models using the brown corpus"]},{"cell_type":"markdown","metadata":{"id":"hs9GkInFJjg0"},"source":["Then we test our `context aware spelling corrector` for both models using some random test sentences:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z22O_vT0Jjg0"},"outputs":[],"source":["test_sentences = [\n","    \"let us sai we are freends\",\n","    \"in consequencaae of her sistero's marriange, been moistress of hois house from a vry early period\",\n","    \"Tomorrrow well bring somethiing new, so liv today as a memoory.\"\n","]"]},{"cell_type":"markdown","source":["First, we are going to use the other two tokenizers, just to see the results, we start with the regexp"],"metadata":{"id":"IPCQsxc6LVjj"}},{"cell_type":"code","source":["# Initialize and train models\n","bigram_model_regexp = NGramLanguageModel(n=2, min_freq=10, tokenizer='regexp')\n","bigram_model_regexp.train(train_corpus)\n","\n","trigram_model_regexp = NGramLanguageModel(n=3, min_freq=10, tokenizer='regexp')\n","trigram_model_regexp.train(train_corpus)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93xK-xpVAgL8","executionInfo":{"status":"ok","timestamp":1745955011890,"user_tz":-180,"elapsed":6914,"user":{"displayName":"miketheofan","userId":"10285638803286005390"}},"outputId":"7a8a3400-dc58-4f13-81cc-725ec1d3df0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training 2-gram model on corpus...\n","Extracted 33081 sentences from corpus\n","Vocabulary size: 6163 words\n","Extracted 189598 unique 2-grams\n","Total tokens in corpus: 746345\n","Training 3-gram model on corpus...\n","Extracted 33081 sentences from corpus\n","Vocabulary size: 6164 words\n","Extracted 461488 unique 3-grams\n","Total tokens in corpus: 746345\n"]}]},{"cell_type":"code","source":["corrector = ContextAwareSpellingCorrector()\n","\n","for sentence in test_sentences:\n","    corrected = corrector.correct(\n","        bigram_model_regexp,\n","        nltk.word_tokenize(sentence),\n","        beam_width=5,\n","        lambda_lm=0.8,\n","        lambda_err=0.2,\n","        skip_oov=True\n","    )\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5Ya7IHzAu_0","executionInfo":{"status":"ok","timestamp":1745955022423,"user_tz":-180,"elapsed":10575,"user":{"displayName":"miketheofan","userId":"10285638803286005390"}},"outputId":"50407061-c283-44f7-9178-101b8b42ad2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Starting correction for sentence: let us sai we are freends\n","\n","\n","Token: 'let' (in vocabulary, skipping correction)\n","\n","Token: 'us' (in vocabulary, skipping correction)\n","\n","Token: 'sai' | Context: ('us',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","a                  -5.4177      -1.0986      -4.5539\n","as                 -6.2911      -1.0986      -5.2526\n","an                 -6.8748      -1.0986      -5.7196\n","say                -7.2887      -0.6931      -5.9696\n","was                -7.2887      -1.0986      -6.0507\n","Best candidate selected: a\n","-------------------------------------------------------\n","\n","Token: 'we' (in vocabulary, skipping correction)\n","\n","Token: 'are' (in vocabulary, skipping correction)\n","\n","Token: 'freends' | Context: ('are',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","freed             -11.4242      -1.0986      -9.3591\n","freed             -11.4242      -1.0986      -9.3591\n","freed             -11.4242      -1.0986      -9.3591\n","freed             -11.4242      -1.0986      -9.3591\n","freed             -11.4242      -1.0986      -9.3591\n","Best candidate selected: freed\n","-------------------------------------------------------\n","\n","Final corrected sentence: let us a we are freed\n","\n","\n","Starting correction for sentence: in consequencaae of her sistero 's marriange , been moistress of hois house from a vry early period\n","\n","\n","Token: 'in' (in vocabulary, skipping correction)\n","\n","Token: 'consequencaae' | Context: ('in',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","consequence       -12.6835      -1.0986     -10.3665\n","Best candidate selected: consequence\n","-------------------------------------------------------\n","\n","Token: 'of' (in vocabulary, skipping correction)\n","\n","Token: 'her' (in vocabulary, skipping correction)\n","\n","Token: 'sistero' | Context: ('her',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","sister            -10.9065      -0.6931      -8.8638\n","sitter            -17.5647      -1.0986     -14.2715\n","Best candidate selected: sister\n","-------------------------------------------------------\n","\n","Token: ''s' | Context: ('sitter',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n",",                  -3.6439      -1.0986      -3.1349\n","of                 -5.4462      -1.0986      -4.5766\n",".                  -5.4462      -1.0986      -4.5766\n","s                  -6.4390      -0.6931      -5.2898\n","in                 -6.4390      -1.0986      -5.3709\n","Best candidate selected: ,\n","-------------------------------------------------------\n","\n","Token: 'marriange' | Context: ('in',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","marriage          -14.1502      -0.6931     -11.4588\n","marriage          -14.1502      -0.6931     -11.4588\n","marriage          -14.1502      -0.6931     -11.4588\n","marriage          -14.1502      -0.6931     -11.4588\n","marriages         -21.8012      -1.0986     -17.6607\n","Best candidate selected: marriage\n","-------------------------------------------------------\n","\n","Token: ',' (in vocabulary, skipping correction)\n","\n","Token: 'been' (in vocabulary, skipping correction)\n","\n","Token: 'moistress' | Context: ('been',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","moistress         -17.2490      +0.0000     -13.7992\n","moistress         -17.2490      +0.0000     -13.7992\n","moistress         -17.2490      +0.0000     -13.7992\n","moistress         -17.2490      +0.0000     -13.7992\n","moistress         -17.2490      +0.0000     -13.7992\n","Best candidate selected: moistress\n","-------------------------------------------------------\n","\n","Token: 'of' (in vocabulary, skipping correction)\n","\n","Token: 'hois' | Context: ('of',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","his                -5.4491      -0.6931      -4.4979\n","his                -5.4491      -0.6931      -4.4979\n","this               -6.1172      -1.0986      -5.1134\n","this               -6.1172      -1.0986      -5.1134\n","his                -5.4491      -0.6931      -4.4979\n","Best candidate selected: his\n","-------------------------------------------------------\n","\n","Token: 'house' (in vocabulary, skipping correction)\n","\n","Token: 'from' (in vocabulary, skipping correction)\n","\n","Token: 'a' (in vocabulary, skipping correction)\n","\n","Token: 'vry' | Context: ('a',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","very               -7.5149      -0.6931      -6.1505\n","very               -7.5149      -0.6931      -6.1505\n","very               -7.5149      -0.6931      -6.1505\n","day                -8.3772      -1.0986      -6.9215\n","very               -7.5149      -0.6931      -6.1505\n","Best candidate selected: very\n","-------------------------------------------------------\n","\n","Token: 'early' (in vocabulary, skipping correction)\n","\n","Token: 'period' (in vocabulary, skipping correction)\n","\n","Final corrected sentence: in consequence of her sister , marriage , been moistress of his house from a very early period\n","\n","\n","Starting correction for sentence: Tomorrrow well bring somethiing new , so liv today as a memoory .\n","\n","\n","Token: 'Tomorrrow' | Context: ('<start>',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","tomorrow          -15.0020      -1.0986     -12.2214\n","Best candidate selected: tomorrow\n","-------------------------------------------------------\n","\n","Token: 'well' (in vocabulary, skipping correction)\n","\n","Token: 'bring' (in vocabulary, skipping correction)\n","\n","Token: 'somethiing' | Context: ('bring',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","something         -13.7898      -0.6931     -11.1705\n","Best candidate selected: something\n","-------------------------------------------------------\n","\n","Token: 'new' (in vocabulary, skipping correction)\n","\n","Token: ',' (in vocabulary, skipping correction)\n","\n","Token: 'so' (in vocabulary, skipping correction)\n","\n","Token: 'liv' | Context: ('so',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","i                  -5.7571      -1.0986      -4.8254\n","it                 -6.0085      -1.0986      -5.0266\n","in                 -7.5921      -1.0986      -6.2934\n","is                 -7.8142      -1.0986      -6.4711\n","did                -8.0767      -1.0986      -6.6811\n","Best candidate selected: i\n","-------------------------------------------------------\n","\n","Token: 'today' (in vocabulary, skipping correction)\n","\n","Token: 'as' (in vocabulary, skipping correction)\n","\n","Token: 'a' (in vocabulary, skipping correction)\n","\n","Token: 'memoory' | Context: ('a',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","memory            -20.4809      -0.6931     -16.5233\n","memory            -20.4809      -0.6931     -16.5233\n","memory            -20.4809      -0.6931     -16.5233\n","memory            -20.4809      -0.6931     -16.5233\n","memory            -20.4809      -0.6931     -16.5233\n","Best candidate selected: memory\n","-------------------------------------------------------\n","\n","Token: '.' (in vocabulary, skipping correction)\n","\n","Final corrected sentence: tomorrow well bring something new , so i today as a memory .\n","\n"]}]},{"cell_type":"code","source":["corrector = ContextAwareSpellingCorrector()\n","\n","for sentence in test_sentences:\n","    corrected = corrector.correct(\n","        trigram_model_regexp,\n","        nltk.word_tokenize(sentence),\n","        beam_width=5,\n","        lambda_lm=0.8,\n","        lambda_err=0.2,\n","        skip_oov=True\n","    )\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CV-aWtceAv5I","executionInfo":{"status":"ok","timestamp":1745955032656,"user_tz":-180,"elapsed":10240,"user":{"displayName":"miketheofan","userId":"10285638803286005390"}},"outputId":"57fb3d15-e8e7-408e-a907-aa13a5580392"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Starting correction for sentence: let us sai we are freends\n","\n","\n","Token: 'let' (in vocabulary, skipping correction)\n","\n","Token: 'us' (in vocabulary, skipping correction)\n","\n","Token: 'sai' | Context: ('let', 'us')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","say                -5.6315      -0.6931      -4.6438\n","see                -5.6315      -1.0986      -4.7249\n","saw               -13.2825      -0.6931     -10.7646\n","sat               -13.2825      -0.6931     -10.7646\n","said              -13.2825      -0.6931     -10.7646\n","Best candidate selected: say\n","-------------------------------------------------------\n","\n","Token: 'we' (in vocabulary, skipping correction)\n","\n","Token: 'are' (in vocabulary, skipping correction)\n","\n","Token: 'freends' | Context: ('we', 'are')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","friends           -14.2110      -0.6931     -11.5074\n","trends            -14.2110      -1.0986     -11.5885\n","friend            -14.2110      -1.0986     -11.5885\n","freed             -14.2110      -1.0986     -11.5885\n","friends           -14.2110      -0.6931     -11.5074\n","Best candidate selected: friends\n","-------------------------------------------------------\n","\n","Final corrected sentence: let us say we are friends\n","\n","\n","Starting correction for sentence: in consequencaae of her sistero 's marriange , been moistress of hois house from a vry early period\n","\n","\n","Token: 'in' (in vocabulary, skipping correction)\n","\n","Token: 'consequencaae' | Context: ('<start2>', 'in')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","consequence       -16.8221      -1.0986     -13.6774\n","Best candidate selected: consequence\n","-------------------------------------------------------\n","\n","Token: 'of' (in vocabulary, skipping correction)\n","\n","Token: 'her' (in vocabulary, skipping correction)\n","\n","Token: 'sistero' | Context: ('of', 'her')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","sister            -14.3278      -0.6931     -11.6009\n","sitter            -14.3278      -1.0986     -11.6820\n","Best candidate selected: sister\n","-------------------------------------------------------\n","\n","Token: ''s' | Context: ('her', 'sitter')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","s                  -5.9547      -0.6931      -4.9024\n","us                -12.6129      -0.6931     -10.2289\n","is                -12.6129      -0.6931     -10.2289\n","vs                -12.6129      -0.6931     -10.2289\n","as                -12.6129      -0.6931     -10.2289\n","Best candidate selected: s\n","-------------------------------------------------------\n","\n","Token: 'marriange' | Context: ('sister', 'as')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","marriage          -12.6129      -0.6931     -10.2289\n","marriages         -12.6129      -1.0986     -10.3100\n","marriage          -12.6129      -0.6931     -10.2289\n","marriage          -12.6129      -0.6931     -10.2289\n","marriage          -12.6129      -0.6931     -10.2289\n","Best candidate selected: marriage\n","-------------------------------------------------------\n","\n","Token: ',' (in vocabulary, skipping correction)\n","\n","Token: 'been' (in vocabulary, skipping correction)\n","\n","Token: 'moistress' | Context: (',', 'been')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","moistress         -12.7448      +0.0000     -10.1959\n","moistress         -12.7448      +0.0000     -10.1959\n","moistress         -12.7448      +0.0000     -10.1959\n","moistress         -12.7448      +0.0000     -10.1959\n","moistress         -12.7448      +0.0000     -10.1959\n","Best candidate selected: moistress\n","-------------------------------------------------------\n","\n","Token: 'of' (in vocabulary, skipping correction)\n","\n","Token: 'hois' | Context: ('moistress', 'of')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","his               -12.5897      -0.6931     -10.2104\n","homes             -12.5897      -1.0986     -10.2914\n","horse             -12.5897      -1.0986     -10.2914\n","hits              -12.5897      -1.0986     -10.2914\n","hope              -12.5897      -1.0986     -10.2914\n","Best candidate selected: his\n","-------------------------------------------------------\n","\n","Token: 'house' (in vocabulary, skipping correction)\n","\n","Token: 'from' (in vocabulary, skipping correction)\n","\n","Token: 'a' (in vocabulary, skipping correction)\n","\n","Token: 'vry' | Context: ('from', 'a')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","very               -7.7179      -0.6931      -6.3130\n","pro                -7.7179      -1.0986      -6.3941\n","very               -7.7179      -0.6931      -6.3130\n","very               -7.7179      -0.6931      -6.3130\n","very               -7.7179      -0.6931      -6.3130\n","Best candidate selected: very\n","-------------------------------------------------------\n","\n","Token: 'early' (in vocabulary, skipping correction)\n","\n","Token: 'period' (in vocabulary, skipping correction)\n","\n","Final corrected sentence: in consequence of her sister s marriage , been moistress of his house from a very early period\n","\n","\n","Starting correction for sentence: Tomorrrow well bring somethiing new , so liv today as a memoory .\n","\n","\n","Token: 'Tomorrrow' | Context: ('<start1>', '<start2>')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","tomorrow          -15.0020      -1.0986     -12.2214\n","Best candidate selected: tomorrow\n","-------------------------------------------------------\n","\n","Token: 'well' (in vocabulary, skipping correction)\n","\n","Token: 'bring' (in vocabulary, skipping correction)\n","\n","Token: 'somethiing' | Context: ('well', 'bring')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","something         -12.5897      -0.6931     -10.2104\n","Best candidate selected: something\n","-------------------------------------------------------\n","\n","Token: 'new' (in vocabulary, skipping correction)\n","\n","Token: ',' (in vocabulary, skipping correction)\n","\n","Token: 'so' (in vocabulary, skipping correction)\n","\n","Token: 'liv' | Context: (',', 'so')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","it                 -4.8969      -1.0986      -4.1372\n","i                  -5.3113      -1.0986      -4.4688\n","if                 -6.3089      -1.0986      -5.2669\n","his                -7.8843      -1.0986      -6.5272\n","is                 -7.8843      -1.0986      -6.5272\n","Best candidate selected: it\n","-------------------------------------------------------\n","\n","Token: 'today' (in vocabulary, skipping correction)\n","\n","Token: 'as' (in vocabulary, skipping correction)\n","\n","Token: 'a' (in vocabulary, skipping correction)\n","\n","Token: 'memoory' | Context: ('as', 'a')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","memory            -16.0246      -0.6931     -12.9583\n","memory            -16.0246      -0.6931     -12.9583\n","memory            -16.0246      -0.6931     -12.9583\n","memory            -16.0246      -0.6931     -12.9583\n","memory            -16.0246      -0.6931     -12.9583\n","Best candidate selected: memory\n","-------------------------------------------------------\n","\n","Token: '.' (in vocabulary, skipping correction)\n","\n","Final corrected sentence: tomorrow well bring something new , so it today as a memory .\n","\n"]}]},{"cell_type":"markdown","source":["And now we also use the custom tokenizer (that skips punctuation)"],"metadata":{"id":"o80qy2pDLeMA"}},{"cell_type":"code","source":["# Initialize and train models\n","bigram_model_custom = NGramLanguageModel(n=2, min_freq=10, tokenizer='custom')\n","bigram_model_custom.train(train_corpus)\n","\n","trigram_model_custom = NGramLanguageModel(n=3, min_freq=10, tokenizer='custom')\n","trigram_model_custom.train(train_corpus)"],"metadata":{"id":"PwVqI29FAy7q","executionInfo":{"status":"aborted","timestamp":1745957053745,"user_tz":-180,"elapsed":10,"user":{"displayName":"Marios Mantzaris","userId":"03416491895175165913"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corrector = ContextAwareSpellingCorrector()\n","\n","for sentence in test_sentences:\n","    corrected = corrector.correct(\n","        bigram_model_custom,\n","        nltk.word_tokenize(sentence),\n","        beam_width=5,\n","        lambda_lm=0.8,\n","        lambda_err=0.2,\n","        skip_oov=True\n","    )\n","    print()"],"metadata":{"id":"iSQV6YOUA9e5","executionInfo":{"status":"aborted","timestamp":1745957053747,"user_tz":-180,"elapsed":10,"user":{"displayName":"Marios Mantzaris","userId":"03416491895175165913"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corrector = ContextAwareSpellingCorrector()\n","\n","for sentence in test_sentences:\n","    corrected = corrector.correct(\n","        trigram_model_custom,\n","        nltk.word_tokenize(sentence),\n","        beam_width=5,\n","        lambda_lm=0.8,\n","        lambda_err=0.2,\n","        skip_oov=True\n","    )\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S2bGEwMsA-qe","executionInfo":{"status":"ok","timestamp":1745955061343,"user_tz":-180,"elapsed":8404,"user":{"displayName":"miketheofan","userId":"10285638803286005390"}},"outputId":"3d35d41b-3f39-4e62-c088-5062526ae19e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Starting correction for sentence: let us sai we are freends\n","\n","\n","Token: 'let' (in vocabulary, skipping correction)\n","\n","Token: 'us' (in vocabulary, skipping correction)\n","\n","Token: 'sai' | Context: ('let', 'us')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","say                -5.6210      -0.6931      -4.6354\n","see                -5.6210      -1.0986      -4.7165\n","saw               -13.2720      -0.6931     -10.7563\n","sat               -13.2720      -0.6931     -10.7563\n","said              -13.2720      -0.6931     -10.7563\n","Best candidate selected: say\n","-------------------------------------------------------\n","\n","Token: 'we' (in vocabulary, skipping correction)\n","\n","Token: 'are' (in vocabulary, skipping correction)\n","\n","Token: 'freends' | Context: ('we', 'are')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","friends           -14.2207      -0.6931     -11.5152\n","trends            -14.2207      -1.0986     -11.5963\n","friend            -14.2207      -1.0986     -11.5963\n","freed             -14.2207      -1.0986     -11.5963\n","friends           -14.2207      -0.6931     -11.5152\n","Best candidate selected: friends\n","-------------------------------------------------------\n","\n","Final corrected sentence: let us say we are friends\n","\n","\n","Starting correction for sentence: in consequencaae of her sistero 's marriange , been moistress of hois house from a vry early period\n","\n","\n","Token: 'in' (in vocabulary, skipping correction)\n","\n","Token: 'consequencaae' | Context: ('<start2>', 'in')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","consequence       -16.7948      -1.0986     -13.6555\n","Best candidate selected: consequence\n","-------------------------------------------------------\n","\n","Token: 'of' (in vocabulary, skipping correction)\n","\n","Token: 'her' (in vocabulary, skipping correction)\n","\n","Token: 'sistero' | Context: ('of', 'her')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","sister            -14.3228      -0.6931     -11.5968\n","sitter            -14.3228      -1.0986     -11.6779\n","Best candidate selected: sister\n","-------------------------------------------------------\n","\n","Token: ''s' (in vocabulary, skipping correction)\n","\n","Token: 'marriange' | Context: ('sitter', \"'s\")\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","marriage          -12.5962      -0.6931     -10.2156\n","marriages         -12.5962      -1.0986     -10.2967\n","marriage          -12.5962      -0.6931     -10.2156\n","marriages         -12.5962      -1.0986     -10.2967\n","Best candidate selected: marriage\n","-------------------------------------------------------\n","\n","Token: ',' (in vocabulary, skipping correction)\n","\n","Token: 'been' (in vocabulary, skipping correction)\n","\n","Token: 'moistress' | Context: (',', 'been')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","moistress         -12.7296      +0.0000     -10.1837\n","moistress         -12.7296      +0.0000     -10.1837\n","moistress         -12.7296      +0.0000     -10.1837\n","moistress         -12.7296      +0.0000     -10.1837\n","Best candidate selected: moistress\n","-------------------------------------------------------\n","\n","Token: 'of' (in vocabulary, skipping correction)\n","\n","Token: 'hois' | Context: ('moistress', 'of')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","his               -12.5727      -0.6931     -10.1968\n","his               -12.5727      -0.6931     -10.1968\n","his               -12.5727      -0.6931     -10.1968\n","homes             -12.5727      -1.0986     -10.2779\n","horse             -12.5727      -1.0986     -10.2779\n","Best candidate selected: his\n","-------------------------------------------------------\n","\n","Token: 'house' (in vocabulary, skipping correction)\n","\n","Token: 'from' (in vocabulary, skipping correction)\n","\n","Token: 'a' (in vocabulary, skipping correction)\n","\n","Token: 'vry' | Context: ('from', 'a')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","very               -7.6925      -0.6931      -6.2926\n","very               -7.6925      -0.6931      -6.2926\n","very               -7.6925      -0.6931      -6.2926\n","very               -7.6925      -0.6931      -6.2926\n","very               -7.6925      -0.6931      -6.2926\n","Best candidate selected: very\n","-------------------------------------------------------\n","\n","Token: 'early' (in vocabulary, skipping correction)\n","\n","Token: 'period' (in vocabulary, skipping correction)\n","\n","Final corrected sentence: in consequence of her sister 's marriage , been moistress of his house from a very early period\n","\n","\n","Starting correction for sentence: Tomorrrow well bring somethiing new , so liv today as a memoory .\n","\n","\n","Token: 'Tomorrrow' | Context: ('<start1>', '<start2>')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","tomorrow          -15.0832      -1.0986     -12.2863\n","Best candidate selected: tomorrow\n","-------------------------------------------------------\n","\n","Token: 'well' (in vocabulary, skipping correction)\n","\n","Token: 'bring' (in vocabulary, skipping correction)\n","\n","Token: 'somethiing' | Context: ('well', 'bring')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","something         -12.5727      -0.6931     -10.1968\n","Best candidate selected: something\n","-------------------------------------------------------\n","\n","Token: 'new' (in vocabulary, skipping correction)\n","\n","Token: ',' (in vocabulary, skipping correction)\n","\n","Token: 'so' (in vocabulary, skipping correction)\n","\n","Token: 'liv' | Context: (',', 'so')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","it                 -4.8742      -1.0986      -4.1191\n","i                  -5.2887      -1.0986      -4.4507\n","if                 -6.2863      -1.0986      -5.2487\n","his                -7.8617      -1.0986      -6.5091\n","is                 -7.8617      -1.0986      -6.5091\n","Best candidate selected: it\n","-------------------------------------------------------\n","\n","Token: 'today' (in vocabulary, skipping correction)\n","\n","Token: 'as' (in vocabulary, skipping correction)\n","\n","Token: 'a' (in vocabulary, skipping correction)\n","\n","Token: 'memoory' | Context: ('as', 'a')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","memory            -16.0078      -0.6931     -12.9449\n","memory            -16.0078      -0.6931     -12.9449\n","memory            -16.0078      -0.6931     -12.9449\n","memory            -16.0078      -0.6931     -12.9449\n","memory            -16.0078      -0.6931     -12.9449\n","Best candidate selected: memory\n","-------------------------------------------------------\n","\n","Token: '.' (in vocabulary, skipping correction)\n","\n","Final corrected sentence: tomorrow well bring something new , so it today as a memory .\n","\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bg_eR7-VJjg0","outputId":"4f6129c8-a512-4031-d92d-458d41533e75","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745955069694,"user_tz":-180,"elapsed":8348,"user":{"displayName":"miketheofan","userId":"10285638803286005390"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Starting correction for sentence: let us sai we are freends\n","\n","\n","Token: 'let' (in vocabulary, skipping correction)\n","\n","Token: 'us' (in vocabulary, skipping correction)\n","\n","Token: 'sai' | Context: ('us',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","a                  -5.4155      -1.0986      -4.5521\n","as                 -6.2888      -1.0986      -5.2508\n","an                 -6.8726      -1.0986      -5.7178\n","say                -7.2864      -0.6931      -5.9678\n","was                -7.2864      -1.0986      -6.0489\n","Best candidate selected: a\n","-------------------------------------------------------\n","\n","Token: 'we' (in vocabulary, skipping correction)\n","\n","Token: 'are' (in vocabulary, skipping correction)\n","\n","Token: 'freends' | Context: ('are',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","freed             -11.4363      -1.0986      -9.3688\n","freed             -11.4363      -1.0986      -9.3688\n","freed             -11.4363      -1.0986      -9.3688\n","freed             -11.4363      -1.0986      -9.3688\n","freed             -11.4363      -1.0986      -9.3688\n","Best candidate selected: freed\n","-------------------------------------------------------\n","\n","Final corrected sentence: let us a we are freed\n","\n","\n","Starting correction for sentence: in consequencaae of her sistero 's marriange , been moistress of hois house from a vry early period\n","\n","\n","Token: 'in' (in vocabulary, skipping correction)\n","\n","Token: 'consequencaae' | Context: ('in',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","consequence       -12.6775      -1.0986     -10.3618\n","Best candidate selected: consequence\n","-------------------------------------------------------\n","\n","Token: 'of' (in vocabulary, skipping correction)\n","\n","Token: 'her' (in vocabulary, skipping correction)\n","\n","Token: 'sistero' | Context: ('her',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","sister            -10.9059      -0.6931      -8.8634\n","sitter            -17.5641      -1.0986     -14.2710\n","Best candidate selected: sister\n","-------------------------------------------------------\n","\n","Token: ''s' (in vocabulary, skipping correction)\n","\n","Token: 'marriange' | Context: (\"'s\",)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","marriage          -18.4708      -0.6931     -14.9152\n","marriages         -18.4708      -1.0986     -14.9963\n","marriage          -18.4708      -0.6931     -14.9152\n","marriages         -18.4708      -1.0986     -14.9963\n","Best candidate selected: marriage\n","-------------------------------------------------------\n","\n","Token: ',' (in vocabulary, skipping correction)\n","\n","Token: 'been' (in vocabulary, skipping correction)\n","\n","Token: 'moistress' | Context: ('been',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","moistress         -17.2483      +0.0000     -13.7987\n","moistress         -17.2483      +0.0000     -13.7987\n","moistress         -17.2483      +0.0000     -13.7987\n","moistress         -17.2483      +0.0000     -13.7987\n","Best candidate selected: moistress\n","-------------------------------------------------------\n","\n","Token: 'of' (in vocabulary, skipping correction)\n","\n","Token: 'hois' | Context: ('of',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","his                -5.4464      -0.6931      -4.4958\n","his                -5.4464      -0.6931      -4.4958\n","this               -6.1145      -1.0986      -5.1113\n","this               -6.1145      -1.0986      -5.1113\n","him                -8.7625      -1.0986      -7.2298\n","Best candidate selected: his\n","-------------------------------------------------------\n","\n","Token: 'house' (in vocabulary, skipping correction)\n","\n","Token: 'from' (in vocabulary, skipping correction)\n","\n","Token: 'a' (in vocabulary, skipping correction)\n","\n","Token: 'vry' | Context: ('a',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","very               -7.5147      -0.6931      -6.1504\n","very               -7.5147      -0.6931      -6.1504\n","very               -7.5147      -0.6931      -6.1504\n","very               -7.5147      -0.6931      -6.1504\n","day                -8.3589      -1.0986      -6.9069\n","Best candidate selected: very\n","-------------------------------------------------------\n","\n","Token: 'early' (in vocabulary, skipping correction)\n","\n","Token: 'period' (in vocabulary, skipping correction)\n","\n","Final corrected sentence: in consequence of her sister 's marriage , been moistress of his house from a very early period\n","\n","\n","Starting correction for sentence: Tomorrrow well bring somethiing new , so liv today as a memoory .\n","\n","\n","Token: 'Tomorrrow' | Context: ('<start>',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","tomorrow          -15.0832      -1.0986     -12.2863\n","Best candidate selected: tomorrow\n","-------------------------------------------------------\n","\n","Token: 'well' (in vocabulary, skipping correction)\n","\n","Token: 'bring' (in vocabulary, skipping correction)\n","\n","Token: 'somethiing' | Context: ('bring',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","something         -13.7824      -0.6931     -11.1645\n","Best candidate selected: something\n","-------------------------------------------------------\n","\n","Token: 'new' (in vocabulary, skipping correction)\n","\n","Token: ',' (in vocabulary, skipping correction)\n","\n","Token: 'so' (in vocabulary, skipping correction)\n","\n","Token: 'liv' | Context: ('so',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","i                  -5.7185      -1.0986      -4.7945\n","it                 -5.9699      -1.0986      -4.9957\n","in                 -7.7756      -1.0986      -6.4402\n","did                -8.0381      -1.0986      -6.6502\n","is                 -8.0381      -1.0986      -6.6502\n","Best candidate selected: i\n","-------------------------------------------------------\n","\n","Token: 'today' (in vocabulary, skipping correction)\n","\n","Token: 'as' (in vocabulary, skipping correction)\n","\n","Token: 'a' (in vocabulary, skipping correction)\n","\n","Token: 'memoory' | Context: ('a',)\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","memory            -20.4625      -0.6931     -16.5087\n","memory            -20.4625      -0.6931     -16.5087\n","memory            -20.4625      -0.6931     -16.5087\n","memory            -20.4625      -0.6931     -16.5087\n","memory            -20.4625      -0.6931     -16.5087\n","Best candidate selected: memory\n","-------------------------------------------------------\n","\n","Token: '.' (in vocabulary, skipping correction)\n","\n","Final corrected sentence: tomorrow well bring something new , so i today as a memory .\n","\n"]}],"source":["corrector = ContextAwareSpellingCorrector()\n","\n","for sentence in test_sentences:\n","    corrected = corrector.correct(\n","        bigram_model,\n","        nltk.word_tokenize(sentence),\n","        beam_width=5,\n","        lambda_lm=0.8,\n","        lambda_err=0.2,\n","        skip_oov=True\n","    )\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_5YSTvH9Jjg0","outputId":"beb90f0e-0a9d-41fe-e82c-a134051b2058","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745945187453,"user_tz":-180,"elapsed":8775,"user":{"displayName":"Marios Mantzaris","userId":"03416491895175165913"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Starting correction for sentence: let us sai we are freends\n","\n","\n","Token: 'let' (in vocabulary, skipping correction)\n","\n","Token: 'us' (in vocabulary, skipping correction)\n","\n","Token: 'sai' | Context: ('let', 'us')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","say                -5.6207      -0.6931      -4.6352\n","see                -5.6207      -1.0986      -4.7163\n","sad               -13.2718      -0.6931     -10.7560\n","sat               -13.2718      -0.6931     -10.7560\n","san               -13.2718      -0.6931     -10.7560\n","Best candidate selected: say\n","-------------------------------------------------------\n","\n","Token: 'we' (in vocabulary, skipping correction)\n","\n","Token: 'are' (in vocabulary, skipping correction)\n","\n","Token: 'freends' | Context: ('we', 'are')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","friends           -14.2205      -0.6931     -11.5151\n","friend            -14.2205      -1.0986     -11.5961\n","freed             -14.2205      -1.0986     -11.5961\n","trends            -14.2205      -1.0986     -11.5961\n","friends           -14.2205      -0.6931     -11.5151\n","Best candidate selected: friends\n","-------------------------------------------------------\n","\n","Final corrected sentence: let us say we are friends\n","\n","\n","Starting correction for sentence: in consequencaae of her sistero 's marriange , been moistress of hois house from a vry early period\n","\n","\n","Token: 'in' (in vocabulary, skipping correction)\n","\n","Token: 'consequencaae' | Context: ('<start2>', 'in')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","consequence       -16.7947      -1.0986     -13.6555\n","Best candidate selected: consequence\n","-------------------------------------------------------\n","\n","Token: 'of' (in vocabulary, skipping correction)\n","\n","Token: 'her' (in vocabulary, skipping correction)\n","\n","Token: 'sistero' | Context: ('of', 'her')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","sister            -14.3226      -0.6931     -11.5967\n","sitter            -14.3226      -1.0986     -11.6778\n","Best candidate selected: sister\n","-------------------------------------------------------\n","\n","Token: ''s' (in vocabulary, skipping correction)\n","\n","Token: 'marriange' | Context: ('sitter', \"'s\")\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","marriage          -12.5957      -0.6931     -10.2152\n","marriages         -12.5957      -1.0986     -10.2963\n","marriage          -12.5957      -0.6931     -10.2152\n","marriages         -12.5957      -1.0986     -10.2963\n","Best candidate selected: marriage\n","-------------------------------------------------------\n","\n","Token: ',' (in vocabulary, skipping correction)\n","\n","Token: 'been' (in vocabulary, skipping correction)\n","\n","Token: 'moistress' | Context: (',', 'been')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","moistress         -12.7292      +0.0000     -10.1834\n","moistress         -12.7292      +0.0000     -10.1834\n","moistress         -12.7292      +0.0000     -10.1834\n","moistress         -12.7292      +0.0000     -10.1834\n","Best candidate selected: moistress\n","-------------------------------------------------------\n","\n","Token: 'of' (in vocabulary, skipping correction)\n","\n","Token: 'hois' | Context: ('moistress', 'of')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","his               -12.5722      -0.6931     -10.1964\n","loss              -12.5722      -1.0986     -10.2775\n","how               -12.5722      -1.0986     -10.2775\n","homes             -12.5722      -1.0986     -10.2775\n","boys              -12.5722      -1.0986     -10.2775\n","Best candidate selected: his\n","-------------------------------------------------------\n","\n","Token: 'house' (in vocabulary, skipping correction)\n","\n","Token: 'from' (in vocabulary, skipping correction)\n","\n","Token: 'a' (in vocabulary, skipping correction)\n","\n","Token: 'vry' | Context: ('from', 'a')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","very               -7.6923      -0.6931      -6.2925\n","very               -7.6923      -0.6931      -6.2925\n","very               -7.6923      -0.6931      -6.2925\n","very               -7.6923      -0.6931      -6.2925\n","very               -7.6923      -0.6931      -6.2925\n","Best candidate selected: very\n","-------------------------------------------------------\n","\n","Token: 'early' (in vocabulary, skipping correction)\n","\n","Token: 'period' (in vocabulary, skipping correction)\n","\n","Final corrected sentence: in consequence of her sister 's marriage , been moistress of his house from a very early period\n","\n","\n","Starting correction for sentence: Tomorrrow well bring somethiing new , so liv today as a memoory .\n","\n","\n","Token: 'Tomorrrow' | Context: ('<start1>', '<start2>')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","tomorrow          -15.0832      -1.0986     -12.2863\n","Best candidate selected: tomorrow\n","-------------------------------------------------------\n","\n","Token: 'well' (in vocabulary, skipping correction)\n","\n","Token: 'bring' (in vocabulary, skipping correction)\n","\n","Token: 'somethiing' | Context: ('well', 'bring')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","something         -12.5722      -0.6931     -10.1964\n","Best candidate selected: something\n","-------------------------------------------------------\n","\n","Token: 'new' (in vocabulary, skipping correction)\n","\n","Token: ',' (in vocabulary, skipping correction)\n","\n","Token: 'so' (in vocabulary, skipping correction)\n","\n","Token: 'liv' | Context: (',', 'so')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","it                 -4.8741      -1.0986      -4.1190\n","i                  -5.2885      -1.0986      -4.4506\n","if                 -6.2861      -1.0986      -5.2486\n","his                -7.8615      -1.0986      -6.5090\n","is                 -7.8615      -1.0986      -6.5090\n","Best candidate selected: it\n","-------------------------------------------------------\n","\n","Token: 'today' (in vocabulary, skipping correction)\n","\n","Token: 'as' (in vocabulary, skipping correction)\n","\n","Token: 'a' (in vocabulary, skipping correction)\n","\n","Token: 'memoory' | Context: ('as', 'a')\n","Top candidates:\n","Candidate         LM Score  Error Score     Combined\n","-------------------------------------------------------\n","memory            -16.0078      -0.6931     -12.9448\n","memory            -16.0078      -0.6931     -12.9448\n","memory            -16.0078      -0.6931     -12.9448\n","memory            -16.0078      -0.6931     -12.9448\n","memory            -16.0078      -0.6931     -12.9448\n","Best candidate selected: memory\n","-------------------------------------------------------\n","\n","Token: '.' (in vocabulary, skipping correction)\n","\n","Final corrected sentence: tomorrow well bring something new , so it today as a memory .\n","\n"]}],"source":["corrector = ContextAwareSpellingCorrector()\n","\n","for sentence in test_sentences:\n","    corrected = corrector.correct(\n","        trigram_model,\n","        nltk.word_tokenize(sentence),\n","        beam_width=5,\n","        lambda_lm=0.8,\n","        lambda_err=0.2,\n","        skip_oov=True\n","    )\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"iA6yy4QvJjg0"},"source":["### _Observations_\n","\n","We tested the corrector using vocabularies from models using all possible tokenizers. We prefer the results produced by the nltk tokenizer, so we will continue the analysis using these bigram and trigram models.\n","\n","1. **Correction Accuracy**\n","   * The **trigram model** generally selects better context-aware corrections compared to the **bigram model**.\n","   * In the bigram model, some corrections make sense locally but fail to match the overall sentence meaning.\n","   * With the trigram model, corrections like \"sey\" → \"see\" are more appropriate, because the model can consider two preceding words instead of only one, leading to more grammatically and semantically correct outputs.\n","\n","2. **Role of Context**\n","   * In the bigram model, only the immediate previous word is available to predict the next word. This can cause the model to pick a word that fits the local pair but not the broader sentence.\n","   * The trigram model, by using two preceding words, captures a richer context, helping it disambiguate between candidates that might otherwise look equally likely based on only one previous word.\n","\n","3. **Candidate Scoring**\n","   * When examining the top candidates:\n","     * The correct words often have better **combined scores** (language model + error model) in the trigram case.\n","     * Even if multiple candidates have close edit distances (error model scores), the **language model score** can now differentiate better because of the stronger context window.\n","   * This difference highlights how using a richer n-gram context improves the model's ability to rank correct candidates higher.\n","\n","4. **Stability Across Runs**\n","   * Even though specific score values (LM, error, combined) can change slightly across different training runs or random seeds, the overall behavior remains consistent:\n","     * The trigram model is more **stable** in choosing the most logical correction.\n","     * The bigram model shows more **variability** and occasional incorrect corrections.\n","\n","5. **Conclusion**\n","   * Moving from a bigram to a trigram model significantly improves the spelling correction performance by leveraging additional context, allowing the system to make more informed and globally consistent decisions about candidate words. The improvement is mainly due to better language model probabilities rather than changes in edit distances."]},{"cell_type":"markdown","metadata":{"id":"CMYn3b3qJjg1"},"source":["## Part 5"]},{"cell_type":"markdown","metadata":{"id":"EfuYzVp7Jjg1"},"source":["### _Artificial Test Dataset Creation_\n","\n","In this section we implement a class that generates an **artificially corrupted version** of the test corpus. This is necessary in order to stimulate real-world noisy inputs and evaluate the performance of the context-aware spelling corrector."]},{"cell_type":"markdown","metadata":{"id":"gPPxRBbkJjg1"},"source":["We firstly declare the class we will use"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v6AuL6m5Jjg1"},"outputs":[],"source":["class ArtificialTestDataset:\n","    def __init__(self, sentences, error_prob=0.05, seed=None):\n","        \"\"\"\n","        Initialize the artificial test dataset generator.\n","\n","        Args:\n","            sentences (List[str]): List of clean sentences to corrupt.\n","            error_prob (float): Probability of replacing each non-space character.\n","            seed (int, optional): Random seed for reproducibility.\n","        \"\"\"\n","        self.sentences = sentences\n","        self.error_prob = error_prob\n","        if seed is not None:\n","            random.seed(seed)\n","        # Character set for random replacements (excluding space)\n","        self.chars = list(string.ascii_letters + string.digits + string.punctuation)\n","\n","    def _corrupt_char(self, c):\n","        # Do not corrupt whitespace; apply corruption with given probability\n","        if c.isspace() or random.random() > self.error_prob:\n","            return c\n","        # Choose a random replacement different from the original\n","        replacement = random.choice(self.chars)\n","        while replacement == c:\n","            replacement = random.choice(self.chars)\n","        return replacement\n","\n","    def generate(self):\n","        \"\"\"\n","        Generate the corrupted dataset.\n","\n","        Returns:\n","            List[str]: Corrupted sentences.\n","        \"\"\"\n","        corrupted = []\n","        for sentence in self.sentences:\n","            corrupted_sentence = ''.join(self._corrupt_char(c) for c in sentence)\n","            corrupted.append(corrupted_sentence)\n","        return corrupted"]},{"cell_type":"markdown","metadata":{"id":"4iTNqj--Jjg1"},"source":["And then we test our generator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lhGmmmuLJjg1","outputId":"cd653f9d-b0a4-44a8-ae98-f6b45975fd0a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Showing original vs. corrupted for first 5 sentences:\n","============================================================\n","Original:  O beautiful for patriot dream that sees beyond the years thine alabaster cities gleam undimmed by human tears .\n","Corrupted: O Jeautifll fzr patriot dream that 6ees beyond Dhe years thine alabaster cities gleam undimmed by human tears .\n","------------------------------------------------------------\n","Original:  ( cf.\n","Corrupted: ( cf.\n","------------------------------------------------------------\n","Original:  The Village office of Western Union with George Towsley as manager and telegrapher continued in Hard's drugstore until 1905 .\n","Corrupted: The Villag} office of WesterP Union with George Towsley as manager )nd telegrapher continued in Hard's drugstore until 1905 .\n","------------------------------------------------------------\n","Original:  As if this was a signal , Poet abruptly began to thrash the water and the quick movement slowly made them sink through the water .\n","Corrupted: As if this was a signal , Poet abruptly began to thrash the water and the quic) movement slowly made tqem sinj thrVugh the water .\n","------------------------------------------------------------\n","Original:  Routine determinations were made for dissolved oxygen in the mixed liquor and for oxygen uptake rates .\n","Corrupted: Routine deQerminati8ns were yade for disHolved oxygen in 'he mixed liquor and for oxygen uptake rates .\n","------------------------------------------------------------\n"]}],"source":["# Now, with test_corpus loaded, generate the corrupted dataset and display samples:\n","generator = ArtificialTestDataset(test_corpus, error_prob=0.05, seed=42)\n","corrupted_test_corpus = generator.generate()\n","\n","print(\"Showing original vs. corrupted for first 5 sentences:\")\n","print(\"=\" * 60)\n","for orig, corrupt in zip(test_corpus[:5], corrupted_test_corpus[:5]):\n","    print(f\"Original:  {orig}\")\n","    print(f\"Corrupted: {corrupt}\")\n","    print(\"-\" * 60)"]},{"cell_type":"markdown","metadata":{"id":"wOcSb0JIJjg1"},"source":["## Part 6\n","Evaluation of the context-aware spelling corrector in terms of Word Error Rate (WER) and character Error Rate (CER)"]},{"cell_type":"markdown","metadata":{"id":"yaTR_CfXJjg1"},"source":["* **Character Error Rate (CER)** and **Word Error Rate (WER)** are metrics that measure the performance of the context aware spelling corrector by calculating the rate of erroneous characters produced by the system compared to the ground truth and its accuracy at the word level by measuring the proportion of incorrectly recognized words relative to the reference text.\n","* Both are derived from the Levenshtein (edit) distance with values typically ranging from 0 to 1, where 0 indicates perfect alignment of the system output to the ground truth anf 1 indicates total dissimilarity between the compared pieces of text. If the score is larger than 1 we assume that the prediction is worse than a complete mismatch, with more actions required (deletion, insertion, substitution) than reference words.\n","* WER is defined from the Levenshtein distance normalised by the sentence length: $$WER=\\frac{S+D+I}{N}$$ where\n","  - S: number of substitutions\n","  - D: number of deletions\n","  - I: number of insertions\n","  - N: number of words in reference text\n","* CER is defined from the Levenshtein distance normalised by the sentence length: $$CER=\\frac{S+D+I}{n}$$ where\n","  - n: number of characters in reference text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TjhwU7-4Jjg1"},"outputs":[],"source":["wer_metric = evaluate.load(\"wer\")  # Load WER metric\n","cer_metric = evaluate.load(\"cer\")  # Load CER metric"]},{"cell_type":"markdown","metadata":{"id":"FmtMWksDJjg1"},"source":["* For Bigram Language Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lXSLciJvJjg2"},"outputs":[],"source":["generator = ArtificialTestDataset(test_corpus, error_prob=0.05, seed=42)\n","corrupted_test_corpus = generator.generate()\n","\n","reference = test_corpus[:100] # Ground truth (list)\n","hypothesis = corrupted_test_corpus # Noisy sentences (list)\n","\n","reference_sentences_tokenised = []\n","corrupted_sentences_tokenised = []\n","corrected_sentences_tokenised = []\n","\n","corrector = ContextAwareSpellingCorrector()\n","\n","for sentence in hypothesis[:100]:\n","    test_tokens = nltk.word_tokenize(sentence)\n","    corrupted_sentences_tokenised.append(sentence)\n","    corrected_sentences_tokenised.append(\" \".join(\n","        corrector.correct(bigram_model,\n","            test_tokens,\n","            beam_width=5,\n","            lambda_lm=0.8,\n","            lambda_err=0.2,\n","            skip_oov=True,\n","            verbose=False)))\n","\n","for sentence in reference:\n","    reference_sentences_tokenised.append(nltk.word_tokenize(sentence))\n","\n","test_data = list(zip(reference_sentences_tokenised, corrupted_sentences_tokenised))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9VcpA5xmJjg2","outputId":"e15d5d8c-9b4a-466c-92d3-580dcd3e4794"},"outputs":[{"name":"stdout","output_type":"stream","text":["WER: 0.3369\n","CER: 0.1024\n"]}],"source":["wer_score = wer_metric.compute(references=reference, predictions=corrected_sentences_tokenised)\n","cer_score = cer_metric.compute(references=reference, predictions=corrected_sentences_tokenised)\n","\n","print(f\"WER: {wer_score:.4f}\")\n","print(f\"CER: {cer_score:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"zCbyYmIWJjg3"},"source":["* For Trigram Language Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8kHckXMaJjg6"},"outputs":[],"source":["generator = ArtificialTestDataset(test_corpus, error_prob=0.05, seed=42)\n","corrupted_test_corpus = generator.generate()\n","\n","reference = test_corpus[:100] # Ground truth (list)\n","hypothesis = corrupted_test_corpus # Noisy (list)\n","\n","reference_sentences_tokenised = []\n","corrupted_sentences_tokenised = []\n","corrected_sentences_tokenised = []\n","\n","corrector = ContextAwareSpellingCorrector()\n","\n","for sentence in hypothesis[:100]:\n","    test_tokens = nltk.word_tokenize(sentence)\n","    corrupted_sentences_tokenised.append(sentence)\n","    corrected_sentences_tokenised.append(\" \".join(\n","        corrector.correct(bigram_model,\n","            test_tokens,\n","            beam_width=5,\n","            lambda_lm=0.8,\n","            lambda_err=0.2,\n","            skip_oov=True,\n","            verbose=False)))\n","\n","for sentence in reference:\n","    reference_sentences_tokenised.append(nltk.word_tokenize(sentence))\n","\n","test_data = list(zip(reference_sentences_tokenised, corrupted_sentences_tokenised))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"25fRGOc8Jjg6","outputId":"9820fd9f-4fdf-4240-ecbf-e3cb27e10949"},"outputs":[{"name":"stdout","output_type":"stream","text":["WER: 0.3369\n","CER: 0.1024\n"]}],"source":["wer_score = wer_metric.compute(references=reference, predictions=corrected_sentences_tokenised)\n","cer_score = cer_metric.compute(references=reference, predictions=corrected_sentences_tokenised)\n","\n","print(f\"WER: {wer_score:.4f}\")\n","print(f\"CER: {cer_score:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"zqTZLcgCJjg6"},"source":["### Implementation of the Evaluation Class\n","\n","The SpellingCorrectionEvaluator class encapsulates the whole pipeline which performs the evaluation of a context-aware spelling corrector (passed as a callable object argument) on artificially corrupted test data (generator method from ArtificialTestDataset instance).\n","\n","Steps:\n","1. Takes in a list of ground truth (clean) sentences to use as references.\n","2. Initializes an ArtificialTestDataset instance to generate noisy versions of the reference sentences by introducing random errors with a given probability (error_prob).\n","3. Applies a context-aware spelling corrector (e.g., beam search using a trained n-gram model) on each corrupted sentence to produce a corrected hypothesis.\n","4. Computes Word Error Rate (WER) and Character Error Rate (CER) by comparing the corrected hypotheses against the original clean references.\n","5. Returns the WER and CER scores as evaluation results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H4sbUSVVJjg6"},"outputs":[],"source":["class SpellingCorrectionExperiment:\n","    \"\"\"\n","        Evaluation of the spelling_corrector_function performance on artificially corrupted data.\n","\n","         Args:\n","             test_corpus (list): List of ground truth (reference) sentences.\n","             spelling_corrector_function (callable): Function for context-aware spelling correction.\n","             language_model: Trained language model passed to the corrector.\n","             error_prob (float): Probability of introducing an error in the test sentences.\n","             seed (int): Random seed for reproducibility.\n","    \"\"\"\n","    def __init__(self,\n","                 test_corpus: list[str],\n","                 spelling_corrector,\n","                 language_model,\n","                 error_prob: float =0.05,\n","                 seed:int = 42,\n","                 beam_width:int = 5):\n","        self.reference_sentences = test_corpus\n","        self.spelling_corrector = spelling_corrector\n","        self.language_model = language_model\n","        self.error_prob = error_prob\n","        self.seed = seed\n","        self.beam_width = beam_width\n","\n","        self.wer_metric = evaluate.load(\"wer\")\n","        self.cer_metric = evaluate.load(\"cer\")\n","\n","    def run(self):\n","        # First generate corrupted versions of the sentences\n","        generator = ArtificialTestDataset(self.reference_sentences, error_prob=self.error_prob, seed=self.seed)\n","        corrupted_sentences = generator.generate()\n","\n","        # Second,  tokenize reference and corrupted sentences\n","        corrupted_tokenized = [nltk.word_tokenize(sentence) for sentence in corrupted_sentences]\n","\n","        # Third, apply correction on the corrupted sentences and show progress bar\n","        corrected_sentences = []\n","        for tokens in tqdm(corrupted_tokenized, desc=\"Correcting Sentences\"):\n","            corrected_tokens = self.spelling_corrector.correct(\n","                self.language_model,\n","                tokens,\n","                beam_width=self.beam_width,  # Beam width passed here\n","                lambda_lm=0.8,\n","                lambda_err=0.2,\n","                skip_oov=True,\n","                verbose=False\n","            )\n","            corrected_sentences.append(\" \".join(corrected_tokens))\n","\n","        # Fourth, evaluate the metrics\n","        wer_score = self.wer_metric.compute(references=self.reference_sentences, predictions=corrected_sentences)\n","        cer_score = self.cer_metric.compute(references=self.reference_sentences, predictions=corrected_sentences)\n","\n","        return wer_score, cer_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Oj7D2ByJjg6","outputId":"0f9220f8-2f7d-4f8b-8577-e114bbaeab56"},"outputs":[{"name":"stderr","output_type":"stream","text":["Correcting Sentences: 100%|██████████| 2000/2000 [4:36:46<00:00,  8.30s/it]    \n"]},{"name":"stdout","output_type":"stream","text":["WER: 0.3352\n","CER: 0.1002\n"]}],"source":["spelling_corrector = ContextAwareSpellingCorrector()\n","\n","# Run the evaluation experiment on a sample of 2000 sentences from the test corpus using the Bigram Model\n","experiment = SpellingCorrectionExperiment(test_corpus[:2000], spelling_corrector, bigram_model)\n","wer, cer = experiment.run()\n","print(f\"WER: {wer:.4f}\")\n","print(f\"CER: {cer:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NgVag8vyJjg7","outputId":"cb8b9c19-3662-4486-e4a5-012c53848dd0"},"outputs":[{"name":"stderr","output_type":"stream","text":["Correcting Sentences: 100%|██████████| 2000/2000 [4:25:58<00:00,  7.98s/it]    \n"]},{"name":"stdout","output_type":"stream","text":["WER: 0.3336\n","CER: 0.0933\n"]}],"source":["# Run the evaluation experiment on a sample of 2000 sentences from the test corpus using Trigram Model\n","experiment = SpellingCorrectionExperiment(test_corpus[:2000], corrector, trigram_model)\n","wer, cer = experiment.run()\n","print(f\"WER: {wer:.4f}\")\n","print(f\"CER: {cer:.4f}\")"]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["CMYn3b3qJjg1","wOcSb0JIJjg1"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
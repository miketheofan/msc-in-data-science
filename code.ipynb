{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfEpHS6hJr-B"
   },
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17023,
     "status": "ok",
     "timestamp": 1744698947523,
     "user": {
      "displayName": "Marios Mantzaris",
      "userId": "03416491895175165913"
     },
     "user_tz": -180
    },
    "id": "2nlFTejCJrr7",
    "outputId": "9f4f7244-7fae-4ece-c586-4e7efe455af9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/michaeltheophanopoulos/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/michaeltheophanopoulos/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/michaeltheophanopoulos/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/michaeltheophanopoulos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from nltk.corpus import reuters\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Tuple, Dict, Set, Callable\n",
    "from tqdm import tqdm\n",
    "from nltk.metrics.distance import edit_distance\n",
    "import heapq\n",
    "import string\n",
    "\n",
    "nltk.download('reuters')\n",
    "nltk.download('brown')\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnoQvXCdJwkx"
   },
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "d92pT_pLJyrZ"
   },
   "outputs": [],
   "source": [
    "# PART 1: N-GRAM LANGUAGE MODEL IMPLEMENTATION\n",
    "# ===========================================\n",
    "\n",
    "class NGramLanguageModel:\n",
    "    def __init__(self, n: int, min_freq: int = 10):\n",
    "        \"\"\"\n",
    "        Initialize an n-gram language model.\n",
    "\n",
    "        Args:\n",
    "            n: The size of n-grams (2 for bigram, 3 for trigram)\n",
    "            min_freq: Minimum frequency to include a word in vocabulary\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "        self.min_freq = min_freq\n",
    "\n",
    "        # Main model components\n",
    "        self.vocabulary = set()  # Words in the vocabulary\n",
    "        self.word_counts = Counter()  # Counts of individual words\n",
    "        self.ngram_counts = defaultdict(Counter)  # Counts of n-grams\n",
    "        self.context_counts = defaultdict(int)  # Counts of (n-1)-grams (contexts)\n",
    "\n",
    "        # Model constants\n",
    "        self.UNK = \"<UNK>\"  # Out-of-vocabulary token\n",
    "        self.END = \"<end>\"  # End of sentence token\n",
    "\n",
    "        # Different start tokens for different n values\n",
    "        if n == 2:\n",
    "            self.START = [\"<start>\"]\n",
    "        elif n == 3:\n",
    "            self.START = [\"<start1>\", \"<start2>\"]\n",
    "        else:\n",
    "            self.START = [f\"<start{i}>\" for i in range(1, n)]\n",
    "\n",
    "        # Statistics\n",
    "        self.total_sentences = 0\n",
    "        self.total_tokens = 0\n",
    "        self.vocabulary_size = 0\n",
    "\n",
    "    def preprocess_text(self, sentences: List[str]) -> List[List[str]]:\n",
    "        \"\"\"\n",
    "        Preprocess raw sentences into tokenized form.\n",
    "\n",
    "        Args:\n",
    "            sentences: List of raw text sentences\n",
    "\n",
    "        Returns:\n",
    "            List of tokenized sentences\n",
    "        \"\"\"\n",
    "        tokenized_sentences = []\n",
    "\n",
    "        for sentence in sentences:\n",
    "            # Clean and tokenize the sentence\n",
    "            clean_sentence = sentence.lower().strip()\n",
    "            tokens = nltk.word_tokenize(clean_sentence)\n",
    "            tokenized_sentences.append(tokens)\n",
    "\n",
    "        return tokenized_sentences\n",
    "\n",
    "    def build_vocabulary(self, tokenized_sentences: List[List[str]]) -> Set[str]:\n",
    "        \"\"\"\n",
    "        Build vocabulary from tokenized sentences based on minimum frequency.\n",
    "\n",
    "        Args:\n",
    "            tokenized_sentences: List of tokenized sentences\n",
    "\n",
    "        Returns:\n",
    "            Set of vocabulary words\n",
    "        \"\"\"\n",
    "        # Count word occurrences\n",
    "        word_counter = Counter()\n",
    "        for sentence in tokenized_sentences:\n",
    "            word_counter.update(sentence)\n",
    "\n",
    "        # Create vocabulary with words that meet minimum frequency\n",
    "        vocabulary = {word for word, count in word_counter.items()\n",
    "                     if count >= self.min_freq}\n",
    "\n",
    "        # # Always add special tokens to vocabulary\n",
    "        vocabulary.add(self.UNK)\n",
    "        vocabulary.add(self.END)\n",
    "        for token in self.START:\n",
    "            vocabulary.add(token)\n",
    "\n",
    "        return vocabulary\n",
    "\n",
    "    def replace_oov_words(self, tokenized_sentences: List[List[str]]) -> List[List[str]]:\n",
    "        \"\"\"\n",
    "        Replace out-of-vocabulary words with UNK token.\n",
    "\n",
    "        Args:\n",
    "            tokenized_sentences: List of tokenized sentences\n",
    "\n",
    "        Returns:\n",
    "            List of tokenized sentences with OOV words replaced\n",
    "        \"\"\"\n",
    "        processed_sentences = []\n",
    "\n",
    "        for sentence in tokenized_sentences:\n",
    "            processed_sentence = []\n",
    "            for token in sentence:\n",
    "                if token in self.vocabulary:\n",
    "                    processed_sentence.append(token)\n",
    "                else:\n",
    "                    processed_sentence.append(self.UNK)\n",
    "            processed_sentences.append(processed_sentence)\n",
    "\n",
    "        return processed_sentences\n",
    "\n",
    "    def extract_ngrams(self, tokenized_sentences: List[List[str]]) -> None:\n",
    "        \"\"\"\n",
    "        Extract n-grams from tokenized sentences and count their occurrences.\n",
    "\n",
    "        Args:\n",
    "            tokenized_sentences: List of tokenized sentences with OOV words replaced\n",
    "        \"\"\"\n",
    "        for sentence in tokenized_sentences:\n",
    "            # Add start and end tokens\n",
    "            augmented_sentence = self.START + sentence + [self.END]\n",
    "            self.total_tokens += len(sentence) + 1  # +1 for END token\n",
    "\n",
    "            # Count individual words (unigrams)\n",
    "            self.word_counts.update(augmented_sentence)\n",
    "\n",
    "            # Extract and count n-grams\n",
    "            for i in range(len(augmented_sentence) - self.n + 1):\n",
    "                ngram = tuple(augmented_sentence[i:i + self.n])\n",
    "                prefix = ngram[:-1]  # Context (n-1 gram)\n",
    "                word = ngram[-1]     # Word being predicted\n",
    "\n",
    "                self.ngram_counts[prefix][word] += 1\n",
    "                self.context_counts[prefix] += 1\n",
    "\n",
    "    def train(self, corpus: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Train the n-gram language model on the provided corpus.\n",
    "\n",
    "        Args:\n",
    "            corpus: List of sentences\n",
    "        \"\"\"\n",
    "        self.total_sentences = len(corpus)\n",
    "        print(f\"Training {self.n}-gram model on {self.total_sentences} sentences...\")\n",
    "\n",
    "        # Preprocess the corpus\n",
    "        tokenized_sentences = self.preprocess_text(corpus)\n",
    "\n",
    "        # Build vocabulary\n",
    "        self.vocabulary = self.build_vocabulary(tokenized_sentences)\n",
    "        self.vocabulary_size = len(self.vocabulary)\n",
    "        print(f\"Vocabulary size: {self.vocabulary_size} words\")\n",
    "\n",
    "        # Replace OOV words\n",
    "        processed_sentences = self.replace_oov_words(tokenized_sentences)\n",
    "\n",
    "        # Extract n-grams\n",
    "        self.extract_ngrams(processed_sentences)\n",
    "\n",
    "        print(f\"Extracted {sum(len(counts) for counts in self.ngram_counts.values())} unique {self.n}-grams\")\n",
    "        print(f\"Total tokens in corpus: {self.total_tokens}\")\n",
    "\n",
    "    def get_laplace_probability(self, word: str, context: tuple) -> float:\n",
    "        \"\"\"\n",
    "        Calculate Laplace-smoothed probability P(word|context).\n",
    "\n",
    "        Args:\n",
    "            word: The word to calculate probability for\n",
    "            context: The preceding (n-1) words\n",
    "\n",
    "        Returns:\n",
    "            The conditional probability P(word|context)\n",
    "        \"\"\"\n",
    "        # Get counts with Laplace smoothing\n",
    "        count_ngram = self.ngram_counts[context][word]\n",
    "        count_context = self.context_counts[context]\n",
    "\n",
    "        # Apply Laplace smoothing (+1 to numerator, +V to denominator)\n",
    "        probability = (count_ngram + 1) / (count_context + self.vocabulary_size)\n",
    "\n",
    "        return probability\n",
    "\n",
    "    def get_log_probability(self, word: str, context: tuple) -> float:\n",
    "        \"\"\"\n",
    "        Calculate log probability log(P(word|context)).\n",
    "\n",
    "        Args:\n",
    "            word: The word to calculate probability for\n",
    "            context: The preceding (n-1) words\n",
    "\n",
    "        Returns:\n",
    "            The log probability log(P(word|context))\n",
    "        \"\"\"\n",
    "        probability = self.get_laplace_probability(word, context)\n",
    "        return math.log2(probability)\n",
    "\n",
    "    def get_sentence_log_probability(self, sentence: List[str]) -> float:\n",
    "        \"\"\"\n",
    "        Calculate the log probability of a sentence.\n",
    "\n",
    "        Args:\n",
    "            sentence: List of tokens in the sentence\n",
    "\n",
    "        Returns:\n",
    "            The log probability of the sentence\n",
    "        \"\"\"\n",
    "        # Replace OOV words with UNK\n",
    "        processed_sentence = [token if token in self.vocabulary else self.UNK for token in sentence]\n",
    "\n",
    "        # Add start and end tokens\n",
    "        augmented_sentence = self.START + processed_sentence + [self.END]\n",
    "\n",
    "        log_prob = 0.0\n",
    "\n",
    "        # Calculate log probability for each word given its context\n",
    "        for i in range(len(self.START), len(augmented_sentence)):\n",
    "            word = augmented_sentence[i]\n",
    "            context = tuple(augmented_sentence[i - self.n + 1:i])\n",
    "\n",
    "            log_prob += self.get_log_probability(word, context)\n",
    "\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6tEY9p9J2Vr"
   },
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "8ZGOfJ8XJ386"
   },
   "outputs": [],
   "source": [
    "# PART 2: CROSS-ENTROPY AND PERPLEXITY EVALUATION\n",
    "# ==============================================\n",
    "\n",
    "def calculate_cross_entropy(model: NGramLanguageModel, test_corpus: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate cross-entropy of a language model on a test corpus.\n",
    "\n",
    "    Args:\n",
    "        model: Trained language model\n",
    "        test_corpus: List of test sentences\n",
    "\n",
    "    Returns:\n",
    "        Cross-entropy value\n",
    "    \"\"\"\n",
    "    # Preprocess test corpus\n",
    "    tokenized_sentences = model.preprocess_text(test_corpus)\n",
    "\n",
    "    # Replace OOV words\n",
    "    processed_sentences = model.replace_oov_words(tokenized_sentences)\n",
    "\n",
    "    total_log_prob = 0.0\n",
    "    total_tokens = 0\n",
    "\n",
    "    # Calculate log probability for each sentence\n",
    "    for sentence in processed_sentences:\n",
    "        # We count end tokens but not start tokens in the total length\n",
    "        total_tokens += len(sentence) + 1  # +1 for END token\n",
    "\n",
    "        # Add start and end tokens\n",
    "        augmented_sentence = model.START + sentence + [model.END]\n",
    "\n",
    "        # Sum log probabilities for each word given its context\n",
    "        for i in range(len(model.START), len(augmented_sentence)):\n",
    "            word = augmented_sentence[i]\n",
    "            context = tuple(augmented_sentence[i - model.n + 1:i])\n",
    "\n",
    "            # Get log probability\n",
    "            log_prob = model.get_log_probability(word, context)\n",
    "            total_log_prob += log_prob\n",
    "\n",
    "    # Calculate cross-entropy\n",
    "    cross_entropy = -total_log_prob / total_tokens\n",
    "\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "U9XFeldBJ4DD"
   },
   "outputs": [],
   "source": [
    "def calculate_perplexity(cross_entropy: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate perplexity from cross-entropy.\n",
    "\n",
    "    Args:\n",
    "        cross_entropy: Cross-entropy value\n",
    "\n",
    "    Returns:\n",
    "        Perplexity value\n",
    "    \"\"\"\n",
    "    return 2 ** cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjjrSzAMJ7Ej"
   },
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "S_iamUVrJ4Fh"
   },
   "outputs": [],
   "source": [
    "def generate_text(model: NGramLanguageModel,\n",
    "                 prompt: List[str],\n",
    "                 max_length: int = 20,\n",
    "                 method: str = \"greedy\",\n",
    "                 top_k: int = 5,\n",
    "                 temperature: float = 1.0) -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate text continuation based on the prompt.\n",
    "\n",
    "    Args:\n",
    "        model: Trained language model\n",
    "        prompt: Initial words to continue from\n",
    "        max_length: Maximum length of the generated sequence\n",
    "        method: Generation method - \"greedy\", \"topk\", or \"nucleus\"\n",
    "        top_k: Number of top candidates to consider for sampling\n",
    "        temperature: Controls randomness (higher = more random)\n",
    "\n",
    "    Returns:\n",
    "        List of words completing the prompt\n",
    "    \"\"\"\n",
    "    # Process the prompt\n",
    "    processed_prompt = [word if word in model.vocabulary else model.UNK for word in prompt]\n",
    "\n",
    "    # Initialize with start tokens + prompt\n",
    "    generated_text = model.START + processed_prompt\n",
    "\n",
    "    # Generate text until we reach max_length or end token\n",
    "    for _ in range(max_length):\n",
    "        # Get the most recent (n-1) words as context\n",
    "        context = tuple(generated_text[-(model.n - 1):])\n",
    "\n",
    "        # Get next word based on the specified method\n",
    "        if method == \"greedy\":\n",
    "            next_word = get_next_word_greedy(model, context)\n",
    "        elif method == \"topk\":\n",
    "            next_word = get_next_word_topk(model, context, top_k, temperature)\n",
    "        elif method == \"nucleus\":\n",
    "            next_word = get_next_word_nucleus(model, context, p=0.9, temperature=temperature)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown generation method: {method}\")\n",
    "\n",
    "        # Add the generated word to the sequence\n",
    "        generated_text.append(next_word)\n",
    "\n",
    "        # Stop if we generated the end token\n",
    "        if next_word == model.END:\n",
    "            break\n",
    "\n",
    "    # Return only the newly generated part (excluding start tokens and prompt)\n",
    "    return generated_text[len(model.START) + len(processed_prompt):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "T_XE7epLJ4H0"
   },
   "outputs": [],
   "source": [
    "def get_next_word_greedy(model: NGramLanguageModel, context: tuple) -> str:\n",
    "    \"\"\"\n",
    "    Get the most probable next word given the context.\n",
    "\n",
    "    Args:\n",
    "        model: Trained language model\n",
    "        context: Current context ((n-1) preceding words)\n",
    "\n",
    "    Returns:\n",
    "        Most probable next word\n",
    "    \"\"\"\n",
    "    # Get probabilities for all words in the vocabulary\n",
    "    candidates = {}\n",
    "\n",
    "    for word in model.vocabulary:\n",
    "        # Skip UNK token for generation\n",
    "        if word == model.UNK:\n",
    "            continue\n",
    "\n",
    "        prob = model.get_laplace_probability(word, context)\n",
    "        candidates[word] = prob\n",
    "\n",
    "    # Return the word with the highest probability\n",
    "    return max(candidates.items(), key=lambda x: x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "GPNhm9RaJ-8S"
   },
   "outputs": [],
   "source": [
    "def get_next_word_topk(model: NGramLanguageModel,\n",
    "                      context: tuple,\n",
    "                      k: int = 5,\n",
    "                      temperature: float = 1.0) -> str:\n",
    "    \"\"\"\n",
    "    Sample next word from top-k most probable words.\n",
    "\n",
    "    Args:\n",
    "        model: Trained language model\n",
    "        context: Current context ((n-1) preceding words)\n",
    "        k: Number of top candidates to consider\n",
    "        temperature: Controls randomness (higher = more random)\n",
    "\n",
    "    Returns:\n",
    "        Sampled next word\n",
    "    \"\"\"\n",
    "    # Get probabilities for all words in the vocabulary\n",
    "    candidates = {}\n",
    "\n",
    "    for word in model.vocabulary:\n",
    "        # Skip UNK token for generation\n",
    "        if word == model.UNK:\n",
    "            continue\n",
    "\n",
    "        prob = model.get_laplace_probability(word, context)\n",
    "        candidates[word] = prob\n",
    "\n",
    "    # Get top-k candidates\n",
    "    top_candidates = sorted(candidates.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "    # Apply temperature scaling\n",
    "    if temperature != 1.0:\n",
    "        probs = np.array([prob for _, prob in top_candidates])\n",
    "        probs = np.power(probs, 1.0 / temperature)\n",
    "        probs = probs / np.sum(probs)\n",
    "    else:\n",
    "        probs = np.array([prob for _, prob in top_candidates])\n",
    "        probs = probs / np.sum(probs)\n",
    "\n",
    "    # Sample from the distribution\n",
    "    words = [word for word, _ in top_candidates]\n",
    "    next_word = np.random.choice(words, p=probs)\n",
    "\n",
    "    return next_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "b3gAhyEjJ-_C"
   },
   "outputs": [],
   "source": [
    "def get_next_word_nucleus(model: NGramLanguageModel,\n",
    "                         context: tuple,\n",
    "                         p: float = 0.9,\n",
    "                         temperature: float = 1.0) -> str:\n",
    "    \"\"\"\n",
    "    Nucleus (top-p) sampling for next word prediction.\n",
    "\n",
    "    Args:\n",
    "        model: Trained language model\n",
    "        context: Current context ((n-1) preceding words)\n",
    "        p: Cumulative probability threshold\n",
    "        temperature: Controls randomness (higher = more random)\n",
    "\n",
    "    Returns:\n",
    "        Sampled next word\n",
    "    \"\"\"\n",
    "    # Get probabilities for all words in the vocabulary\n",
    "    candidates = {}\n",
    "\n",
    "    for word in model.vocabulary:\n",
    "        # Skip UNK token for generation\n",
    "        if word == model.UNK:\n",
    "            continue\n",
    "\n",
    "        prob = model.get_laplace_probability(word, context)\n",
    "        candidates[word] = prob\n",
    "\n",
    "    # Sort candidates by probability\n",
    "    sorted_candidates = sorted(candidates.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Apply temperature scaling\n",
    "    if temperature != 1.0:\n",
    "        probs = np.array([prob for _, prob in sorted_candidates])\n",
    "        probs = np.power(probs, 1.0 / temperature)\n",
    "        probs = probs / np.sum(probs)\n",
    "    else:\n",
    "        probs = np.array([prob for _, prob in sorted_candidates])\n",
    "        probs = probs / np.sum(probs)\n",
    "\n",
    "    # Calculate cumulative probabilities\n",
    "    cumulative_probs = np.cumsum(probs)\n",
    "\n",
    "    # Find smallest set of words with cumulative probability >= p\n",
    "    cutoff_idx = np.where(cumulative_probs >= p)[0][0] + 1\n",
    "\n",
    "    # Select only those candidates\n",
    "    top_p_candidates = sorted_candidates[:cutoff_idx]\n",
    "\n",
    "    # Re-normalize probabilities\n",
    "    top_p_probs = np.array([prob for _, prob in top_p_candidates])\n",
    "    top_p_probs = top_p_probs / np.sum(top_p_probs)\n",
    "\n",
    "    # Sample from the distribution\n",
    "    words = [word for word, _ in top_p_candidates]\n",
    "    next_word = np.random.choice(words, p=top_p_probs)\n",
    "\n",
    "    return next_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "s2cTq7csKA2b"
   },
   "outputs": [],
   "source": [
    "def beam_search(model: NGramLanguageModel,\n",
    "               prompt: List[str],\n",
    "               beam_width: int = 5,\n",
    "               max_length: int = 20) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Beam search for text generation.\n",
    "\n",
    "    Args:\n",
    "        model: Trained language model\n",
    "        prompt: Initial words to continue from\n",
    "        beam_width: Beam width\n",
    "        max_length: Maximum length of the generated sequence\n",
    "\n",
    "    Returns:\n",
    "        List of generated sequences (beams)\n",
    "    \"\"\"\n",
    "    # Process the prompt\n",
    "    processed_prompt = [word if word in model.vocabulary else model.UNK for word in prompt]\n",
    "\n",
    "    # Initialize beams with start tokens + prompt\n",
    "    initial_sequence = model.START + processed_prompt\n",
    "    beams = [(initial_sequence, 0.0)]  # (sequence, log_prob)\n",
    "\n",
    "    # Generate for max_length steps\n",
    "    for _ in range(max_length):\n",
    "        new_beams = []\n",
    "\n",
    "        # Expand each beam\n",
    "        for sequence, score in beams:\n",
    "            # If the sequence ended, keep it as is\n",
    "            if sequence[-1] == model.END:\n",
    "                new_beams.append((sequence, score))\n",
    "                continue\n",
    "\n",
    "            # Get context\n",
    "            context = tuple(sequence[-(model.n - 1):])\n",
    "\n",
    "            # Calculate probabilities for all possible next words\n",
    "            candidates = {}\n",
    "            for word in model.vocabulary:\n",
    "                # Skip UNK token for generation\n",
    "                if word == model.UNK:\n",
    "                    continue\n",
    "\n",
    "                log_prob = model.get_log_probability(word, context)\n",
    "                candidates[word] = log_prob\n",
    "\n",
    "            # Get top candidates\n",
    "            top_candidates = sorted(candidates.items(), key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "\n",
    "            # Create new beams with expanded sequences\n",
    "            for word, log_prob in top_candidates:\n",
    "                new_sequence = sequence + [word]\n",
    "                new_score = score + log_prob\n",
    "                new_beams.append((new_sequence, new_score))\n",
    "\n",
    "        # Select top beams\n",
    "        beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "\n",
    "        # Check if all beams have ended\n",
    "        if all(sequence[-1] == model.END for sequence, _ in beams):\n",
    "            break\n",
    "\n",
    "    # Return only the newly generated parts (excluding start tokens and prompt)\n",
    "    start_len = len(model.START) + len(processed_prompt)\n",
    "    return [sequence[start_len:] for sequence, _ in beams]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob(p: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute log-probability with safe handling for zero.\n",
    "\n",
    "    Args:\n",
    "        p: A probability value\n",
    "\n",
    "    Returns:\n",
    "        Natural log of p, or -inf if p is 0\n",
    "    \"\"\"\n",
    "    return math.log(p) if p > 0 else float('-inf')\n",
    "\n",
    "\n",
    "def softmax(scores):\n",
    "    \"\"\"\n",
    "    Compute softmax over a list of scores.\n",
    "\n",
    "    Args:\n",
    "        scores: List of float scores\n",
    "\n",
    "    Returns:\n",
    "        List of normalized probabilities\n",
    "    \"\"\"\n",
    "    exp_scores = [math.exp(s - max(scores)) for s in scores]\n",
    "    total = sum(exp_scores)\n",
    "    return [e / total for e in exp_scores]\n",
    "\n",
    "\n",
    "def calculate_lm_score(candidate: str, context: Tuple[str, ...], model: NGramLanguageModel) -> float:\n",
    "    \"\"\"\n",
    "    Get the language model log-probability of a candidate given context.\n",
    "\n",
    "    Args:\n",
    "        candidate: Word to score\n",
    "        context: Tuple of previous words\n",
    "        model: Trained N-gram language model\n",
    "\n",
    "    Returns:\n",
    "        Log-probability of candidate given context\n",
    "    \"\"\"\n",
    "    return model.get_log_probability(candidate, context)\n",
    "\n",
    "\n",
    "def calculate_error_score(noisy_token: str, candidate: str) -> float:\n",
    "    \"\"\"\n",
    "    Compute the log-probability of a candidate based on its edit distance.\n",
    "\n",
    "    Args:\n",
    "        noisy_token: Original word\n",
    "        candidate: Possible correction\n",
    "\n",
    "    Returns:\n",
    "        Log-probability based on inverse edit distance\n",
    "    \"\"\"\n",
    "    edit_dist = nltk.edit_distance(noisy_token, candidate)\n",
    "    return log_prob(1 / (edit_dist + 1))\n",
    "\n",
    "\n",
    "def combine_scores(lm_score: float, error_score: float, lambda_lm: float = 0.8, lambda_err: float = 0.2) -> float:\n",
    "    \"\"\"\n",
    "    Combine language model and error model scores using weighted sum.\n",
    "\n",
    "    Args:\n",
    "        lm_score: Log-probability from language model\n",
    "        error_score: Log-probability from error model\n",
    "        lambda_lm: Weight for language model\n",
    "        lambda_err: Weight for error model\n",
    "\n",
    "    Returns:\n",
    "        Combined score\n",
    "    \"\"\"\n",
    "    return lambda_lm * lm_score + lambda_err * error_score\n",
    "\n",
    "\n",
    "def generate_candidates(\n",
    "    noisy_token: str,\n",
    "    vocabulary: Set[str],\n",
    "    max_edit_distance: int = 2,\n",
    "    skip_oov: bool = True\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate candidate corrections within a max edit distance.\n",
    "\n",
    "    Args:\n",
    "        noisy_token: Token to correct\n",
    "        vocabulary: Set of known words\n",
    "        max_edit_distance: Max allowed edit distance\n",
    "        skip_oov: If True, return token if it’s in vocabulary\n",
    "\n",
    "    Returns:\n",
    "        List of candidate words\n",
    "    \"\"\"\n",
    "    if skip_oov and noisy_token in vocabulary:\n",
    "        return [noisy_token]\n",
    "\n",
    "    candidates = []\n",
    "    for word in vocabulary:\n",
    "        if word == \"<UNK>\":\n",
    "            continue\n",
    "        if nltk.edit_distance(noisy_token, word) <= max_edit_distance:\n",
    "            candidates.append(word)\n",
    "    return candidates or [noisy_token]\n",
    "\n",
    "def beam_search_step(\n",
    "    beams: List[Tuple[List[str], float]],\n",
    "    noisy_token: str,\n",
    "    model: NGramLanguageModel,\n",
    "    vocabulary: Set[str],\n",
    "    beam_width: int = 5,\n",
    "    lambda_lm: float = 0.8,\n",
    "    lambda_err: float = 0.2,\n",
    "    max_edit_distance: int = 2,\n",
    "    skip_oov: bool = True\n",
    ") -> List[Tuple[List[str], float]]:\n",
    "    \"\"\"\n",
    "    Expand beam sequences with possible corrections for the next token.\n",
    "\n",
    "    Args:\n",
    "        beams: List of (sequence, score) pairs\n",
    "        noisy_token: Token to correct\n",
    "        model: N-gram language model\n",
    "        vocabulary: Set of valid words\n",
    "        beam_width: Max beams to keep\n",
    "        lambda_lm: LM score weight\n",
    "        lambda_err: Error score weight\n",
    "        max_edit_distance: Edit distance threshold\n",
    "        skip_oov: If True, use original token if in vocab\n",
    "\n",
    "    Returns:\n",
    "        Updated list of top-k beams\n",
    "    \"\"\"\n",
    "    new_beams = []\n",
    "\n",
    "    for sequence, score in beams:\n",
    "        context = tuple(sequence[-(model.n - 1):])\n",
    "        candidates = generate_candidates(noisy_token, vocabulary, max_edit_distance, skip_oov)\n",
    "\n",
    "        print(f\"Token: '{noisy_token}' | Context: {context}\")\n",
    "        print(\"Candidate scores:\")\n",
    "        for candidate in candidates:\n",
    "            lm_score = calculate_lm_score(candidate, context, model)\n",
    "            err_score = calculate_error_score(noisy_token, candidate)\n",
    "            total_score = combine_scores(lm_score, err_score, lambda_lm, lambda_err)\n",
    "            print(f\"  {candidate:<12} | LM: {lm_score:+8.4f} | Error: {err_score:+8.4f} | Combined: {total_score:+8.4f}\")\n",
    "\n",
    "            new_sequence = sequence + [candidate]\n",
    "            new_score = score + total_score\n",
    "            new_beams.append((new_sequence, new_score))\n",
    "\n",
    "    if not new_beams:\n",
    "        print(f\"Warning: No valid candidates for '{noisy_token}'. Using fallback.\")\n",
    "        for sequence, score in beams:\n",
    "            new_sequence = sequence + [noisy_token]\n",
    "        new_beams.append((new_sequence, score))\n",
    "\n",
    "    top_beams = heapq.nlargest(beam_width, new_beams, key=lambda x: x[1])\n",
    "    top_tokens = [beam[0][-1] for beam in top_beams]\n",
    "    print(f\"Top selected tokens: {top_tokens}\\n\")\n",
    "\n",
    "    return top_beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_aware_spelling_corrector(\n",
    "    model,\n",
    "    noisy_sentence: List[str],\n",
    "    beam_width: int = 5,\n",
    "    lambda_lm: float = 0.8,\n",
    "    lambda_err: float = 0.2,\n",
    "    max_edit_distance: int = 2,\n",
    "    skip_oov: bool = True,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Perform context-aware spelling correction on a noisy sentence using beam search.\n",
    "\n",
    "    Args:\n",
    "        model: Trained N-gram language model with .START and .vocabulary\n",
    "        noisy_sentence: List of potentially misspelled tokens\n",
    "        beam_width: Number of sequences to keep per step\n",
    "        lambda_lm: Weight for the language model score\n",
    "        lambda_err: Weight for the error model score\n",
    "        max_edit_distance: Max edit distance for generating candidates\n",
    "        skip_oov: If True, preserve in-vocabulary words\n",
    "\n",
    "    Returns:\n",
    "        A list of corrected tokens\n",
    "    \"\"\"\n",
    "    print(f\"Starting correction for sentence: {' '.join(noisy_sentence)}\")\n",
    "    beams = [(model.START, 0.0)]\n",
    "    for noisy_token in noisy_sentence:\n",
    "        beams = beam_search_step(\n",
    "            beams, noisy_token, model, model.vocabulary,\n",
    "            beam_width, lambda_lm, lambda_err, max_edit_distance, skip_oov\n",
    "        )\n",
    "    best_sequence = max(beams, key=lambda x: x[1])[0]\n",
    "    corrected = best_sequence[len(model.START):]\n",
    "    print(f\"Final corrected sentence: {' '.join(corrected)}\")\n",
    "    return corrected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading brown corpus...\n",
      "Corpus split: 39621 train, 8490 validation, 8491 test sentences\n",
      "Training 2-gram model on 39621 sentences...\n",
      "Vocabulary size: 6637 words\n",
      "Extracted 209440 unique 2-grams\n",
      "Total tokens in corpus: 859931\n",
      "Training 3-gram model on 39621 sentences...\n",
      "Vocabulary size: 6638 words\n",
      "Extracted 519364 unique 3-grams\n",
      "Total tokens in corpus: 859931\n"
     ]
    }
   ],
   "source": [
    "train_corpus, val_corpus, test_corpus = load_and_split_corpus(corpus_name='brown')\n",
    "\n",
    "# Initialize and train models\n",
    "bigram_model = NGramLanguageModel(n=2, min_freq=10)\n",
    "bigram_model.train(train_corpus)\n",
    "\n",
    "trigram_model = NGramLanguageModel(n=3, min_freq=10)\n",
    "trigram_model.train(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with sentence: \"let us sey we are friendz\"\n",
      "Starting correction for sentence: let us sey we are friendz\n",
      "Token: 'let' | Context: ('<start>',)\n",
      "Candidate scores:\n",
      "  let          | LM:  -9.6148 | Error:  +0.0000 | Combined:  -9.1340\n",
      "Top selected tokens: ['let']\n",
      "\n",
      "Token: 'us' | Context: ('let',)\n",
      "Candidate scores:\n",
      "  us           | LM:  -7.3349 | Error:  +0.0000 | Combined:  -6.9681\n",
      "Top selected tokens: ['us']\n",
      "\n",
      "Token: 'sey' | Context: ('us',)\n",
      "Candidate scores:\n",
      "  sad          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  so           | LM: -11.7922 | Error:  -1.0986 | Combined: -11.2575\n",
      "  keys         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sera         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  why          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  fee          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  s            | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  ed           | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sin          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  amy          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sky          | LM: -12.7922 | Error:  -0.6931 | Combined: -12.1872\n",
      "  led          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  e.           | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sam          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  fly          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  lee          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  le           | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  fed          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  seed         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  jet          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  day          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  st.          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  seek         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  set          | LM: -12.7922 | Error:  -0.6931 | Combined: -12.1872\n",
      "  sent         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sex          | LM: -12.7922 | Error:  -0.6931 | Combined: -12.1872\n",
      "  seal         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  seem         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  used         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  see          | LM: -11.2072 | Error:  -0.6931 | Combined: -10.6815\n",
      "  boy          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  guy          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  my           | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  leg          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  they         | LM: -11.7922 | Error:  -1.0986 | Combined: -11.2575\n",
      "  el           | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  roy          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  shu          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sell         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  we           | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  s.           | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  way          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  says         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  seat         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  et           | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  bay          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  buy          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  saw          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  stay         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  few          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  let          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  new          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  rev          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sox          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  try          | LM: -11.7922 | Error:  -1.0986 | Combined: -11.2575\n",
      "  hen          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  casey        | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  san          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  pay          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  yet          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  seen         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  wet          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  may          | LM: -11.7922 | Error:  -1.0986 | Combined: -11.2575\n",
      "  hey          | LM: -12.7922 | Error:  -0.6931 | Combined: -12.1872\n",
      "  she          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sun          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sat          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sees         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  joy          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  bed          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  her          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  pen          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  met          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  grey         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  send         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  ben          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  be           | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  ten          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sen.         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sit          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  tea          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  self         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  ray          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sba          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  bet          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  get          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sets         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  very         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sir          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  step         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  dry          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  stem         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  yes          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  men          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  hay          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  per          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  eye          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  deny         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  say          | LM: -10.7922 | Error:  -0.6931 | Combined: -10.2872\n",
      "  key          | LM: -12.7922 | Error:  -0.6931 | Combined: -12.1872\n",
      "  net          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  lay          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  thy          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  ken          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  'em          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  any          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sec          | LM: -12.7922 | Error:  -0.6931 | Combined: -12.1872\n",
      "  e            | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sea          | LM: -12.7922 | Error:  -0.6931 | Combined: -12.1872\n",
      "  me           | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  six          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sum          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  red          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  kay          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  cry          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  ye           | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  gay          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  jew          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  son          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  he           | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  by           | LM: -10.2072 | Error:  -1.0986 | Combined:  -9.7518\n",
      "  uses         | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  use          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  de           | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  zen          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  sue          | LM: -12.7922 | Error:  -1.0986 | Combined: -12.2075\n",
      "  shy          | LM: -12.7922 | Error:  -0.6931 | Combined: -12.1872\n",
      "Top selected tokens: ['by', 'say', 'see', 'so', 'they']\n",
      "\n",
      "Token: 'we' | Context: ('by',)\n",
      "Candidate scores:\n",
      "  we           | LM: -13.3435 | Error:  +0.0000 | Combined: -12.6763\n",
      "Token: 'we' | Context: ('say',)\n",
      "Candidate scores:\n",
      "  we           | LM: -11.7719 | Error:  +0.0000 | Combined: -11.1833\n",
      "Token: 'we' | Context: ('see',)\n",
      "Candidate scores:\n",
      "  we           | LM: -12.8090 | Error:  +0.0000 | Combined: -12.1685\n",
      "Token: 'we' | Context: ('so',)\n",
      "Candidate scores:\n",
      "  we           | LM:  -8.9748 | Error:  +0.0000 | Combined:  -8.5260\n",
      "Token: 'we' | Context: ('they',)\n",
      "Candidate scores:\n",
      "  we           | LM: -13.1751 | Error:  +0.0000 | Combined: -12.5163\n",
      "Top selected tokens: ['we', 'we', 'we', 'we', 'we']\n",
      "\n",
      "Token: 'are' | Context: ('we',)\n",
      "Candidate scores:\n",
      "  are          | LM:  -5.7978 | Error:  +0.0000 | Combined:  -5.5080\n",
      "Token: 'are' | Context: ('we',)\n",
      "Candidate scores:\n",
      "  are          | LM:  -5.7978 | Error:  +0.0000 | Combined:  -5.5080\n",
      "Token: 'are' | Context: ('we',)\n",
      "Candidate scores:\n",
      "  are          | LM:  -5.7978 | Error:  +0.0000 | Combined:  -5.5080\n",
      "Token: 'are' | Context: ('we',)\n",
      "Candidate scores:\n",
      "  are          | LM:  -5.7978 | Error:  +0.0000 | Combined:  -5.5080\n",
      "Token: 'are' | Context: ('we',)\n",
      "Candidate scores:\n",
      "  are          | LM:  -5.7978 | Error:  +0.0000 | Combined:  -5.5080\n",
      "Top selected tokens: ['are', 'are', 'are', 'are', 'are']\n",
      "\n",
      "Token: 'friendz' | Context: ('are',)\n",
      "Candidate scores:\n",
      "  friend       | LM: -13.2524 | Error:  -0.6931 | Combined: -12.6244\n",
      "  friendly     | LM: -13.2524 | Error:  -1.0986 | Combined: -12.6447\n",
      "  friends      | LM: -13.2524 | Error:  -0.6931 | Combined: -12.6244\n",
      "Token: 'friendz' | Context: ('are',)\n",
      "Candidate scores:\n",
      "  friend       | LM: -13.2524 | Error:  -0.6931 | Combined: -12.6244\n",
      "  friendly     | LM: -13.2524 | Error:  -1.0986 | Combined: -12.6447\n",
      "  friends      | LM: -13.2524 | Error:  -0.6931 | Combined: -12.6244\n",
      "Token: 'friendz' | Context: ('are',)\n",
      "Candidate scores:\n",
      "  friend       | LM: -13.2524 | Error:  -0.6931 | Combined: -12.6244\n",
      "  friendly     | LM: -13.2524 | Error:  -1.0986 | Combined: -12.6447\n",
      "  friends      | LM: -13.2524 | Error:  -0.6931 | Combined: -12.6244\n",
      "Token: 'friendz' | Context: ('are',)\n",
      "Candidate scores:\n",
      "  friend       | LM: -13.2524 | Error:  -0.6931 | Combined: -12.6244\n",
      "  friendly     | LM: -13.2524 | Error:  -1.0986 | Combined: -12.6447\n",
      "  friends      | LM: -13.2524 | Error:  -0.6931 | Combined: -12.6244\n",
      "Token: 'friendz' | Context: ('are',)\n",
      "Candidate scores:\n",
      "  friend       | LM: -13.2524 | Error:  -0.6931 | Combined: -12.6244\n",
      "  friendly     | LM: -13.2524 | Error:  -1.0986 | Combined: -12.6447\n",
      "  friends      | LM: -13.2524 | Error:  -0.6931 | Combined: -12.6244\n",
      "Top selected tokens: ['friend', 'friends', 'friendly', 'friend', 'friends']\n",
      "\n",
      "Final corrected sentence: let us so we are friend\n",
      "Bigram model produced:\n",
      "  let us so we are friend\n",
      "\n",
      "Testing with sentence: \"in consequencaae of her sistero's marriange, been moistress of hois house from a vry early period\"\n",
      "Starting correction for sentence: in consequencaae of her sistero 's marriange , been moistress of hois house from a vry early period\n",
      "Token: 'in' | Context: ('<start>',)\n",
      "Candidate scores:\n",
      "  in           | LM:  -5.2626 | Error:  +0.0000 | Combined:  -4.9995\n",
      "Top selected tokens: ['in']\n",
      "\n",
      "Token: 'consequencaae' | Context: ('in',)\n",
      "Candidate scores:\n",
      "  consequence  | LM: -12.8067 | Error:  -1.0986 | Combined: -12.2213\n",
      "Top selected tokens: ['consequence']\n",
      "\n",
      "Token: 'of' | Context: ('consequence',)\n",
      "Candidate scores:\n",
      "  of           | LM:  -9.1157 | Error:  +0.0000 | Combined:  -8.6599\n",
      "Top selected tokens: ['of']\n",
      "\n",
      "Token: 'her' | Context: ('of',)\n",
      "Candidate scores:\n",
      "  her          | LM:  -7.5834 | Error:  +0.0000 | Combined:  -7.2042\n",
      "Top selected tokens: ['her']\n",
      "\n",
      "Token: 'sistero' | Context: ('her',)\n",
      "Candidate scores:\n",
      "  sister       | LM: -12.0970 | Error:  -0.6931 | Combined: -11.5268\n",
      "  sitter       | LM: -13.0970 | Error:  -1.0986 | Combined: -12.4971\n",
      "Top selected tokens: ['sister', 'sitter']\n",
      "\n",
      "Token: ''s' | Context: ('sister',)\n",
      "Candidate scores:\n",
      "  's           | LM: -11.1174 | Error:  +0.0000 | Combined: -10.5616\n",
      "Token: ''s' | Context: ('sitter',)\n",
      "Candidate scores:\n",
      "  's           | LM: -11.7004 | Error:  +0.0000 | Combined: -11.1154\n",
      "Top selected tokens: [\"'s\", \"'s\"]\n",
      "\n",
      "Token: 'marriange' | Context: (\"'s\",)\n",
      "Candidate scores:\n",
      "  marriages    | LM: -13.3807 | Error:  -1.0986 | Combined: -12.7666\n",
      "  marriage     | LM: -13.3807 | Error:  -0.6931 | Combined: -12.7464\n",
      "Token: 'marriange' | Context: (\"'s\",)\n",
      "Candidate scores:\n",
      "  marriages    | LM: -13.3807 | Error:  -1.0986 | Combined: -12.7666\n",
      "  marriage     | LM: -13.3807 | Error:  -0.6931 | Combined: -12.7464\n",
      "Top selected tokens: ['marriage', 'marriages', 'marriage', 'marriages']\n",
      "\n",
      "Token: ',' | Context: ('marriage',)\n",
      "Candidate scores:\n",
      "  ,            | LM:  -9.7104 | Error:  +0.0000 | Combined:  -9.2249\n",
      "Token: ',' | Context: ('marriages',)\n",
      "Candidate scores:\n",
      "  ,            | LM:  -9.8927 | Error:  +0.0000 | Combined:  -9.3980\n",
      "Token: ',' | Context: ('marriage',)\n",
      "Candidate scores:\n",
      "  ,            | LM:  -9.7104 | Error:  +0.0000 | Combined:  -9.2249\n",
      "Token: ',' | Context: ('marriages',)\n",
      "Candidate scores:\n",
      "  ,            | LM:  -9.8927 | Error:  +0.0000 | Combined:  -9.3980\n",
      "Top selected tokens: [',', ',', ',', ',']\n",
      "\n",
      "Token: 'been' | Context: (',',)\n",
      "Candidate scores:\n",
      "  been         | LM: -12.3597 | Error:  +0.0000 | Combined: -11.7418\n",
      "Token: 'been' | Context: (',',)\n",
      "Candidate scores:\n",
      "  been         | LM: -12.3597 | Error:  +0.0000 | Combined: -11.7418\n",
      "Token: 'been' | Context: (',',)\n",
      "Candidate scores:\n",
      "  been         | LM: -12.3597 | Error:  +0.0000 | Combined: -11.7418\n",
      "Token: 'been' | Context: (',',)\n",
      "Candidate scores:\n",
      "  been         | LM: -12.3597 | Error:  +0.0000 | Combined: -11.7418\n",
      "Top selected tokens: ['been', 'been', 'been', 'been']\n",
      "\n",
      "Token: 'moistress' | Context: ('been',)\n",
      "Candidate scores:\n",
      "  moistress    | LM: -13.0277 | Error:  +0.0000 | Combined: -12.3763\n",
      "Token: 'moistress' | Context: ('been',)\n",
      "Candidate scores:\n",
      "  moistress    | LM: -13.0277 | Error:  +0.0000 | Combined: -12.3763\n",
      "Token: 'moistress' | Context: ('been',)\n",
      "Candidate scores:\n",
      "  moistress    | LM: -13.0277 | Error:  +0.0000 | Combined: -12.3763\n",
      "Token: 'moistress' | Context: ('been',)\n",
      "Candidate scores:\n",
      "  moistress    | LM: -13.0277 | Error:  +0.0000 | Combined: -12.3763\n",
      "Top selected tokens: ['moistress', 'moistress', 'moistress', 'moistress']\n",
      "\n",
      "Token: 'of' | Context: ('moistress',)\n",
      "Candidate scores:\n",
      "  of           | LM: -12.6963 | Error:  +0.0000 | Combined: -12.0615\n",
      "Token: 'of' | Context: ('moistress',)\n",
      "Candidate scores:\n",
      "  of           | LM: -12.6963 | Error:  +0.0000 | Combined: -12.0615\n",
      "Token: 'of' | Context: ('moistress',)\n",
      "Candidate scores:\n",
      "  of           | LM: -12.6963 | Error:  +0.0000 | Combined: -12.0615\n",
      "Token: 'of' | Context: ('moistress',)\n",
      "Candidate scores:\n",
      "  of           | LM: -12.6963 | Error:  +0.0000 | Combined: -12.0615\n",
      "Top selected tokens: ['of', 'of', 'of', 'of']\n",
      "\n",
      "Token: 'hois' | Context: ('of',)\n",
      "Candidate scores:\n",
      "  does         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  noise        | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  home         | LM: -11.9671 | Error:  -1.0986 | Combined: -11.4237\n",
      "  his          | LM:  -5.7650 | Error:  -0.6931 | Combined:  -5.5114\n",
      "  rows         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  axis         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  this         | LM:  -6.3934 | Error:  -1.0986 | Combined:  -6.1287\n",
      "  hope         | LM: -11.7972 | Error:  -1.0986 | Combined: -11.2622\n",
      "  horse        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  sons         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  tons         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  holes        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  oils         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hot          | LM: -12.1597 | Error:  -1.0986 | Combined: -11.6067\n",
      "  soil         | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  soils        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  tops         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  louis        | LM: -12.9671 | Error:  -1.0986 | Combined: -12.3737\n",
      "  oil          | LM: -12.9671 | Error:  -1.0986 | Combined: -12.3737\n",
      "  dogs         | LM: -12.9671 | Error:  -1.0986 | Combined: -12.3737\n",
      "  shoes        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hans         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  shows        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hours        | LM: -12.6452 | Error:  -1.0986 | Combined: -12.0678\n",
      "  hole         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  loss         | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  join         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  boys         | LM: -12.1597 | Error:  -1.0986 | Combined: -11.6067\n",
      "  cops         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  toes         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  him          | LM:  -9.1857 | Error:  -1.0986 | Combined:  -8.7814\n",
      "  holds        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  gods         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  holy         | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  chris        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  dots         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hour         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  house        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  shops        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  shots        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  homes        | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  hold         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hit          | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  boris        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  hopes        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  boss         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hoag         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  cows         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hats         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hits         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  goes         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  lots         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  host         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  los          | LM: -12.9671 | Error:  -1.0986 | Combined: -12.3737\n",
      "  hair         | LM: -12.6452 | Error:  -1.0986 | Combined: -12.0678\n",
      "  has          | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  horn         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  pops         | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  toys         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  is           | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  moist        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  jobs         | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  how          | LM: -10.3821 | Error:  -1.0986 | Combined:  -9.9180\n",
      "Token: 'hois' | Context: ('of',)\n",
      "Candidate scores:\n",
      "  does         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  noise        | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  home         | LM: -11.9671 | Error:  -1.0986 | Combined: -11.4237\n",
      "  his          | LM:  -5.7650 | Error:  -0.6931 | Combined:  -5.5114\n",
      "  rows         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  axis         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  this         | LM:  -6.3934 | Error:  -1.0986 | Combined:  -6.1287\n",
      "  hope         | LM: -11.7972 | Error:  -1.0986 | Combined: -11.2622\n",
      "  horse        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  sons         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  tons         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  holes        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  oils         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hot          | LM: -12.1597 | Error:  -1.0986 | Combined: -11.6067\n",
      "  soil         | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  soils        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  tops         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  louis        | LM: -12.9671 | Error:  -1.0986 | Combined: -12.3737\n",
      "  oil          | LM: -12.9671 | Error:  -1.0986 | Combined: -12.3737\n",
      "  dogs         | LM: -12.9671 | Error:  -1.0986 | Combined: -12.3737\n",
      "  shoes        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hans         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  shows        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hours        | LM: -12.6452 | Error:  -1.0986 | Combined: -12.0678\n",
      "  hole         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  loss         | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  join         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  boys         | LM: -12.1597 | Error:  -1.0986 | Combined: -11.6067\n",
      "  cops         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  toes         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  him          | LM:  -9.1857 | Error:  -1.0986 | Combined:  -8.7814\n",
      "  holds        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  gods         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  holy         | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  chris        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  dots         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hour         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  house        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  shops        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  shots        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  homes        | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  hold         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hit          | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  boris        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  hopes        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  boss         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hoag         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  cows         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hats         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hits         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  goes         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  lots         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  host         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  los          | LM: -12.9671 | Error:  -1.0986 | Combined: -12.3737\n",
      "  hair         | LM: -12.6452 | Error:  -1.0986 | Combined: -12.0678\n",
      "  has          | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  horn         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  pops         | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  toys         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  is           | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  moist        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  jobs         | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  how          | LM: -10.3821 | Error:  -1.0986 | Combined:  -9.9180\n",
      "Token: 'hois' | Context: ('of',)\n",
      "Candidate scores:\n",
      "  does         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  noise        | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  home         | LM: -11.9671 | Error:  -1.0986 | Combined: -11.4237\n",
      "  his          | LM:  -5.7650 | Error:  -0.6931 | Combined:  -5.5114\n",
      "  rows         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  axis         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  this         | LM:  -6.3934 | Error:  -1.0986 | Combined:  -6.1287\n",
      "  hope         | LM: -11.7972 | Error:  -1.0986 | Combined: -11.2622\n",
      "  horse        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  sons         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  tons         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  holes        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  oils         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hot          | LM: -12.1597 | Error:  -1.0986 | Combined: -11.6067\n",
      "  soil         | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  soils        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  tops         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  louis        | LM: -12.9671 | Error:  -1.0986 | Combined: -12.3737\n",
      "  oil          | LM: -12.9671 | Error:  -1.0986 | Combined: -12.3737\n",
      "  dogs         | LM: -12.9671 | Error:  -1.0986 | Combined: -12.3737\n",
      "  shoes        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hans         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  shows        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hours        | LM: -12.6452 | Error:  -1.0986 | Combined: -12.0678\n",
      "  hole         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  loss         | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  join         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  boys         | LM: -12.1597 | Error:  -1.0986 | Combined: -11.6067\n",
      "  cops         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  toes         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  him          | LM:  -9.1857 | Error:  -1.0986 | Combined:  -8.7814\n",
      "  holds        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  gods         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  holy         | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  chris        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  dots         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hour         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  house        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  shops        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  shots        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  homes        | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  hold         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hit          | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  boris        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  hopes        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  boss         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hoag         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  cows         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hats         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hits         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  goes         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  lots         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  host         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  los          | LM: -12.9671 | Error:  -1.0986 | Combined: -12.3737\n",
      "  hair         | LM: -12.6452 | Error:  -1.0986 | Combined: -12.0678\n",
      "  has          | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  horn         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  pops         | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  toys         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  is           | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  moist        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  jobs         | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  how          | LM: -10.3821 | Error:  -1.0986 | Combined:  -9.9180\n",
      "Token: 'hois' | Context: ('of',)\n",
      "Candidate scores:\n",
      "  does         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  noise        | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  home         | LM: -11.9671 | Error:  -1.0986 | Combined: -11.4237\n",
      "  his          | LM:  -5.7650 | Error:  -0.6931 | Combined:  -5.5114\n",
      "  rows         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  axis         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  this         | LM:  -6.3934 | Error:  -1.0986 | Combined:  -6.1287\n",
      "  hope         | LM: -11.7972 | Error:  -1.0986 | Combined: -11.2622\n",
      "  horse        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  sons         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  tons         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  holes        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  oils         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hot          | LM: -12.1597 | Error:  -1.0986 | Combined: -11.6067\n",
      "  soil         | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  soils        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  tops         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  louis        | LM: -12.9671 | Error:  -1.0986 | Combined: -12.3737\n",
      "  oil          | LM: -12.9671 | Error:  -1.0986 | Combined: -12.3737\n",
      "  dogs         | LM: -12.9671 | Error:  -1.0986 | Combined: -12.3737\n",
      "  shoes        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hans         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  shows        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hours        | LM: -12.6452 | Error:  -1.0986 | Combined: -12.0678\n",
      "  hole         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  loss         | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  join         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  boys         | LM: -12.1597 | Error:  -1.0986 | Combined: -11.6067\n",
      "  cops         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  toes         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  him          | LM:  -9.1857 | Error:  -1.0986 | Combined:  -8.7814\n",
      "  holds        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  gods         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  holy         | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  chris        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  dots         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hour         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  house        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  shops        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  shots        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  homes        | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  hold         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hit          | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  boris        | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  hopes        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  boss         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hoag         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  cows         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hats         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  hits         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  goes         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  lots         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  host         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  los          | LM: -12.9671 | Error:  -1.0986 | Combined: -12.3737\n",
      "  hair         | LM: -12.6452 | Error:  -1.0986 | Combined: -12.0678\n",
      "  has          | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  horn         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  pops         | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  toys         | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  is           | LM: -13.9671 | Error:  -1.0986 | Combined: -13.3237\n",
      "  moist        | LM: -14.9671 | Error:  -1.0986 | Combined: -14.2737\n",
      "  jobs         | LM: -13.3821 | Error:  -1.0986 | Combined: -12.7680\n",
      "  how          | LM: -10.3821 | Error:  -1.0986 | Combined:  -9.9180\n",
      "Top selected tokens: ['his', 'his', 'this', 'this', 'his']\n",
      "\n",
      "Token: 'house' | Context: ('his',)\n",
      "Candidate scores:\n",
      "  house        | LM: -10.3219 | Error:  +0.0000 | Combined:  -9.8058\n",
      "Token: 'house' | Context: ('his',)\n",
      "Candidate scores:\n",
      "  house        | LM: -10.3219 | Error:  +0.0000 | Combined:  -9.8058\n",
      "Token: 'house' | Context: ('this',)\n",
      "Candidate scores:\n",
      "  house        | LM: -11.7432 | Error:  +0.0000 | Combined: -11.1560\n",
      "Token: 'house' | Context: ('this',)\n",
      "Candidate scores:\n",
      "  house        | LM: -11.7432 | Error:  +0.0000 | Combined: -11.1560\n",
      "Token: 'house' | Context: ('his',)\n",
      "Candidate scores:\n",
      "  house        | LM: -10.3219 | Error:  +0.0000 | Combined:  -9.8058\n",
      "Top selected tokens: ['house', 'house', 'house', 'house', 'house']\n",
      "\n",
      "Token: 'from' | Context: ('house',)\n",
      "Candidate scores:\n",
      "  from         | LM: -12.7838 | Error:  +0.0000 | Combined: -12.1446\n",
      "Token: 'from' | Context: ('house',)\n",
      "Candidate scores:\n",
      "  from         | LM: -12.7838 | Error:  +0.0000 | Combined: -12.1446\n",
      "Token: 'from' | Context: ('house',)\n",
      "Candidate scores:\n",
      "  from         | LM: -12.7838 | Error:  +0.0000 | Combined: -12.1446\n",
      "Token: 'from' | Context: ('house',)\n",
      "Candidate scores:\n",
      "  from         | LM: -12.7838 | Error:  +0.0000 | Combined: -12.1446\n",
      "Token: 'from' | Context: ('house',)\n",
      "Candidate scores:\n",
      "  from         | LM: -12.7838 | Error:  +0.0000 | Combined: -12.1446\n",
      "Top selected tokens: ['from', 'from', 'from', 'from', 'from']\n",
      "\n",
      "Token: 'a' | Context: ('from',)\n",
      "Candidate scores:\n",
      "  a            | LM:  -5.8022 | Error:  +0.0000 | Combined:  -5.5121\n",
      "Token: 'a' | Context: ('from',)\n",
      "Candidate scores:\n",
      "  a            | LM:  -5.8022 | Error:  +0.0000 | Combined:  -5.5121\n",
      "Token: 'a' | Context: ('from',)\n",
      "Candidate scores:\n",
      "  a            | LM:  -5.8022 | Error:  +0.0000 | Combined:  -5.5121\n",
      "Token: 'a' | Context: ('from',)\n",
      "Candidate scores:\n",
      "  a            | LM:  -5.8022 | Error:  +0.0000 | Combined:  -5.5121\n",
      "Token: 'a' | Context: ('from',)\n",
      "Candidate scores:\n",
      "  a            | LM:  -5.8022 | Error:  +0.0000 | Combined:  -5.5121\n",
      "Top selected tokens: ['a', 'a', 'a', 'a', 'a']\n",
      "\n",
      "Token: 'vry' | Context: ('a',)\n",
      "Candidate scores:\n",
      "  v            | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  r            | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  vs.          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  why          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  amy          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  sky          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  fly          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  day          | LM:  -8.7540 | Error:  -1.0986 | Combined:  -8.3712\n",
      "  mr.          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  art          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  gray         | LM: -12.1600 | Error:  -1.0986 | Combined: -11.6069\n",
      "  mary         | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  pray         | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  boy          | LM:  -9.6746 | Error:  -1.0986 | Combined:  -9.2458\n",
      "  guy          | LM: -11.6746 | Error:  -1.0986 | Combined: -11.1458\n",
      "  my           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  roy          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  era          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  ivory        | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  arc          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  way          | LM:  -9.0557 | Error:  -1.0986 | Combined:  -8.6578\n",
      "  bay          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  buy          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  tray         | LM: -12.8970 | Error:  -1.0986 | Combined: -12.3070\n",
      "  van          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  try          | LM: -14.4819 | Error:  -0.6931 | Combined: -13.7925\n",
      "  or           | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  pay          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  via          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  may          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  jury         | LM: -11.8970 | Error:  -1.0986 | Combined: -11.3570\n",
      "  hey          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  joy          | LM: -12.4819 | Error:  -1.0986 | Combined: -11.9128\n",
      "  grey         | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  're          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  arm          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  ray          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  very         | LM:  -7.9273 | Error:  -0.6931 | Combined:  -7.5656\n",
      "  every        | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  vary         | LM: -14.4819 | Error:  -0.6931 | Combined: -13.7925\n",
      "  dry          | LM: -12.1600 | Error:  -0.6931 | Combined: -11.5867\n",
      "  hay          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  are          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  fury         | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  say          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  key          | LM: -12.1600 | Error:  -1.0986 | Combined: -11.6069\n",
      "  army         | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  lay          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  thy          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  any          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  jr.          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  kay          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  cry          | LM: -12.1600 | Error:  -0.6931 | Combined: -11.5867\n",
      "  gay          | LM: -12.4819 | Error:  -1.0986 | Combined: -11.9128\n",
      "  pro          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  v.           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  by           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  dr.          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  r.           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  shy          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "Token: 'vry' | Context: ('a',)\n",
      "Candidate scores:\n",
      "  v            | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  r            | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  vs.          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  why          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  amy          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  sky          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  fly          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  day          | LM:  -8.7540 | Error:  -1.0986 | Combined:  -8.3712\n",
      "  mr.          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  art          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  gray         | LM: -12.1600 | Error:  -1.0986 | Combined: -11.6069\n",
      "  mary         | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  pray         | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  boy          | LM:  -9.6746 | Error:  -1.0986 | Combined:  -9.2458\n",
      "  guy          | LM: -11.6746 | Error:  -1.0986 | Combined: -11.1458\n",
      "  my           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  roy          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  era          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  ivory        | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  arc          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  way          | LM:  -9.0557 | Error:  -1.0986 | Combined:  -8.6578\n",
      "  bay          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  buy          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  tray         | LM: -12.8970 | Error:  -1.0986 | Combined: -12.3070\n",
      "  van          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  try          | LM: -14.4819 | Error:  -0.6931 | Combined: -13.7925\n",
      "  or           | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  pay          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  via          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  may          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  jury         | LM: -11.8970 | Error:  -1.0986 | Combined: -11.3570\n",
      "  hey          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  joy          | LM: -12.4819 | Error:  -1.0986 | Combined: -11.9128\n",
      "  grey         | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  're          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  arm          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  ray          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  very         | LM:  -7.9273 | Error:  -0.6931 | Combined:  -7.5656\n",
      "  every        | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  vary         | LM: -14.4819 | Error:  -0.6931 | Combined: -13.7925\n",
      "  dry          | LM: -12.1600 | Error:  -0.6931 | Combined: -11.5867\n",
      "  hay          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  are          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  fury         | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  say          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  key          | LM: -12.1600 | Error:  -1.0986 | Combined: -11.6069\n",
      "  army         | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  lay          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  thy          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  any          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  jr.          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  kay          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  cry          | LM: -12.1600 | Error:  -0.6931 | Combined: -11.5867\n",
      "  gay          | LM: -12.4819 | Error:  -1.0986 | Combined: -11.9128\n",
      "  pro          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  v.           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  by           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  dr.          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  r.           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  shy          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "Token: 'vry' | Context: ('a',)\n",
      "Candidate scores:\n",
      "  v            | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  r            | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  vs.          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  why          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  amy          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  sky          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  fly          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  day          | LM:  -8.7540 | Error:  -1.0986 | Combined:  -8.3712\n",
      "  mr.          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  art          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  gray         | LM: -12.1600 | Error:  -1.0986 | Combined: -11.6069\n",
      "  mary         | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  pray         | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  boy          | LM:  -9.6746 | Error:  -1.0986 | Combined:  -9.2458\n",
      "  guy          | LM: -11.6746 | Error:  -1.0986 | Combined: -11.1458\n",
      "  my           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  roy          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  era          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  ivory        | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  arc          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  way          | LM:  -9.0557 | Error:  -1.0986 | Combined:  -8.6578\n",
      "  bay          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  buy          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  tray         | LM: -12.8970 | Error:  -1.0986 | Combined: -12.3070\n",
      "  van          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  try          | LM: -14.4819 | Error:  -0.6931 | Combined: -13.7925\n",
      "  or           | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  pay          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  via          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  may          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  jury         | LM: -11.8970 | Error:  -1.0986 | Combined: -11.3570\n",
      "  hey          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  joy          | LM: -12.4819 | Error:  -1.0986 | Combined: -11.9128\n",
      "  grey         | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  're          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  arm          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  ray          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  very         | LM:  -7.9273 | Error:  -0.6931 | Combined:  -7.5656\n",
      "  every        | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  vary         | LM: -14.4819 | Error:  -0.6931 | Combined: -13.7925\n",
      "  dry          | LM: -12.1600 | Error:  -0.6931 | Combined: -11.5867\n",
      "  hay          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  are          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  fury         | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  say          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  key          | LM: -12.1600 | Error:  -1.0986 | Combined: -11.6069\n",
      "  army         | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  lay          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  thy          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  any          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  jr.          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  kay          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  cry          | LM: -12.1600 | Error:  -0.6931 | Combined: -11.5867\n",
      "  gay          | LM: -12.4819 | Error:  -1.0986 | Combined: -11.9128\n",
      "  pro          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  v.           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  by           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  dr.          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  r.           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  shy          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "Token: 'vry' | Context: ('a',)\n",
      "Candidate scores:\n",
      "  v            | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  r            | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  vs.          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  why          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  amy          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  sky          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  fly          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  day          | LM:  -8.7540 | Error:  -1.0986 | Combined:  -8.3712\n",
      "  mr.          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  art          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  gray         | LM: -12.1600 | Error:  -1.0986 | Combined: -11.6069\n",
      "  mary         | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  pray         | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  boy          | LM:  -9.6746 | Error:  -1.0986 | Combined:  -9.2458\n",
      "  guy          | LM: -11.6746 | Error:  -1.0986 | Combined: -11.1458\n",
      "  my           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  roy          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  era          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  ivory        | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  arc          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  way          | LM:  -9.0557 | Error:  -1.0986 | Combined:  -8.6578\n",
      "  bay          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  buy          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  tray         | LM: -12.8970 | Error:  -1.0986 | Combined: -12.3070\n",
      "  van          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  try          | LM: -14.4819 | Error:  -0.6931 | Combined: -13.7925\n",
      "  or           | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  pay          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  via          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  may          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  jury         | LM: -11.8970 | Error:  -1.0986 | Combined: -11.3570\n",
      "  hey          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  joy          | LM: -12.4819 | Error:  -1.0986 | Combined: -11.9128\n",
      "  grey         | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  're          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  arm          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  ray          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  very         | LM:  -7.9273 | Error:  -0.6931 | Combined:  -7.5656\n",
      "  every        | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  vary         | LM: -14.4819 | Error:  -0.6931 | Combined: -13.7925\n",
      "  dry          | LM: -12.1600 | Error:  -0.6931 | Combined: -11.5867\n",
      "  hay          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  are          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  fury         | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  say          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  key          | LM: -12.1600 | Error:  -1.0986 | Combined: -11.6069\n",
      "  army         | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  lay          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  thy          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  any          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  jr.          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  kay          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  cry          | LM: -12.1600 | Error:  -0.6931 | Combined: -11.5867\n",
      "  gay          | LM: -12.4819 | Error:  -1.0986 | Combined: -11.9128\n",
      "  pro          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  v.           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  by           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  dr.          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  r.           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  shy          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "Token: 'vry' | Context: ('a',)\n",
      "Candidate scores:\n",
      "  v            | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  r            | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  vs.          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  why          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  amy          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  sky          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  fly          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  day          | LM:  -8.7540 | Error:  -1.0986 | Combined:  -8.3712\n",
      "  mr.          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  art          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  gray         | LM: -12.1600 | Error:  -1.0986 | Combined: -11.6069\n",
      "  mary         | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  pray         | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  boy          | LM:  -9.6746 | Error:  -1.0986 | Combined:  -9.2458\n",
      "  guy          | LM: -11.6746 | Error:  -1.0986 | Combined: -11.1458\n",
      "  my           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  roy          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  era          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  ivory        | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  arc          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  way          | LM:  -9.0557 | Error:  -1.0986 | Combined:  -8.6578\n",
      "  bay          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  buy          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  tray         | LM: -12.8970 | Error:  -1.0986 | Combined: -12.3070\n",
      "  van          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  try          | LM: -14.4819 | Error:  -0.6931 | Combined: -13.7925\n",
      "  or           | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  pay          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  via          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  may          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  jury         | LM: -11.8970 | Error:  -1.0986 | Combined: -11.3570\n",
      "  hey          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  joy          | LM: -12.4819 | Error:  -1.0986 | Combined: -11.9128\n",
      "  grey         | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  're          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  arm          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  ray          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  very         | LM:  -7.9273 | Error:  -0.6931 | Combined:  -7.5656\n",
      "  every        | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  vary         | LM: -14.4819 | Error:  -0.6931 | Combined: -13.7925\n",
      "  dry          | LM: -12.1600 | Error:  -0.6931 | Combined: -11.5867\n",
      "  hay          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  are          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  fury         | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  say          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  key          | LM: -12.1600 | Error:  -1.0986 | Combined: -11.6069\n",
      "  army         | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  lay          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  thy          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  any          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  jr.          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  kay          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  cry          | LM: -12.1600 | Error:  -0.6931 | Combined: -11.5867\n",
      "  gay          | LM: -12.4819 | Error:  -1.0986 | Combined: -11.9128\n",
      "  pro          | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  v.           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  by           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  dr.          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "  r.           | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  shy          | LM: -13.4819 | Error:  -1.0986 | Combined: -12.8628\n",
      "Top selected tokens: ['very', 'very', 'day', 'day', 'way']\n",
      "\n",
      "Token: 'early' | Context: ('very',)\n",
      "Candidate scores:\n",
      "  early        | LM: -10.8136 | Error:  +0.0000 | Combined: -10.2729\n",
      "Token: 'early' | Context: ('very',)\n",
      "Candidate scores:\n",
      "  early        | LM: -10.8136 | Error:  +0.0000 | Combined: -10.2729\n",
      "Token: 'early' | Context: ('day',)\n",
      "Candidate scores:\n",
      "  early        | LM: -12.7981 | Error:  +0.0000 | Combined: -12.1582\n",
      "Token: 'early' | Context: ('day',)\n",
      "Candidate scores:\n",
      "  early        | LM: -12.7981 | Error:  +0.0000 | Combined: -12.1582\n",
      "Token: 'early' | Context: ('way',)\n",
      "Candidate scores:\n",
      "  early        | LM: -12.8293 | Error:  +0.0000 | Combined: -12.1879\n",
      "Top selected tokens: ['early', 'early', 'early', 'early', 'early']\n",
      "\n",
      "Token: 'period' | Context: ('early',)\n",
      "Candidate scores:\n",
      "  period       | LM: -12.7526 | Error:  +0.0000 | Combined: -12.1150\n",
      "Token: 'period' | Context: ('early',)\n",
      "Candidate scores:\n",
      "  period       | LM: -12.7526 | Error:  +0.0000 | Combined: -12.1150\n",
      "Token: 'period' | Context: ('early',)\n",
      "Candidate scores:\n",
      "  period       | LM: -12.7526 | Error:  +0.0000 | Combined: -12.1150\n",
      "Token: 'period' | Context: ('early',)\n",
      "Candidate scores:\n",
      "  period       | LM: -12.7526 | Error:  +0.0000 | Combined: -12.1150\n",
      "Token: 'period' | Context: ('early',)\n",
      "Candidate scores:\n",
      "  period       | LM: -12.7526 | Error:  +0.0000 | Combined: -12.1150\n",
      "Top selected tokens: ['period', 'period', 'period', 'period', 'period']\n",
      "\n",
      "Final corrected sentence: in consequence of her sister 's marriage , been moistress of his house from a very early period\n",
      "Bigram model produced:\n",
      "  in consequence of her sister 's marriage , been moistress of his house from a very early period\n",
      "\n",
      "Testing with sentence: \"Tomorrrow well bring somethiing new, so leav today as a memoory.\"\n",
      "Starting correction for sentence: Tomorrrow well bring somethiing new , so leav today as a memoory .\n",
      "Token: 'Tomorrrow' | Context: ('<start>',)\n",
      "Candidate scores:\n",
      "  tomorrow     | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "Top selected tokens: ['tomorrow']\n",
      "\n",
      "Token: 'well' | Context: ('tomorrow',)\n",
      "Candidate scores:\n",
      "  well         | LM: -12.7065 | Error:  +0.0000 | Combined: -12.0712\n",
      "Top selected tokens: ['well']\n",
      "\n",
      "Token: 'bring' | Context: ('well',)\n",
      "Candidate scores:\n",
      "  bring        | LM: -12.8269 | Error:  +0.0000 | Combined: -12.1856\n",
      "Top selected tokens: ['bring']\n",
      "\n",
      "Token: 'somethiing' | Context: ('bring',)\n",
      "Candidate scores:\n",
      "  something    | LM: -12.7175 | Error:  -0.6931 | Combined: -12.1162\n",
      "Top selected tokens: ['something']\n",
      "\n",
      "Token: 'new' | Context: ('something',)\n",
      "Candidate scores:\n",
      "  new          | LM: -11.7613 | Error:  +0.0000 | Combined: -11.1733\n",
      "Top selected tokens: ['new']\n",
      "\n",
      "Token: ',' | Context: ('new',)\n",
      "Candidate scores:\n",
      "  ,            | LM:  -8.9230 | Error:  +0.0000 | Combined:  -8.4768\n",
      "Top selected tokens: [',']\n",
      "\n",
      "Token: 'so' | Context: (',',)\n",
      "Candidate scores:\n",
      "  so           | LM:  -7.9372 | Error:  +0.0000 | Combined:  -7.5404\n",
      "Top selected tokens: ['so']\n",
      "\n",
      "Token: 'leav' | Context: ('so',)\n",
      "Candidate scores:\n",
      "  weak         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  led          | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  lest         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  lee          | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  le           | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  beam         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  dean         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  loan         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  mean         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  seal         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  fear         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  deal         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  head         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  dear         | LM: -11.9748 | Error:  -1.0986 | Combined: -11.4310\n",
      "  leg          | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  law          | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  leaves       | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  clear        | LM: -11.9748 | Error:  -1.0986 | Combined: -11.4310\n",
      "  yeah         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  bear         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  lap          | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  less         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  ear          | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  near         | LM: -11.3898 | Error:  -1.0986 | Combined: -10.8753\n",
      "  seat         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  real         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  learn        | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  lend         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  legal        | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  let          | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  peas         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  jean         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  read         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  heavy        | LM: -11.9748 | Error:  -1.0986 | Combined: -11.4310\n",
      "  beat         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  rev          | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  lens         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  deaf         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  gear         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  plea         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  dead         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  left         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  hear         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  neat         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  load         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  tea          | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  clean        | LM: -11.9748 | Error:  -1.0986 | Combined: -11.4310\n",
      "  leads        | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  wear         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  year         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  eat          | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  heat         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  legs         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  lay          | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  heap         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  lean         | LM: -12.9748 | Error:  -0.6931 | Combined: -12.3607\n",
      "  sea          | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  meat         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  rear         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  la           | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  leave        | LM: -12.9748 | Error:  -0.6931 | Combined: -12.3607\n",
      "  least        | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  meal         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  lao          | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  team         | LM: -12.9748 | Error:  -1.0986 | Combined: -12.3810\n",
      "  lead         | LM: -12.9748 | Error:  -0.6931 | Combined: -12.3607\n",
      "Top selected tokens: ['near', 'dear', 'clear', 'heavy', 'clean']\n",
      "\n",
      "Token: 'today' | Context: ('near',)\n",
      "Candidate scores:\n",
      "  today        | LM: -12.7247 | Error:  +0.0000 | Combined: -12.0885\n",
      "Token: 'today' | Context: ('dear',)\n",
      "Candidate scores:\n",
      "  today        | LM: -12.7041 | Error:  +0.0000 | Combined: -12.0689\n",
      "Token: 'today' | Context: ('clear',)\n",
      "Candidate scores:\n",
      "  today        | LM: -12.7298 | Error:  +0.0000 | Combined: -12.0933\n",
      "Token: 'today' | Context: ('heavy',)\n",
      "Candidate scores:\n",
      "  today        | LM: -12.7134 | Error:  +0.0000 | Combined: -12.0777\n",
      "Token: 'today' | Context: ('clean',)\n",
      "Candidate scores:\n",
      "  today        | LM: -12.7067 | Error:  +0.0000 | Combined: -12.0714\n",
      "Top selected tokens: ['today', 'today', 'today', 'today', 'today']\n",
      "\n",
      "Token: 'as' | Context: ('today',)\n",
      "Candidate scores:\n",
      "  as           | LM: -10.1563 | Error:  +0.0000 | Combined:  -9.6485\n",
      "Token: 'as' | Context: ('today',)\n",
      "Candidate scores:\n",
      "  as           | LM: -10.1563 | Error:  +0.0000 | Combined:  -9.6485\n",
      "Token: 'as' | Context: ('today',)\n",
      "Candidate scores:\n",
      "  as           | LM: -10.1563 | Error:  +0.0000 | Combined:  -9.6485\n",
      "Token: 'as' | Context: ('today',)\n",
      "Candidate scores:\n",
      "  as           | LM: -10.1563 | Error:  +0.0000 | Combined:  -9.6485\n",
      "Token: 'as' | Context: ('today',)\n",
      "Candidate scores:\n",
      "  as           | LM: -10.1563 | Error:  +0.0000 | Combined:  -9.6485\n",
      "Top selected tokens: ['as', 'as', 'as', 'as', 'as']\n",
      "\n",
      "Token: 'a' | Context: ('as',)\n",
      "Candidate scores:\n",
      "  a            | LM:  -4.1181 | Error:  +0.0000 | Combined:  -3.9122\n",
      "Token: 'a' | Context: ('as',)\n",
      "Candidate scores:\n",
      "  a            | LM:  -4.1181 | Error:  +0.0000 | Combined:  -3.9122\n",
      "Token: 'a' | Context: ('as',)\n",
      "Candidate scores:\n",
      "  a            | LM:  -4.1181 | Error:  +0.0000 | Combined:  -3.9122\n",
      "Token: 'a' | Context: ('as',)\n",
      "Candidate scores:\n",
      "  a            | LM:  -4.1181 | Error:  +0.0000 | Combined:  -3.9122\n",
      "Token: 'a' | Context: ('as',)\n",
      "Candidate scores:\n",
      "  a            | LM:  -4.1181 | Error:  +0.0000 | Combined:  -3.9122\n",
      "Top selected tokens: ['a', 'a', 'a', 'a', 'a']\n",
      "\n",
      "Token: 'memoory' | Context: ('a',)\n",
      "Candidate scores:\n",
      "  memory       | LM: -14.4819 | Error:  -0.6931 | Combined: -13.7925\n",
      "Token: 'memoory' | Context: ('a',)\n",
      "Candidate scores:\n",
      "  memory       | LM: -14.4819 | Error:  -0.6931 | Combined: -13.7925\n",
      "Token: 'memoory' | Context: ('a',)\n",
      "Candidate scores:\n",
      "  memory       | LM: -14.4819 | Error:  -0.6931 | Combined: -13.7925\n",
      "Token: 'memoory' | Context: ('a',)\n",
      "Candidate scores:\n",
      "  memory       | LM: -14.4819 | Error:  -0.6931 | Combined: -13.7925\n",
      "Token: 'memoory' | Context: ('a',)\n",
      "Candidate scores:\n",
      "  memory       | LM: -14.4819 | Error:  -0.6931 | Combined: -13.7925\n",
      "Top selected tokens: ['memory', 'memory', 'memory', 'memory', 'memory']\n",
      "\n",
      "Token: '.' | Context: ('memory',)\n",
      "Candidate scores:\n",
      "  .            | LM:  -9.9007 | Error:  +0.0000 | Combined:  -9.4056\n",
      "Token: '.' | Context: ('memory',)\n",
      "Candidate scores:\n",
      "  .            | LM:  -9.9007 | Error:  +0.0000 | Combined:  -9.4056\n",
      "Token: '.' | Context: ('memory',)\n",
      "Candidate scores:\n",
      "  .            | LM:  -9.9007 | Error:  +0.0000 | Combined:  -9.4056\n",
      "Token: '.' | Context: ('memory',)\n",
      "Candidate scores:\n",
      "  .            | LM:  -9.9007 | Error:  +0.0000 | Combined:  -9.4056\n",
      "Token: '.' | Context: ('memory',)\n",
      "Candidate scores:\n",
      "  .            | LM:  -9.9007 | Error:  +0.0000 | Combined:  -9.4056\n",
      "Top selected tokens: ['.', '.', '.', '.', '.']\n",
      "\n",
      "Final corrected sentence: tomorrow well bring something new , so near today as a memory .\n",
      "Bigram model produced:\n",
      "  tomorrow well bring something new , so near today as a memory .\n",
      "\n",
      "Testing with sentence: \"He wento too the storr to by some bred and mlik.\"\n",
      "Starting correction for sentence: He wento too the storr to by some bred and mlik .\n",
      "Token: 'He' | Context: ('<start>',)\n",
      "Candidate scores:\n",
      "  v            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  5            | LM: -11.1755 | Error:  -1.0986 | Combined: -10.6716\n",
      "  n.           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  r            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  so           | LM:  -8.3275 | Error:  -1.0986 | Combined:  -7.9660\n",
      "  18           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  i            | LM:  -5.4476 | Error:  -1.0986 | Combined:  -5.2301\n",
      "  fee          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  40           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  s            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  29           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  26           | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  .            | LM:  -9.3275 | Error:  -1.0986 | Combined:  -8.9160\n",
      "  ed           | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  80           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  led          | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  e.           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  lee          | LM: -13.4974 | Error:  -1.0986 | Combined: -12.8775\n",
      "  le           | LM: -14.4974 | Error:  -0.6931 | Combined: -13.8072\n",
      "  65           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  4            | LM: -10.4530 | Error:  -1.0986 | Combined:  -9.9853\n",
      "  fed          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  ''           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  us           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  no           | LM:  -8.0712 | Error:  -1.0986 | Combined:  -7.7225\n",
      "  aj           | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  jet          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  al           | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  )            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  30           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  tie          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  0            | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  one          | LM:  -7.4476 | Error:  -1.0986 | Combined:  -7.1301\n",
      "  ace          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  ah           | LM: -12.9125 | Error:  -1.0986 | Combined: -12.3218\n",
      "  set          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  19           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  mae          | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  sex          | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  27           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  *            | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  31           | LM: -13.4974 | Error:  -1.0986 | Combined: -12.8775\n",
      "  21           | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  28           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  45           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  l            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  w.           | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  see          | LM: -12.0380 | Error:  -1.0986 | Combined: -11.4910\n",
      "  due          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  17           | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  b            | LM: -12.6901 | Error:  -1.0986 | Combined: -12.1105\n",
      "  ;            | LM: -12.3275 | Error:  -1.0986 | Combined: -11.7660\n",
      "  g.           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  }            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  70           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  du           | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  my           | LM:  -9.3889 | Error:  -1.0986 | Combined:  -8.9744\n",
      "  lie          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  leg          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  ,            | LM:  -8.6519 | Error:  -1.0986 | Combined:  -8.2743\n",
      "  el           | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  it           | LM:  -5.0503 | Error:  -1.0986 | Combined:  -4.8527\n",
      "  joe          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  lb           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  k            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  15           | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  we           | LM:  -6.8321 | Error:  -0.6931 | Combined:  -6.5251\n",
      "  go           | LM: -12.6901 | Error:  -1.0986 | Combined: -12.1105\n",
      "  ca           | LM: -12.9125 | Error:  -1.0986 | Combined: -12.3218\n",
      "  p            | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  u            | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  j            | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  o            | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  x            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  t.           | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  'm           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  s.           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  d.           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  to           | LM:  -7.5144 | Error:  -1.0986 | Combined:  -7.1936\n",
      "  pie          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  et           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  14           | LM: -13.1755 | Error:  -1.0986 | Combined: -12.5716\n",
      "  the          | LM:  -3.3882 | Error:  -1.0986 | Combined:  -3.2738\n",
      "  ice          | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  c.           | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  'd           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  25           | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  71           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  %            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  few          | LM: -11.6901 | Error:  -1.0986 | Combined: -11.1605\n",
      "  let          | LM:  -9.6148 | Error:  -1.0986 | Combined:  -9.1890\n",
      "  36           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  (            | LM:  -7.7425 | Error:  -1.0986 | Combined:  -7.4103\n",
      "  m            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  new          | LM: -10.3681 | Error:  -1.0986 | Combined:  -9.9047\n",
      "  die          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  an           | LM:  -8.6271 | Error:  -1.0986 | Combined:  -8.2506\n",
      "  b.           | LM: -13.1755 | Error:  -1.0986 | Combined: -12.5716\n",
      "  's           | LM: -13.1755 | Error:  -1.0986 | Combined: -12.5716\n",
      "  rev          | LM: -12.6901 | Error:  -1.0986 | Combined: -12.1105\n",
      "  &            | LM: -12.1755 | Error:  -1.0986 | Combined: -11.6216\n",
      "  hen          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  22           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  or           | LM:  -9.6645 | Error:  -1.0986 | Combined:  -9.2362\n",
      "  yet          | LM:  -9.1576 | Error:  -1.0986 | Combined:  -8.7546\n",
      "  10           | LM: -12.6901 | Error:  -1.0986 | Combined: -12.1105\n",
      "  pa           | LM: -12.9125 | Error:  -1.0986 | Combined: -12.3218\n",
      "  wet          | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  g            | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  11           | LM: -12.9125 | Error:  -1.0986 | Combined: -12.3218\n",
      "  hey          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  she          | LM:  -6.1710 | Error:  -1.0986 | Combined:  -5.9174\n",
      "  tv           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  50           | LM: -12.9125 | Error:  -1.0986 | Combined: -12.3218\n",
      "  ate          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  l.           | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  lo           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  23           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  p.           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  13           | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  up           | LM: -12.4974 | Error:  -1.0986 | Combined: -11.9275\n",
      "  bed          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  di           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  her          | LM:  -8.8250 | Error:  -1.0986 | Combined:  -8.4387\n",
      "  pen          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  a            | LM:  -6.0197 | Error:  -1.0986 | Combined:  -5.7736\n",
      "  met          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  do           | LM:  -9.3076 | Error:  -1.0986 | Combined:  -8.8971\n",
      "  ben          | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  {            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  be           | LM: -11.4974 | Error:  -0.6931 | Combined: -10.9572\n",
      "  ten          | LM: -12.0380 | Error:  -1.0986 | Combined: -11.4910\n",
      "  3            | LM:  -9.9739 | Error:  -1.0986 | Combined:  -9.5301\n",
      "  oh           | LM: -10.8536 | Error:  -1.0986 | Combined: -10.3658\n",
      "  're          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  ``           | LM:  -4.0581 | Error:  -1.0986 | Combined:  -3.9101\n",
      "  at           | LM:  -7.4367 | Error:  -1.0986 | Combined:  -7.1198\n",
      "  90           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  cm           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  tea          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  k.           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  wo           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  bet          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  get          | LM: -12.6901 | Error:  -1.0986 | Combined: -12.1105\n",
      "  q            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  na           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  m.           | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  da           | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  am           | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  eve          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  9            | LM: -12.3275 | Error:  -1.0986 | Combined: -11.7660\n",
      "  -            | LM: -12.9125 | Error:  -1.0986 | Combined: -12.3218\n",
      "  /            | LM: -12.6901 | Error:  -1.0986 | Combined: -12.1105\n",
      "  've          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  yes          | LM: -10.6901 | Error:  -1.0986 | Combined: -10.2105\n",
      "  f.           | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  men          | LM: -11.6901 | Error:  -1.0986 | Combined: -11.1605\n",
      "  are          | LM: -10.5432 | Error:  -1.0986 | Combined: -10.0710\n",
      "  per          | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  eye          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  key          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  24           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  if           | LM:  -6.6933 | Error:  -1.0986 | Combined:  -6.4136\n",
      "  u.           | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  net          | LM: -13.4974 | Error:  -1.0986 | Combined: -12.8775\n",
      "  2            | LM:  -9.3889 | Error:  -1.0986 | Combined:  -8.9744\n",
      "  as           | LM:  -6.9660 | Error:  -1.0986 | Combined:  -6.6727\n",
      "  c            | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  d            | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  af           | LM: -12.3275 | Error:  -1.0986 | Combined: -11.7660\n",
      "  ken          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  8            | LM: -12.0380 | Error:  -1.0986 | Combined: -11.4910\n",
      "  'em          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  sec          | LM: -12.1755 | Error:  -1.0986 | Combined: -11.6216\n",
      "  n            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  7            | LM: -11.1755 | Error:  -1.0986 | Combined: -10.6716\n",
      "  1            | LM: -10.2120 | Error:  -1.0986 | Combined:  -9.7563\n",
      "  e            | LM: -14.4974 | Error:  -0.6931 | Combined: -13.8072\n",
      "  zg           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  ?            | LM:  -4.8013 | Error:  -1.0986 | Combined:  -4.6162\n",
      "  sea          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  h.           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  me           | LM: -14.4974 | Error:  -0.6931 | Combined: -13.8072\n",
      "  red          | LM: -12.9125 | Error:  -1.0986 | Combined: -12.3218\n",
      "  85           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  $            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  --           | LM:  -9.5905 | Error:  -1.0986 | Combined:  -9.1659\n",
      "  la           | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  ye           | LM: -15.4974 | Error:  -0.6931 | Combined: -14.7572\n",
      "  jew          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  f            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  a.           | LM: -12.0380 | Error:  -1.0986 | Combined: -11.4910\n",
      "  o.           | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  ai           | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  v.           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  he           | LM:  -4.5137 | Error:  -0.6931 | Combined:  -4.3227\n",
      "  by           | LM:  -8.3785 | Error:  -1.0986 | Combined:  -8.0145\n",
      "  75           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  of           | LM:  -8.8681 | Error:  -1.0986 | Combined:  -8.4796\n",
      "  !            | LM:  -6.3968 | Error:  -1.0986 | Combined:  -6.1318\n",
      "  20           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  h            | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  ma           | LM: -13.4974 | Error:  -1.0986 | Combined: -12.8775\n",
      "  6            | LM: -11.3275 | Error:  -1.0986 | Combined: -10.8160\n",
      "  is           | LM:  -9.8536 | Error:  -1.0986 | Combined:  -9.4158\n",
      "  16           | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  r.           | LM: -13.1755 | Error:  -1.0986 | Combined: -12.5716\n",
      "  use          | LM: -11.7970 | Error:  -1.0986 | Combined: -11.2621\n",
      "  :            | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  on           | LM:  -7.6271 | Error:  -1.0986 | Combined:  -7.3006\n",
      "  age          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  35           | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  i.e          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  in           | LM:  -5.2626 | Error:  -1.0986 | Combined:  -5.0544\n",
      "  12           | LM: -12.1755 | Error:  -1.0986 | Combined: -11.6216\n",
      "  t            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  '            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  de           | LM: -13.4974 | Error:  -0.6931 | Combined: -12.8572\n",
      "  j.           | LM: -13.1755 | Error:  -1.0986 | Combined: -12.5716\n",
      "  zen          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  34           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  sue          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  60           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "Top selected tokens: ['the', '``', 'he', '?', 'it']\n",
      "\n",
      "Token: 'wento' | Context: ('the',)\n",
      "Candidate scores:\n",
      "  rent         | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  want         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  sent         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  tent         | LM: -12.9471 | Error:  -1.0986 | Combined: -12.3547\n",
      "  onto         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  went         | LM: -15.7545 | Error:  -0.6931 | Combined: -15.0014\n",
      "  cent         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  west         | LM:  -9.2153 | Error:  -1.0986 | Combined:  -8.8095\n",
      "  into         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  twenty       | LM: -13.7545 | Error:  -1.0986 | Combined: -13.1217\n",
      "  wet          | LM: -12.9471 | Error:  -1.0986 | Combined: -12.3547\n",
      "  bent         | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  unto         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  wants        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  cents        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "Token: 'wento' | Context: ('``',)\n",
      "Candidate scores:\n",
      "  rent         | LM: -14.2178 | Error:  -1.0986 | Combined: -13.5618\n",
      "  want         | LM: -14.2178 | Error:  -1.0986 | Combined: -13.5618\n",
      "  sent         | LM: -14.2178 | Error:  -1.0986 | Combined: -13.5618\n",
      "  tent         | LM: -14.2178 | Error:  -1.0986 | Combined: -13.5618\n",
      "  onto         | LM: -14.2178 | Error:  -1.0986 | Combined: -13.5618\n",
      "  went         | LM: -12.6328 | Error:  -0.6931 | Combined: -12.0359\n",
      "  cent         | LM: -14.2178 | Error:  -1.0986 | Combined: -13.5618\n",
      "  west         | LM: -13.2178 | Error:  -1.0986 | Combined: -12.6118\n",
      "  into         | LM: -11.8959 | Error:  -1.0986 | Combined: -11.3560\n",
      "  twenty       | LM: -14.2178 | Error:  -1.0986 | Combined: -13.5618\n",
      "  wet          | LM: -13.2178 | Error:  -1.0986 | Combined: -12.6118\n",
      "  bent         | LM: -14.2178 | Error:  -1.0986 | Combined: -13.5618\n",
      "  unto         | LM: -14.2178 | Error:  -1.0986 | Combined: -13.5618\n",
      "  wants        | LM: -14.2178 | Error:  -1.0986 | Combined: -13.5618\n",
      "  cents        | LM: -14.2178 | Error:  -1.0986 | Combined: -13.5618\n",
      "Token: 'wento' | Context: ('he',)\n",
      "Candidate scores:\n",
      "  rent         | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "  want         | LM: -11.7233 | Error:  -1.0986 | Combined: -11.1921\n",
      "  sent         | LM: -11.4014 | Error:  -1.0986 | Combined: -10.8863\n",
      "  tent         | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "  onto         | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "  went         | LM:  -7.6573 | Error:  -0.6931 | Combined:  -7.3090\n",
      "  cent         | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "  west         | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "  into         | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "  twenty       | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "  wet          | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "  bent         | LM: -12.7233 | Error:  -1.0986 | Combined: -12.1421\n",
      "  unto         | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "  wants        | LM:  -9.9160 | Error:  -1.0986 | Combined:  -9.4751\n",
      "  cents        | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "Token: 'wento' | Context: ('?',)\n",
      "Candidate scores:\n",
      "  rent         | LM: -13.2753 | Error:  -1.0986 | Combined: -12.6664\n",
      "  want         | LM: -13.2753 | Error:  -1.0986 | Combined: -12.6664\n",
      "  sent         | LM: -13.2753 | Error:  -1.0986 | Combined: -12.6664\n",
      "  tent         | LM: -13.2753 | Error:  -1.0986 | Combined: -12.6664\n",
      "  onto         | LM: -13.2753 | Error:  -1.0986 | Combined: -12.6664\n",
      "  went         | LM: -13.2753 | Error:  -0.6931 | Combined: -12.6461\n",
      "  cent         | LM: -13.2753 | Error:  -1.0986 | Combined: -12.6664\n",
      "  west         | LM: -13.2753 | Error:  -1.0986 | Combined: -12.6664\n",
      "  into         | LM: -13.2753 | Error:  -1.0986 | Combined: -12.6664\n",
      "  twenty       | LM: -13.2753 | Error:  -1.0986 | Combined: -12.6664\n",
      "  wet          | LM: -13.2753 | Error:  -1.0986 | Combined: -12.6664\n",
      "  bent         | LM: -13.2753 | Error:  -1.0986 | Combined: -12.6664\n",
      "  unto         | LM: -13.2753 | Error:  -1.0986 | Combined: -12.6664\n",
      "  wants        | LM: -13.2753 | Error:  -1.0986 | Combined: -12.6664\n",
      "  cents        | LM: -13.2753 | Error:  -1.0986 | Combined: -12.6664\n",
      "Token: 'wento' | Context: ('it',)\n",
      "Candidate scores:\n",
      "  rent         | LM: -13.6680 | Error:  -1.0986 | Combined: -13.0395\n",
      "  want         | LM: -13.6680 | Error:  -1.0986 | Combined: -13.0395\n",
      "  sent         | LM: -13.6680 | Error:  -1.0986 | Combined: -13.0395\n",
      "  tent         | LM: -13.6680 | Error:  -1.0986 | Combined: -13.0395\n",
      "  onto         | LM: -12.0830 | Error:  -1.0986 | Combined: -11.5338\n",
      "  went         | LM: -10.8606 | Error:  -0.6931 | Combined: -10.3523\n",
      "  cent         | LM: -13.6680 | Error:  -1.0986 | Combined: -13.0395\n",
      "  west         | LM: -13.6680 | Error:  -1.0986 | Combined: -13.0395\n",
      "  into         | LM:  -9.8606 | Error:  -1.0986 | Combined:  -9.4225\n",
      "  twenty       | LM: -13.6680 | Error:  -1.0986 | Combined: -13.0395\n",
      "  wet          | LM: -13.6680 | Error:  -1.0986 | Combined: -13.0395\n",
      "  bent         | LM: -13.6680 | Error:  -1.0986 | Combined: -13.0395\n",
      "  unto         | LM: -13.6680 | Error:  -1.0986 | Combined: -13.0395\n",
      "  wants        | LM: -13.6680 | Error:  -1.0986 | Combined: -13.0395\n",
      "  cents        | LM: -13.6680 | Error:  -1.0986 | Combined: -13.0395\n",
      "Top selected tokens: ['went', 'west', 'wants', 'into', 'went']\n",
      "\n",
      "Token: 'too' | Context: ('went',)\n",
      "Candidate scores:\n",
      "  too          | LM: -12.7719 | Error:  +0.0000 | Combined: -12.1333\n",
      "Token: 'too' | Context: ('west',)\n",
      "Candidate scores:\n",
      "  too          | LM: -12.7328 | Error:  +0.0000 | Combined: -12.0962\n",
      "Token: 'too' | Context: ('wants',)\n",
      "Candidate scores:\n",
      "  too          | LM: -12.7054 | Error:  +0.0000 | Combined: -12.0701\n",
      "Token: 'too' | Context: ('into',)\n",
      "Candidate scores:\n",
      "  too          | LM: -12.9421 | Error:  +0.0000 | Combined: -12.2950\n",
      "Token: 'too' | Context: ('went',)\n",
      "Candidate scores:\n",
      "  too          | LM: -12.7719 | Error:  +0.0000 | Combined: -12.1333\n",
      "Top selected tokens: ['too', 'too', 'too', 'too', 'too']\n",
      "\n",
      "Token: 'the' | Context: ('too',)\n",
      "Candidate scores:\n",
      "  the          | LM: -11.8176 | Error:  +0.0000 | Combined: -11.2267\n",
      "Token: 'the' | Context: ('too',)\n",
      "Candidate scores:\n",
      "  the          | LM: -11.8176 | Error:  +0.0000 | Combined: -11.2267\n",
      "Token: 'the' | Context: ('too',)\n",
      "Candidate scores:\n",
      "  the          | LM: -11.8176 | Error:  +0.0000 | Combined: -11.2267\n",
      "Token: 'the' | Context: ('too',)\n",
      "Candidate scores:\n",
      "  the          | LM: -11.8176 | Error:  +0.0000 | Combined: -11.2267\n",
      "Token: 'the' | Context: ('too',)\n",
      "Candidate scores:\n",
      "  the          | LM: -11.8176 | Error:  +0.0000 | Combined: -11.2267\n",
      "Top selected tokens: ['the', 'the', 'the', 'the', 'the']\n",
      "\n",
      "Token: 'storr' | Context: ('the',)\n",
      "Candidate scores:\n",
      "  stove        | LM: -12.9471 | Error:  -1.0986 | Combined: -12.3547\n",
      "  stone        | LM: -12.7545 | Error:  -1.0986 | Combined: -12.1717\n",
      "  tore         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  stars        | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  start        | LM: -12.0540 | Error:  -1.0986 | Combined: -11.5063\n",
      "  sort         | LM: -11.3622 | Error:  -1.0986 | Combined: -10.8490\n",
      "  stood        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  tour         | LM: -12.5845 | Error:  -1.0986 | Combined: -12.0102\n",
      "  stores       | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  stop         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  star         | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  score        | LM: -12.4325 | Error:  -1.0986 | Combined: -11.8658\n",
      "  shore        | LM: -12.7545 | Error:  -1.0986 | Combined: -12.1717\n",
      "  torn         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  stern        | LM: -13.1695 | Error:  -1.0986 | Combined: -12.5660\n",
      "  sport        | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  stored       | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  sorry        | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  storm        | LM: -13.1695 | Error:  -0.6931 | Combined: -12.5457\n",
      "  store        | LM: -12.0540 | Error:  -0.6931 | Combined: -11.4860\n",
      "  story        | LM: -10.7101 | Error:  -0.6931 | Combined: -10.2092\n",
      "  stock        | LM: -11.5065 | Error:  -1.0986 | Combined: -10.9861\n",
      "  short        | LM: -12.5845 | Error:  -1.0986 | Combined: -12.0102\n",
      "  stare        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "Token: 'storr' | Context: ('the',)\n",
      "Candidate scores:\n",
      "  stove        | LM: -12.9471 | Error:  -1.0986 | Combined: -12.3547\n",
      "  stone        | LM: -12.7545 | Error:  -1.0986 | Combined: -12.1717\n",
      "  tore         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  stars        | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  start        | LM: -12.0540 | Error:  -1.0986 | Combined: -11.5063\n",
      "  sort         | LM: -11.3622 | Error:  -1.0986 | Combined: -10.8490\n",
      "  stood        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  tour         | LM: -12.5845 | Error:  -1.0986 | Combined: -12.0102\n",
      "  stores       | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  stop         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  star         | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  score        | LM: -12.4325 | Error:  -1.0986 | Combined: -11.8658\n",
      "  shore        | LM: -12.7545 | Error:  -1.0986 | Combined: -12.1717\n",
      "  torn         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  stern        | LM: -13.1695 | Error:  -1.0986 | Combined: -12.5660\n",
      "  sport        | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  stored       | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  sorry        | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  storm        | LM: -13.1695 | Error:  -0.6931 | Combined: -12.5457\n",
      "  store        | LM: -12.0540 | Error:  -0.6931 | Combined: -11.4860\n",
      "  story        | LM: -10.7101 | Error:  -0.6931 | Combined: -10.2092\n",
      "  stock        | LM: -11.5065 | Error:  -1.0986 | Combined: -10.9861\n",
      "  short        | LM: -12.5845 | Error:  -1.0986 | Combined: -12.0102\n",
      "  stare        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "Token: 'storr' | Context: ('the',)\n",
      "Candidate scores:\n",
      "  stove        | LM: -12.9471 | Error:  -1.0986 | Combined: -12.3547\n",
      "  stone        | LM: -12.7545 | Error:  -1.0986 | Combined: -12.1717\n",
      "  tore         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  stars        | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  start        | LM: -12.0540 | Error:  -1.0986 | Combined: -11.5063\n",
      "  sort         | LM: -11.3622 | Error:  -1.0986 | Combined: -10.8490\n",
      "  stood        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  tour         | LM: -12.5845 | Error:  -1.0986 | Combined: -12.0102\n",
      "  stores       | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  stop         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  star         | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  score        | LM: -12.4325 | Error:  -1.0986 | Combined: -11.8658\n",
      "  shore        | LM: -12.7545 | Error:  -1.0986 | Combined: -12.1717\n",
      "  torn         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  stern        | LM: -13.1695 | Error:  -1.0986 | Combined: -12.5660\n",
      "  sport        | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  stored       | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  sorry        | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  storm        | LM: -13.1695 | Error:  -0.6931 | Combined: -12.5457\n",
      "  store        | LM: -12.0540 | Error:  -0.6931 | Combined: -11.4860\n",
      "  story        | LM: -10.7101 | Error:  -0.6931 | Combined: -10.2092\n",
      "  stock        | LM: -11.5065 | Error:  -1.0986 | Combined: -10.9861\n",
      "  short        | LM: -12.5845 | Error:  -1.0986 | Combined: -12.0102\n",
      "  stare        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "Token: 'storr' | Context: ('the',)\n",
      "Candidate scores:\n",
      "  stove        | LM: -12.9471 | Error:  -1.0986 | Combined: -12.3547\n",
      "  stone        | LM: -12.7545 | Error:  -1.0986 | Combined: -12.1717\n",
      "  tore         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  stars        | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  start        | LM: -12.0540 | Error:  -1.0986 | Combined: -11.5063\n",
      "  sort         | LM: -11.3622 | Error:  -1.0986 | Combined: -10.8490\n",
      "  stood        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  tour         | LM: -12.5845 | Error:  -1.0986 | Combined: -12.0102\n",
      "  stores       | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  stop         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  star         | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  score        | LM: -12.4325 | Error:  -1.0986 | Combined: -11.8658\n",
      "  shore        | LM: -12.7545 | Error:  -1.0986 | Combined: -12.1717\n",
      "  torn         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  stern        | LM: -13.1695 | Error:  -1.0986 | Combined: -12.5660\n",
      "  sport        | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  stored       | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  sorry        | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  storm        | LM: -13.1695 | Error:  -0.6931 | Combined: -12.5457\n",
      "  store        | LM: -12.0540 | Error:  -0.6931 | Combined: -11.4860\n",
      "  story        | LM: -10.7101 | Error:  -0.6931 | Combined: -10.2092\n",
      "  stock        | LM: -11.5065 | Error:  -1.0986 | Combined: -10.9861\n",
      "  short        | LM: -12.5845 | Error:  -1.0986 | Combined: -12.0102\n",
      "  stare        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "Token: 'storr' | Context: ('the',)\n",
      "Candidate scores:\n",
      "  stove        | LM: -12.9471 | Error:  -1.0986 | Combined: -12.3547\n",
      "  stone        | LM: -12.7545 | Error:  -1.0986 | Combined: -12.1717\n",
      "  tore         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  stars        | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  start        | LM: -12.0540 | Error:  -1.0986 | Combined: -11.5063\n",
      "  sort         | LM: -11.3622 | Error:  -1.0986 | Combined: -10.8490\n",
      "  stood        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  tour         | LM: -12.5845 | Error:  -1.0986 | Combined: -12.0102\n",
      "  stores       | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  stop         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  star         | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  score        | LM: -12.4325 | Error:  -1.0986 | Combined: -11.8658\n",
      "  shore        | LM: -12.7545 | Error:  -1.0986 | Combined: -12.1717\n",
      "  torn         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  stern        | LM: -13.1695 | Error:  -1.0986 | Combined: -12.5660\n",
      "  sport        | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  stored       | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  sorry        | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  storm        | LM: -13.1695 | Error:  -0.6931 | Combined: -12.5457\n",
      "  store        | LM: -12.0540 | Error:  -0.6931 | Combined: -11.4860\n",
      "  story        | LM: -10.7101 | Error:  -0.6931 | Combined: -10.2092\n",
      "  stock        | LM: -11.5065 | Error:  -1.0986 | Combined: -10.9861\n",
      "  short        | LM: -12.5845 | Error:  -1.0986 | Combined: -12.0102\n",
      "  stare        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "Top selected tokens: ['story', 'story', 'sort', 'stock', 'sort']\n",
      "\n",
      "Token: 'to' | Context: ('story',)\n",
      "Candidate scores:\n",
      "  to           | LM: -12.7155 | Error:  +0.0000 | Combined: -12.0798\n",
      "Token: 'to' | Context: ('story',)\n",
      "Candidate scores:\n",
      "  to           | LM: -12.7155 | Error:  +0.0000 | Combined: -12.0798\n",
      "Token: 'to' | Context: ('sort',)\n",
      "Candidate scores:\n",
      "  to           | LM: -10.7222 | Error:  +0.0000 | Combined: -10.1861\n",
      "Token: 'to' | Context: ('stock',)\n",
      "Candidate scores:\n",
      "  to           | LM: -10.7177 | Error:  +0.0000 | Combined: -10.1818\n",
      "Token: 'to' | Context: ('sort',)\n",
      "Candidate scores:\n",
      "  to           | LM: -10.7222 | Error:  +0.0000 | Combined: -10.1861\n",
      "Top selected tokens: ['to', 'to', 'to', 'to', 'to']\n",
      "\n",
      "Token: 'by' | Context: ('to',)\n",
      "Candidate scores:\n",
      "  by           | LM: -12.6092 | Error:  +0.0000 | Combined: -11.9788\n",
      "Token: 'by' | Context: ('to',)\n",
      "Candidate scores:\n",
      "  by           | LM: -12.6092 | Error:  +0.0000 | Combined: -11.9788\n",
      "Token: 'by' | Context: ('to',)\n",
      "Candidate scores:\n",
      "  by           | LM: -12.6092 | Error:  +0.0000 | Combined: -11.9788\n",
      "Token: 'by' | Context: ('to',)\n",
      "Candidate scores:\n",
      "  by           | LM: -12.6092 | Error:  +0.0000 | Combined: -11.9788\n",
      "Token: 'by' | Context: ('to',)\n",
      "Candidate scores:\n",
      "  by           | LM: -12.6092 | Error:  +0.0000 | Combined: -11.9788\n",
      "Top selected tokens: ['by', 'by', 'by', 'by', 'by']\n",
      "\n",
      "Token: 'some' | Context: ('by',)\n",
      "Candidate scores:\n",
      "  some         | LM:  -8.7585 | Error:  +0.0000 | Combined:  -8.3206\n",
      "Token: 'some' | Context: ('by',)\n",
      "Candidate scores:\n",
      "  some         | LM:  -8.7585 | Error:  +0.0000 | Combined:  -8.3206\n",
      "Token: 'some' | Context: ('by',)\n",
      "Candidate scores:\n",
      "  some         | LM:  -8.7585 | Error:  +0.0000 | Combined:  -8.3206\n",
      "Token: 'some' | Context: ('by',)\n",
      "Candidate scores:\n",
      "  some         | LM:  -8.7585 | Error:  +0.0000 | Combined:  -8.3206\n",
      "Token: 'some' | Context: ('by',)\n",
      "Candidate scores:\n",
      "  some         | LM:  -8.7585 | Error:  +0.0000 | Combined:  -8.3206\n",
      "Top selected tokens: ['some', 'some', 'some', 'some', 'some']\n",
      "\n",
      "Token: 'bred' | Context: ('some',)\n",
      "Candidate scores:\n",
      "  rod          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  beds         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  cared        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bold         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  ed           | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bride        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  led          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bird         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fed          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  seed         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  area         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  broad        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  used         | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  cried        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  urged        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bad          | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  bod          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  based        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fled         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tired        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fired        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  hired        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  freed        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  read         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  beef         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tied         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  rev          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  greg         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  crew         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bend         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  need         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  dried        | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  free         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bed          | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  drew         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  grey         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  ben          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  be           | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  're          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  grew         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  buried       | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bore         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  brief        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bet          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bare         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  burned       | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  break        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  band         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  brand        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tried        | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  breed        | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  are          | LM: -10.1188 | Error:  -1.0986 | Combined:  -9.6677\n",
      "  bread        | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  feed         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  dared        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tree         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  aged         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  died         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  freud        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  red          | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  armed        | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  trend        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bid          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bond         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fred         | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  beer         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  been         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "Token: 'bred' | Context: ('some',)\n",
      "Candidate scores:\n",
      "  rod          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  beds         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  cared        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bold         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  ed           | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bride        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  led          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bird         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fed          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  seed         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  area         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  broad        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  used         | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  cried        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  urged        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bad          | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  bod          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  based        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fled         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tired        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fired        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  hired        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  freed        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  read         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  beef         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tied         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  rev          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  greg         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  crew         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bend         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  need         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  dried        | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  free         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bed          | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  drew         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  grey         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  ben          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  be           | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  're          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  grew         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  buried       | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bore         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  brief        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bet          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bare         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  burned       | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  break        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  band         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  brand        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tried        | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  breed        | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  are          | LM: -10.1188 | Error:  -1.0986 | Combined:  -9.6677\n",
      "  bread        | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  feed         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  dared        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tree         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  aged         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  died         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  freud        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  red          | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  armed        | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  trend        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bid          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bond         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fred         | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  beer         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  been         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "Token: 'bred' | Context: ('some',)\n",
      "Candidate scores:\n",
      "  rod          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  beds         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  cared        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bold         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  ed           | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bride        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  led          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bird         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fed          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  seed         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  area         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  broad        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  used         | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  cried        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  urged        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bad          | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  bod          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  based        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fled         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tired        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fired        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  hired        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  freed        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  read         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  beef         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tied         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  rev          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  greg         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  crew         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bend         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  need         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  dried        | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  free         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bed          | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  drew         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  grey         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  ben          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  be           | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  're          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  grew         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  buried       | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bore         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  brief        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bet          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bare         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  burned       | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  break        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  band         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  brand        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tried        | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  breed        | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  are          | LM: -10.1188 | Error:  -1.0986 | Combined:  -9.6677\n",
      "  bread        | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  feed         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  dared        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tree         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  aged         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  died         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  freud        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  red          | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  armed        | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  trend        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bid          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bond         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fred         | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  beer         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  been         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "Token: 'bred' | Context: ('some',)\n",
      "Candidate scores:\n",
      "  rod          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  beds         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  cared        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bold         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  ed           | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bride        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  led          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bird         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fed          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  seed         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  area         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  broad        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  used         | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  cried        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  urged        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bad          | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  bod          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  based        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fled         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tired        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fired        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  hired        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  freed        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  read         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  beef         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tied         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  rev          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  greg         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  crew         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bend         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  need         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  dried        | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  free         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bed          | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  drew         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  grey         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  ben          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  be           | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  're          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  grew         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  buried       | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bore         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  brief        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bet          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bare         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  burned       | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  break        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  band         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  brand        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tried        | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  breed        | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  are          | LM: -10.1188 | Error:  -1.0986 | Combined:  -9.6677\n",
      "  bread        | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  feed         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  dared        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tree         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  aged         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  died         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  freud        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  red          | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  armed        | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  trend        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bid          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bond         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fred         | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  beer         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  been         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "Token: 'bred' | Context: ('some',)\n",
      "Candidate scores:\n",
      "  rod          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  beds         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  cared        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bold         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  ed           | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bride        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  led          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bird         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fed          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  seed         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  area         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  broad        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  used         | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  cried        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  urged        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bad          | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  bod          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  based        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fled         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tired        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fired        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  hired        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  freed        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  read         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  beef         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tied         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  rev          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  greg         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  crew         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bend         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  need         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  dried        | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  free         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bed          | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  drew         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  grey         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  ben          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  be           | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  're          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  grew         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  buried       | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bore         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  brief        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bet          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bare         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  burned       | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  break        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  band         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  brand        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tried        | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  breed        | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  are          | LM: -10.1188 | Error:  -1.0986 | Combined:  -9.6677\n",
      "  bread        | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  feed         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  dared        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  tree         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  aged         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  died         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  freud        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  red          | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  armed        | LM: -11.9261 | Error:  -1.0986 | Combined: -11.3847\n",
      "  trend        | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bid          | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  bond         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  fred         | LM: -12.9261 | Error:  -0.6931 | Combined: -12.3145\n",
      "  beer         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "  been         | LM: -12.9261 | Error:  -1.0986 | Combined: -12.3347\n",
      "Top selected tokens: ['are', 'are', 'are', 'are', 'are']\n",
      "\n",
      "Token: 'and' | Context: ('are',)\n",
      "Candidate scores:\n",
      "  and          | LM: -11.6674 | Error:  +0.0000 | Combined: -11.0840\n",
      "Token: 'and' | Context: ('are',)\n",
      "Candidate scores:\n",
      "  and          | LM: -11.6674 | Error:  +0.0000 | Combined: -11.0840\n",
      "Token: 'and' | Context: ('are',)\n",
      "Candidate scores:\n",
      "  and          | LM: -11.6674 | Error:  +0.0000 | Combined: -11.0840\n",
      "Token: 'and' | Context: ('are',)\n",
      "Candidate scores:\n",
      "  and          | LM: -11.6674 | Error:  +0.0000 | Combined: -11.0840\n",
      "Token: 'and' | Context: ('are',)\n",
      "Candidate scores:\n",
      "  and          | LM: -11.6674 | Error:  +0.0000 | Combined: -11.0840\n",
      "Top selected tokens: ['and', 'and', 'and', 'and', 'and']\n",
      "\n",
      "Token: 'mlik' | Context: ('and',)\n",
      "Candidate scores:\n",
      "  main         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  lie          | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  lid          | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  like         | LM: -12.7109 | Error:  -1.0986 | Combined: -12.1302\n",
      "  monk         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  slip         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  mark         | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  lip          | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  alike        | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  mike         | LM: -13.1259 | Error:  -1.0986 | Combined: -12.5245\n",
      "  slid         | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  mail         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  slim         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  lit          | LM: -12.7109 | Error:  -1.0986 | Combined: -12.1302\n",
      "  milk         | LM: -13.1259 | Error:  -1.0986 | Combined: -12.5245\n",
      "  maid         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  link         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "Token: 'mlik' | Context: ('and',)\n",
      "Candidate scores:\n",
      "  main         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  lie          | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  lid          | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  like         | LM: -12.7109 | Error:  -1.0986 | Combined: -12.1302\n",
      "  monk         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  slip         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  mark         | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  lip          | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  alike        | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  mike         | LM: -13.1259 | Error:  -1.0986 | Combined: -12.5245\n",
      "  slid         | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  mail         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  slim         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  lit          | LM: -12.7109 | Error:  -1.0986 | Combined: -12.1302\n",
      "  milk         | LM: -13.1259 | Error:  -1.0986 | Combined: -12.5245\n",
      "  maid         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  link         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "Token: 'mlik' | Context: ('and',)\n",
      "Candidate scores:\n",
      "  main         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  lie          | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  lid          | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  like         | LM: -12.7109 | Error:  -1.0986 | Combined: -12.1302\n",
      "  monk         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  slip         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  mark         | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  lip          | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  alike        | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  mike         | LM: -13.1259 | Error:  -1.0986 | Combined: -12.5245\n",
      "  slid         | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  mail         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  slim         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  lit          | LM: -12.7109 | Error:  -1.0986 | Combined: -12.1302\n",
      "  milk         | LM: -13.1259 | Error:  -1.0986 | Combined: -12.5245\n",
      "  maid         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  link         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "Token: 'mlik' | Context: ('and',)\n",
      "Candidate scores:\n",
      "  main         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  lie          | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  lid          | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  like         | LM: -12.7109 | Error:  -1.0986 | Combined: -12.1302\n",
      "  monk         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  slip         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  mark         | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  lip          | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  alike        | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  mike         | LM: -13.1259 | Error:  -1.0986 | Combined: -12.5245\n",
      "  slid         | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  mail         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  slim         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  lit          | LM: -12.7109 | Error:  -1.0986 | Combined: -12.1302\n",
      "  milk         | LM: -13.1259 | Error:  -1.0986 | Combined: -12.5245\n",
      "  maid         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  link         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "Token: 'mlik' | Context: ('and',)\n",
      "Candidate scores:\n",
      "  main         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  lie          | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  lid          | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  like         | LM: -12.7109 | Error:  -1.0986 | Combined: -12.1302\n",
      "  monk         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  slip         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  mark         | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  lip          | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  alike        | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  mike         | LM: -13.1259 | Error:  -1.0986 | Combined: -12.5245\n",
      "  slid         | LM: -13.7109 | Error:  -1.0986 | Combined: -13.0802\n",
      "  mail         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  slim         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  lit          | LM: -12.7109 | Error:  -1.0986 | Combined: -12.1302\n",
      "  milk         | LM: -13.1259 | Error:  -1.0986 | Combined: -12.5245\n",
      "  maid         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "  link         | LM: -14.7109 | Error:  -1.0986 | Combined: -14.0302\n",
      "Top selected tokens: ['like', 'lit', 'like', 'lit', 'mike']\n",
      "\n",
      "Token: '.' | Context: ('like',)\n",
      "Candidate scores:\n",
      "  .            | LM:  -8.9767 | Error:  +0.0000 | Combined:  -8.5279\n",
      "Token: '.' | Context: ('lit',)\n",
      "Candidate scores:\n",
      "  .            | LM: -12.6991 | Error:  +0.0000 | Combined: -12.0642\n",
      "Token: '.' | Context: ('like',)\n",
      "Candidate scores:\n",
      "  .            | LM:  -8.9767 | Error:  +0.0000 | Combined:  -8.5279\n",
      "Token: '.' | Context: ('lit',)\n",
      "Candidate scores:\n",
      "  .            | LM: -12.6991 | Error:  +0.0000 | Combined: -12.0642\n",
      "Token: '.' | Context: ('mike',)\n",
      "Candidate scores:\n",
      "  .            | LM: -10.3887 | Error:  +0.0000 | Combined:  -9.8692\n",
      "Top selected tokens: ['.', '.', '.', '.', '.']\n",
      "\n",
      "Final corrected sentence: he went too the sort to by some are and like .\n",
      "Bigram model produced:\n",
      "  he went too the sort to by some are and like .\n",
      "\n",
      "Testing with sentence: \"Ths is an exampel of a sentense with severl erors.\"\n",
      "Starting correction for sentence: Ths is an exampel of a sentense with severl erors .\n",
      "Token: 'Ths' | Context: ('<start>',)\n",
      "Candidate scores:\n",
      "  why          | LM:  -9.4530 | Error:  -1.0986 | Combined:  -9.0353\n",
      "  s            | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  his          | LM:  -7.1891 | Error:  -1.0986 | Combined:  -6.8846\n",
      "  this         | LM:  -5.8410 | Error:  -1.0986 | Combined:  -5.6039\n",
      "  us           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  ah           | LM: -12.9125 | Error:  -1.0986 | Combined: -12.3218\n",
      "  gas          | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  its          | LM:  -9.7695 | Error:  -1.0986 | Combined:  -9.3360\n",
      "  who          | LM: -10.6394 | Error:  -1.0986 | Combined: -10.1624\n",
      "  shu          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  thus         | LM:  -8.7559 | Error:  -1.0986 | Combined:  -8.3731\n",
      "  the          | LM:  -3.3882 | Error:  -1.0986 | Combined:  -3.2738\n",
      "  's           | LM: -13.1755 | Error:  -1.0986 | Combined: -12.5716\n",
      "  she          | LM:  -6.1710 | Error:  -1.0986 | Combined:  -5.9174\n",
      "  oh           | LM: -10.8536 | Error:  -1.0986 | Combined: -10.3658\n",
      "  yes          | LM: -10.6901 | Error:  -1.0986 | Combined: -10.2105\n",
      "  as           | LM:  -6.9660 | Error:  -1.0986 | Combined:  -6.6727\n",
      "  thy          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  h.           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  was          | LM: -10.3681 | Error:  -1.0986 | Combined:  -9.9047\n",
      "  los          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  he           | LM:  -4.5137 | Error:  -1.0986 | Combined:  -4.3430\n",
      "  has          | LM: -13.4974 | Error:  -1.0986 | Combined: -12.8775\n",
      "  h            | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  is           | LM:  -9.8536 | Error:  -1.0986 | Combined:  -9.4158\n",
      "  bus          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  shy          | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "Top selected tokens: ['the', 'he', 'this', 'she', 'as']\n",
      "\n",
      "Token: 'is' | Context: ('the',)\n",
      "Candidate scores:\n",
      "  is           | LM: -14.7545 | Error:  +0.0000 | Combined: -14.0167\n",
      "Token: 'is' | Context: ('he',)\n",
      "Candidate scores:\n",
      "  is           | LM:  -5.9420 | Error:  +0.0000 | Combined:  -5.6449\n",
      "Token: 'is' | Context: ('this',)\n",
      "Candidate scores:\n",
      "  is           | LM:  -5.0381 | Error:  +0.0000 | Combined:  -4.7862\n",
      "Token: 'is' | Context: ('she',)\n",
      "Candidate scores:\n",
      "  is           | LM:  -8.2331 | Error:  +0.0000 | Combined:  -7.8215\n",
      "Token: 'is' | Context: ('as',)\n",
      "Candidate scores:\n",
      "  is           | LM:  -9.8186 | Error:  +0.0000 | Combined:  -9.3277\n",
      "Top selected tokens: ['is', 'is', 'is', 'is', 'is']\n",
      "\n",
      "Token: 'an' | Context: ('is',)\n",
      "Candidate scores:\n",
      "  an           | LM:  -6.9045 | Error:  +0.0000 | Combined:  -6.5593\n",
      "Token: 'an' | Context: ('is',)\n",
      "Candidate scores:\n",
      "  an           | LM:  -6.9045 | Error:  +0.0000 | Combined:  -6.5593\n",
      "Token: 'an' | Context: ('is',)\n",
      "Candidate scores:\n",
      "  an           | LM:  -6.9045 | Error:  +0.0000 | Combined:  -6.5593\n",
      "Token: 'an' | Context: ('is',)\n",
      "Candidate scores:\n",
      "  an           | LM:  -6.9045 | Error:  +0.0000 | Combined:  -6.5593\n",
      "Token: 'an' | Context: ('is',)\n",
      "Candidate scores:\n",
      "  an           | LM:  -6.9045 | Error:  +0.0000 | Combined:  -6.5593\n",
      "Top selected tokens: ['an', 'an', 'an', 'an', 'an']\n",
      "\n",
      "Token: 'exampel' | Context: ('an',)\n",
      "Candidate scores:\n",
      "  example      | LM:  -8.8530 | Error:  -1.0986 | Combined:  -8.4653\n",
      "  examples     | LM: -13.1749 | Error:  -1.0986 | Combined: -12.5711\n",
      "Token: 'exampel' | Context: ('an',)\n",
      "Candidate scores:\n",
      "  example      | LM:  -8.8530 | Error:  -1.0986 | Combined:  -8.4653\n",
      "  examples     | LM: -13.1749 | Error:  -1.0986 | Combined: -12.5711\n",
      "Token: 'exampel' | Context: ('an',)\n",
      "Candidate scores:\n",
      "  example      | LM:  -8.8530 | Error:  -1.0986 | Combined:  -8.4653\n",
      "  examples     | LM: -13.1749 | Error:  -1.0986 | Combined: -12.5711\n",
      "Token: 'exampel' | Context: ('an',)\n",
      "Candidate scores:\n",
      "  example      | LM:  -8.8530 | Error:  -1.0986 | Combined:  -8.4653\n",
      "  examples     | LM: -13.1749 | Error:  -1.0986 | Combined: -12.5711\n",
      "Token: 'exampel' | Context: ('an',)\n",
      "Candidate scores:\n",
      "  example      | LM:  -8.8530 | Error:  -1.0986 | Combined:  -8.4653\n",
      "  examples     | LM: -13.1749 | Error:  -1.0986 | Combined: -12.5711\n",
      "Top selected tokens: ['example', 'example', 'example', 'examples', 'examples']\n",
      "\n",
      "Token: 'of' | Context: ('example',)\n",
      "Candidate scores:\n",
      "  of           | LM:  -7.6941 | Error:  +0.0000 | Combined:  -7.3094\n",
      "Token: 'of' | Context: ('example',)\n",
      "Candidate scores:\n",
      "  of           | LM:  -7.6941 | Error:  +0.0000 | Combined:  -7.3094\n",
      "Token: 'of' | Context: ('example',)\n",
      "Candidate scores:\n",
      "  of           | LM:  -7.6941 | Error:  +0.0000 | Combined:  -7.3094\n",
      "Token: 'of' | Context: ('examples',)\n",
      "Candidate scores:\n",
      "  of           | LM:  -8.6177 | Error:  +0.0000 | Combined:  -8.1869\n",
      "Token: 'of' | Context: ('examples',)\n",
      "Candidate scores:\n",
      "  of           | LM:  -8.6177 | Error:  +0.0000 | Combined:  -8.1869\n",
      "Top selected tokens: ['of', 'of', 'of', 'of', 'of']\n",
      "\n",
      "Token: 'a' | Context: ('of',)\n",
      "Candidate scores:\n",
      "  a            | LM:  -4.9643 | Error:  +0.0000 | Combined:  -4.7161\n",
      "Token: 'a' | Context: ('of',)\n",
      "Candidate scores:\n",
      "  a            | LM:  -4.9643 | Error:  +0.0000 | Combined:  -4.7161\n",
      "Token: 'a' | Context: ('of',)\n",
      "Candidate scores:\n",
      "  a            | LM:  -4.9643 | Error:  +0.0000 | Combined:  -4.7161\n",
      "Token: 'a' | Context: ('of',)\n",
      "Candidate scores:\n",
      "  a            | LM:  -4.9643 | Error:  +0.0000 | Combined:  -4.7161\n",
      "Token: 'a' | Context: ('of',)\n",
      "Candidate scores:\n",
      "  a            | LM:  -4.9643 | Error:  +0.0000 | Combined:  -4.7161\n",
      "Top selected tokens: ['a', 'a', 'a', 'a', 'a']\n",
      "\n",
      "Token: 'sentense' | Context: ('a',)\n",
      "Candidate scores:\n",
      "  sentences    | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  sentence     | LM: -12.4819 | Error:  -0.6931 | Combined: -11.8925\n",
      "  intense      | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "Token: 'sentense' | Context: ('a',)\n",
      "Candidate scores:\n",
      "  sentences    | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  sentence     | LM: -12.4819 | Error:  -0.6931 | Combined: -11.8925\n",
      "  intense      | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "Token: 'sentense' | Context: ('a',)\n",
      "Candidate scores:\n",
      "  sentences    | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  sentence     | LM: -12.4819 | Error:  -0.6931 | Combined: -11.8925\n",
      "  intense      | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "Token: 'sentense' | Context: ('a',)\n",
      "Candidate scores:\n",
      "  sentences    | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  sentence     | LM: -12.4819 | Error:  -0.6931 | Combined: -11.8925\n",
      "  intense      | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "Token: 'sentense' | Context: ('a',)\n",
      "Candidate scores:\n",
      "  sentences    | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "  sentence     | LM: -12.4819 | Error:  -0.6931 | Combined: -11.8925\n",
      "  intense      | LM: -14.4819 | Error:  -1.0986 | Combined: -13.8128\n",
      "Top selected tokens: ['sentence', 'sentence', 'sentences', 'intense', 'sentences']\n",
      "\n",
      "Token: 'with' | Context: ('sentence',)\n",
      "Candidate scores:\n",
      "  with         | LM: -12.7022 | Error:  +0.0000 | Combined: -12.0671\n",
      "Token: 'with' | Context: ('sentence',)\n",
      "Candidate scores:\n",
      "  with         | LM: -12.7022 | Error:  +0.0000 | Combined: -12.0671\n",
      "Token: 'with' | Context: ('sentences',)\n",
      "Candidate scores:\n",
      "  with         | LM: -12.6987 | Error:  +0.0000 | Combined: -12.0638\n",
      "Token: 'with' | Context: ('intense',)\n",
      "Candidate scores:\n",
      "  with         | LM: -12.7024 | Error:  +0.0000 | Combined: -12.0673\n",
      "Token: 'with' | Context: ('sentences',)\n",
      "Candidate scores:\n",
      "  with         | LM: -12.6987 | Error:  +0.0000 | Combined: -12.0638\n",
      "Top selected tokens: ['with', 'with', 'with', 'with', 'with']\n",
      "\n",
      "Token: 'severl' | Context: ('with',)\n",
      "Candidate scores:\n",
      "  ever         | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  fever        | LM: -12.5153 | Error:  -1.0986 | Combined: -11.9445\n",
      "  severe       | LM: -13.5153 | Error:  -0.6931 | Combined: -12.8742\n",
      "  seven        | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  several      | LM: -11.1934 | Error:  -0.6931 | Combined: -10.6684\n",
      "  level        | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  every        | LM: -10.5153 | Error:  -1.0986 | Combined: -10.0445\n",
      "  never        | LM: -12.5153 | Error:  -1.0986 | Combined: -11.9445\n",
      "  severely     | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  reveal       | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "Token: 'severl' | Context: ('with',)\n",
      "Candidate scores:\n",
      "  ever         | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  fever        | LM: -12.5153 | Error:  -1.0986 | Combined: -11.9445\n",
      "  severe       | LM: -13.5153 | Error:  -0.6931 | Combined: -12.8742\n",
      "  seven        | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  several      | LM: -11.1934 | Error:  -0.6931 | Combined: -10.6684\n",
      "  level        | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  every        | LM: -10.5153 | Error:  -1.0986 | Combined: -10.0445\n",
      "  never        | LM: -12.5153 | Error:  -1.0986 | Combined: -11.9445\n",
      "  severely     | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  reveal       | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "Token: 'severl' | Context: ('with',)\n",
      "Candidate scores:\n",
      "  ever         | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  fever        | LM: -12.5153 | Error:  -1.0986 | Combined: -11.9445\n",
      "  severe       | LM: -13.5153 | Error:  -0.6931 | Combined: -12.8742\n",
      "  seven        | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  several      | LM: -11.1934 | Error:  -0.6931 | Combined: -10.6684\n",
      "  level        | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  every        | LM: -10.5153 | Error:  -1.0986 | Combined: -10.0445\n",
      "  never        | LM: -12.5153 | Error:  -1.0986 | Combined: -11.9445\n",
      "  severely     | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  reveal       | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "Token: 'severl' | Context: ('with',)\n",
      "Candidate scores:\n",
      "  ever         | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  fever        | LM: -12.5153 | Error:  -1.0986 | Combined: -11.9445\n",
      "  severe       | LM: -13.5153 | Error:  -0.6931 | Combined: -12.8742\n",
      "  seven        | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  several      | LM: -11.1934 | Error:  -0.6931 | Combined: -10.6684\n",
      "  level        | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  every        | LM: -10.5153 | Error:  -1.0986 | Combined: -10.0445\n",
      "  never        | LM: -12.5153 | Error:  -1.0986 | Combined: -11.9445\n",
      "  severely     | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  reveal       | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "Token: 'severl' | Context: ('with',)\n",
      "Candidate scores:\n",
      "  ever         | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  fever        | LM: -12.5153 | Error:  -1.0986 | Combined: -11.9445\n",
      "  severe       | LM: -13.5153 | Error:  -0.6931 | Combined: -12.8742\n",
      "  seven        | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  several      | LM: -11.1934 | Error:  -0.6931 | Combined: -10.6684\n",
      "  level        | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  every        | LM: -10.5153 | Error:  -1.0986 | Combined: -10.0445\n",
      "  never        | LM: -12.5153 | Error:  -1.0986 | Combined: -11.9445\n",
      "  severely     | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "  reveal       | LM: -13.5153 | Error:  -1.0986 | Combined: -12.8945\n",
      "Top selected tokens: ['every', 'every', 'several', 'several', 'fever']\n",
      "\n",
      "Token: 'erors' | Context: ('every',)\n",
      "Candidate scores:\n",
      "  rows         | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "  grows        | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "  cross        | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "  error        | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "  errors       | LM: -12.7690 | Error:  -0.6931 | Combined: -12.1652\n",
      "  doors        | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "  gross        | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "  ears         | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "  crops        | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "  heroes       | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "Token: 'erors' | Context: ('every',)\n",
      "Candidate scores:\n",
      "  rows         | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "  grows        | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "  cross        | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "  error        | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "  errors       | LM: -12.7690 | Error:  -0.6931 | Combined: -12.1652\n",
      "  doors        | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "  gross        | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "  ears         | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "  crops        | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "  heroes       | LM: -12.7690 | Error:  -1.0986 | Combined: -12.1855\n",
      "Token: 'erors' | Context: ('several',)\n",
      "Candidate scores:\n",
      "  rows         | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "  grows        | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "  cross        | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "  error        | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "  errors       | LM: -11.7507 | Error:  -0.6931 | Combined: -11.1978\n",
      "  doors        | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "  gross        | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "  ears         | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "  crops        | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "  heroes       | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "Token: 'erors' | Context: ('several',)\n",
      "Candidate scores:\n",
      "  rows         | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "  grows        | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "  cross        | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "  error        | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "  errors       | LM: -11.7507 | Error:  -0.6931 | Combined: -11.1978\n",
      "  doors        | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "  gross        | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "  ears         | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "  crops        | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "  heroes       | LM: -12.7507 | Error:  -1.0986 | Combined: -12.1681\n",
      "Token: 'erors' | Context: ('fever',)\n",
      "Candidate scores:\n",
      "  rows         | LM: -12.6998 | Error:  -1.0986 | Combined: -12.1197\n",
      "  grows        | LM: -12.6998 | Error:  -1.0986 | Combined: -12.1197\n",
      "  cross        | LM: -12.6998 | Error:  -1.0986 | Combined: -12.1197\n",
      "  error        | LM: -12.6998 | Error:  -1.0986 | Combined: -12.1197\n",
      "  errors       | LM: -12.6998 | Error:  -0.6931 | Combined: -12.0995\n",
      "  doors        | LM: -12.6998 | Error:  -1.0986 | Combined: -12.1197\n",
      "  gross        | LM: -12.6998 | Error:  -1.0986 | Combined: -12.1197\n",
      "  ears         | LM: -12.6998 | Error:  -1.0986 | Combined: -12.1197\n",
      "  crops        | LM: -12.6998 | Error:  -1.0986 | Combined: -12.1197\n",
      "  heroes       | LM: -12.6998 | Error:  -1.0986 | Combined: -12.1197\n",
      "Top selected tokens: ['errors', 'errors', 'rows', 'grows', 'cross']\n",
      "\n",
      "Token: '.' | Context: ('errors',)\n",
      "Candidate scores:\n",
      "  .            | LM: -10.7037 | Error:  +0.0000 | Combined: -10.1685\n",
      "Token: '.' | Context: ('errors',)\n",
      "Candidate scores:\n",
      "  .            | LM: -10.7037 | Error:  +0.0000 | Combined: -10.1685\n",
      "Token: '.' | Context: ('rows',)\n",
      "Candidate scores:\n",
      "  .            | LM: -12.6991 | Error:  +0.0000 | Combined: -12.0642\n",
      "Token: '.' | Context: ('grows',)\n",
      "Candidate scores:\n",
      "  .            | LM: -12.6987 | Error:  +0.0000 | Combined: -12.0638\n",
      "Token: '.' | Context: ('cross',)\n",
      "Candidate scores:\n",
      "  .            | LM: -10.3833 | Error:  +0.0000 | Combined:  -9.8641\n",
      "Top selected tokens: ['.', '.', '.', '.', '.']\n",
      "\n",
      "Final corrected sentence: he is an example of a sentence with several errors .\n",
      "Bigram model produced:\n",
      "  he is an example of a sentence with several errors .\n",
      "\n",
      "Testing with sentence: \"Wee shuld definately do ths agan some day.\"\n",
      "Starting correction for sentence: Wee shuld definately do ths agan some day .\n",
      "Token: 'Wee' | Context: ('<start>',)\n",
      "Candidate scores:\n",
      "  fee          | LM: -15.4974 | Error:  -0.6931 | Combined: -14.7572\n",
      "  ed           | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  led          | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  e.           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  lee          | LM: -13.4974 | Error:  -0.6931 | Combined: -12.8572\n",
      "  le           | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  fed          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  week         | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  weep         | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  were         | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  seed         | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  jet          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  meet         | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  tie          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  feet         | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  one          | LM:  -7.4476 | Error:  -1.0986 | Combined:  -7.1301\n",
      "  ace          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  seek         | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  set          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  mae          | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  jeep         | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  sex          | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  seem         | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  see          | LM: -12.0380 | Error:  -0.6931 | Combined: -11.4707\n",
      "  due          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  feel         | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  lie          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  leg          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  el           | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  deep         | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  joe          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  pete         | LM: -12.0380 | Error:  -1.0986 | Combined: -11.4910\n",
      "  we           | LM:  -6.8321 | Error:  -1.0986 | Combined:  -6.5454\n",
      "  keep         | LM: -12.1755 | Error:  -1.0986 | Combined: -11.6216\n",
      "  pie          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  et           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  the          | LM:  -3.3882 | Error:  -1.0986 | Combined:  -3.2738\n",
      "  ice          | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  few          | LM: -11.6901 | Error:  -1.0986 | Combined: -11.1605\n",
      "  let          | LM:  -9.6148 | Error:  -1.0986 | Combined:  -9.1890\n",
      "  new          | LM: -10.3681 | Error:  -1.0986 | Combined:  -9.9047\n",
      "  die          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  beef         | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  rev          | LM: -12.6901 | Error:  -1.0986 | Combined: -12.1105\n",
      "  hen          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  yet          | LM:  -9.1576 | Error:  -1.0986 | Combined:  -8.7546\n",
      "  mere         | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  seen         | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  need         | LM: -13.4974 | Error:  -1.0986 | Combined: -12.8775\n",
      "  wet          | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  hey          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  she          | LM:  -6.1710 | Error:  -1.0986 | Combined:  -5.9174\n",
      "  sees         | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  free         | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  ate          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  bed          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  her          | LM:  -8.8250 | Error:  -1.0986 | Combined:  -8.4387\n",
      "  pen          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  met          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  knee         | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  ben          | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  be           | LM: -11.4974 | Error:  -1.0986 | Combined: -10.9775\n",
      "  ten          | LM: -12.0380 | Error:  -1.0986 | Combined: -11.4910\n",
      "  thee         | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  're          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  tea          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  bet          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  get          | LM: -12.6901 | Error:  -1.0986 | Combined: -12.1105\n",
      "  eve          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  've          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  yes          | LM: -10.6901 | Error:  -1.0986 | Combined: -10.2105\n",
      "  men          | LM: -11.6901 | Error:  -1.0986 | Combined: -11.1605\n",
      "  here         | LM:  -8.8681 | Error:  -1.0986 | Combined:  -8.4796\n",
      "  are          | LM: -10.5432 | Error:  -1.0986 | Combined: -10.0710\n",
      "  per          | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  eye          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  key          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  feed         | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  net          | LM: -13.4974 | Error:  -1.0986 | Combined: -12.8775\n",
      "  ken          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  tree         | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  'em          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  sec          | LM: -12.1755 | Error:  -1.0986 | Combined: -11.6216\n",
      "  e            | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  sea          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  fees         | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  me           | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  red          | LM: -12.9125 | Error:  -1.0986 | Combined: -12.3218\n",
      "  ye           | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  jew          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  he           | LM:  -4.5137 | Error:  -1.0986 | Combined:  -4.3430\n",
      "  use          | LM: -11.7970 | Error:  -1.0986 | Combined: -11.2621\n",
      "  age          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  i.e          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  beer         | LM: -13.9125 | Error:  -1.0986 | Combined: -13.2718\n",
      "  de           | LM: -13.4974 | Error:  -1.0986 | Combined: -12.8775\n",
      "  zen          | LM: -14.4974 | Error:  -1.0986 | Combined: -13.8275\n",
      "  been         | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "  sue          | LM: -15.4974 | Error:  -1.0986 | Combined: -14.7775\n",
      "Top selected tokens: ['the', 'he', 'she', 'we', 'one']\n",
      "\n",
      "Token: 'shuld' | Context: ('the',)\n",
      "Candidate scores:\n",
      "  shut         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  sound        | LM: -10.8476 | Error:  -1.0986 | Combined: -10.3601\n",
      "  squad        | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  could        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  shu          | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  held         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  should       | LM: -15.7545 | Error:  -0.6931 | Combined: -15.0014\n",
      "  souls        | LM: -14.1695 | Error:  -1.0986 | Combined: -13.5160\n",
      "  would        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  hold         | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  soul         | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  sold         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  shall        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  child        | LM: -10.6670 | Error:  -1.0986 | Combined: -10.1886\n",
      "  shell        | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "Token: 'shuld' | Context: ('he',)\n",
      "Candidate scores:\n",
      "  shut         | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "  sound        | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "  squad        | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "  could        | LM:  -5.9354 | Error:  -1.0986 | Combined:  -5.6936\n",
      "  shu          | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "  held         | LM:  -9.9160 | Error:  -1.0986 | Combined:  -9.4751\n",
      "  should       | LM:  -9.0229 | Error:  -0.6931 | Combined:  -8.6064\n",
      "  souls        | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "  would        | LM:  -6.0580 | Error:  -1.0986 | Combined:  -5.8100\n",
      "  hold         | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "  soul         | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "  sold         | LM: -11.7233 | Error:  -1.0986 | Combined: -11.1921\n",
      "  shall        | LM: -12.1384 | Error:  -1.0986 | Combined: -11.5864\n",
      "  child        | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "  shell        | LM: -13.7233 | Error:  -1.0986 | Combined: -13.0921\n",
      "Token: 'shuld' | Context: ('she',)\n",
      "Candidate scores:\n",
      "  shut         | LM: -13.0911 | Error:  -1.0986 | Combined: -12.4915\n",
      "  sound        | LM: -13.0911 | Error:  -1.0986 | Combined: -12.4915\n",
      "  squad        | LM: -13.0911 | Error:  -1.0986 | Combined: -12.4915\n",
      "  could        | LM:  -6.9826 | Error:  -1.0986 | Combined:  -6.6884\n",
      "  shu          | LM: -13.0911 | Error:  -1.0986 | Combined: -12.4915\n",
      "  held         | LM: -10.7692 | Error:  -1.0986 | Combined: -10.2856\n",
      "  should       | LM: -10.7692 | Error:  -0.6931 | Combined: -10.2654\n",
      "  souls        | LM: -13.0911 | Error:  -1.0986 | Combined: -12.4915\n",
      "  would        | LM:  -6.7513 | Error:  -1.0986 | Combined:  -6.4686\n",
      "  hold         | LM: -13.0911 | Error:  -1.0986 | Combined: -12.4915\n",
      "  soul         | LM: -13.0911 | Error:  -1.0986 | Combined: -12.4915\n",
      "  sold         | LM: -13.0911 | Error:  -1.0986 | Combined: -12.4915\n",
      "  shall        | LM: -13.0911 | Error:  -1.0986 | Combined: -12.4915\n",
      "  child        | LM: -13.0911 | Error:  -1.0986 | Combined: -12.4915\n",
      "  shell        | LM: -13.0911 | Error:  -1.0986 | Combined: -12.4915\n",
      "Token: 'shuld' | Context: ('we',)\n",
      "Candidate scores:\n",
      "  shut         | LM: -13.0740 | Error:  -1.0986 | Combined: -12.4752\n",
      "  sound        | LM: -13.0740 | Error:  -1.0986 | Combined: -12.4752\n",
      "  squad        | LM: -13.0740 | Error:  -1.0986 | Combined: -12.4752\n",
      "  could        | LM:  -7.8645 | Error:  -1.0986 | Combined:  -7.5262\n",
      "  shu          | LM: -13.0740 | Error:  -1.0986 | Combined: -12.4752\n",
      "  held         | LM: -13.0740 | Error:  -1.0986 | Combined: -12.4752\n",
      "  should       | LM:  -7.5194 | Error:  -0.6931 | Combined:  -7.1781\n",
      "  souls        | LM: -13.0740 | Error:  -1.0986 | Combined: -12.4752\n",
      "  would        | LM:  -8.1671 | Error:  -1.0986 | Combined:  -7.8137\n",
      "  hold         | LM: -11.0740 | Error:  -1.0986 | Combined: -10.5752\n",
      "  soul         | LM: -13.0740 | Error:  -1.0986 | Combined: -12.4752\n",
      "  sold         | LM: -13.0740 | Error:  -1.0986 | Combined: -12.4752\n",
      "  shall        | LM:  -8.2160 | Error:  -1.0986 | Combined:  -7.8601\n",
      "  child        | LM: -13.0740 | Error:  -1.0986 | Combined: -12.4752\n",
      "  shell        | LM: -13.0740 | Error:  -1.0986 | Combined: -12.4752\n",
      "Token: 'shuld' | Context: ('one',)\n",
      "Candidate scores:\n",
      "  shut         | LM: -13.1380 | Error:  -1.0986 | Combined: -12.5360\n",
      "  sound        | LM: -12.1380 | Error:  -1.0986 | Combined: -11.5860\n",
      "  squad        | LM: -12.1380 | Error:  -1.0986 | Combined: -11.5860\n",
      "  could        | LM:  -9.1380 | Error:  -1.0986 | Combined:  -8.7360\n",
      "  shu          | LM: -13.1380 | Error:  -1.0986 | Combined: -12.5360\n",
      "  held         | LM: -13.1380 | Error:  -1.0986 | Combined: -12.5360\n",
      "  should       | LM: -10.1380 | Error:  -0.6931 | Combined:  -9.6657\n",
      "  souls        | LM: -13.1380 | Error:  -1.0986 | Combined: -12.5360\n",
      "  would        | LM:  -9.0505 | Error:  -1.0986 | Combined:  -8.6529\n",
      "  hold         | LM: -13.1380 | Error:  -1.0986 | Combined: -12.5360\n",
      "  soul         | LM: -13.1380 | Error:  -1.0986 | Combined: -12.5360\n",
      "  sold         | LM: -13.1380 | Error:  -1.0986 | Combined: -12.5360\n",
      "  shall        | LM: -13.1380 | Error:  -1.0986 | Combined: -12.5360\n",
      "  child        | LM: -11.5530 | Error:  -1.0986 | Combined: -11.0303\n",
      "  shell        | LM: -13.1380 | Error:  -1.0986 | Combined: -12.5360\n",
      "Top selected tokens: ['could', 'would', 'would', 'could', 'should']\n",
      "\n",
      "Token: 'definately' | Context: ('could',)\n",
      "Candidate scores:\n",
      "  definitely   | LM: -12.9403 | Error:  -0.6931 | Combined: -12.3280\n",
      "Token: 'definately' | Context: ('would',)\n",
      "Candidate scores:\n",
      "  definitely   | LM: -13.0689 | Error:  -0.6931 | Combined: -12.4502\n",
      "Token: 'definately' | Context: ('would',)\n",
      "Candidate scores:\n",
      "  definitely   | LM: -13.0689 | Error:  -0.6931 | Combined: -12.4502\n",
      "Token: 'definately' | Context: ('could',)\n",
      "Candidate scores:\n",
      "  definitely   | LM: -12.9403 | Error:  -0.6931 | Combined: -12.3280\n",
      "Token: 'definately' | Context: ('should',)\n",
      "Candidate scores:\n",
      "  definitely   | LM: -12.8260 | Error:  -0.6931 | Combined: -12.2193\n",
      "Top selected tokens: ['definitely', 'definitely', 'definitely', 'definitely', 'definitely']\n",
      "\n",
      "Token: 'do' | Context: ('definitely',)\n",
      "Candidate scores:\n",
      "  do           | LM: -11.6996 | Error:  +0.0000 | Combined: -11.1146\n",
      "Token: 'do' | Context: ('definitely',)\n",
      "Candidate scores:\n",
      "  do           | LM: -11.6996 | Error:  +0.0000 | Combined: -11.1146\n",
      "Token: 'do' | Context: ('definitely',)\n",
      "Candidate scores:\n",
      "  do           | LM: -11.6996 | Error:  +0.0000 | Combined: -11.1146\n",
      "Token: 'do' | Context: ('definitely',)\n",
      "Candidate scores:\n",
      "  do           | LM: -11.6996 | Error:  +0.0000 | Combined: -11.1146\n",
      "Token: 'do' | Context: ('definitely',)\n",
      "Candidate scores:\n",
      "  do           | LM: -11.6996 | Error:  +0.0000 | Combined: -11.1146\n",
      "Top selected tokens: ['do', 'do', 'do', 'do', 'do']\n",
      "\n",
      "Token: 'ths' | Context: ('do',)\n",
      "Candidate scores:\n",
      "  why          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  s            | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  his          | LM: -10.3618 | Error:  -1.0986 | Combined:  -9.8986\n",
      "  then         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  that         | LM:  -8.4232 | Error:  -1.0986 | Combined:  -8.0569\n",
      "  this         | LM:  -8.5544 | Error:  -0.6931 | Combined:  -8.1613\n",
      "  us           | LM: -11.9467 | Error:  -1.0986 | Combined: -11.4043\n",
      "  tie          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  ah           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  than         | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  tons         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  gas          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  its          | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  tip          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  they         | LM:  -9.9467 | Error:  -1.0986 | Combined:  -9.5043\n",
      "  who          | LM: -11.9467 | Error:  -1.0986 | Combined: -11.4043\n",
      "  shu          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tops         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thus         | LM: -12.9467 | Error:  -0.6931 | Combined: -12.3340\n",
      "  these        | LM: -10.3618 | Error:  -1.0986 | Combined:  -9.8986\n",
      "  those        | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  too          | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  t.           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  to           | LM:  -9.0398 | Error:  -1.0986 | Combined:  -8.6428\n",
      "  test         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  the          | LM:  -7.6988 | Error:  -0.6931 | Combined:  -7.3485\n",
      "  's           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  try          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  paths        | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  toes         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tax          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thin         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  she          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tv           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  ten          | LM: -11.9467 | Error:  -1.0986 | Combined: -11.4043\n",
      "  thee         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  oh           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tea          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tap          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  ties         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  task         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  top          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thor         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  yes          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tom          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  as           | LM:  -9.7768 | Error:  -1.0986 | Combined:  -9.3429\n",
      "  tim          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thy          | LM: -12.9467 | Error:  -0.6931 | Combined: -12.3340\n",
      "  h.           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  them         | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  was          | LM:  -9.6248 | Error:  -1.0986 | Combined:  -9.1985\n",
      "  los          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  two          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  he           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  has          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  h            | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  toys         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  is           | LM:  -9.2463 | Error:  -1.0986 | Combined:  -8.8389\n",
      "  tar          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  bus          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  t            | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  shy          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "Token: 'ths' | Context: ('do',)\n",
      "Candidate scores:\n",
      "  why          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  s            | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  his          | LM: -10.3618 | Error:  -1.0986 | Combined:  -9.8986\n",
      "  then         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  that         | LM:  -8.4232 | Error:  -1.0986 | Combined:  -8.0569\n",
      "  this         | LM:  -8.5544 | Error:  -0.6931 | Combined:  -8.1613\n",
      "  us           | LM: -11.9467 | Error:  -1.0986 | Combined: -11.4043\n",
      "  tie          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  ah           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  than         | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  tons         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  gas          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  its          | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  tip          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  they         | LM:  -9.9467 | Error:  -1.0986 | Combined:  -9.5043\n",
      "  who          | LM: -11.9467 | Error:  -1.0986 | Combined: -11.4043\n",
      "  shu          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tops         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thus         | LM: -12.9467 | Error:  -0.6931 | Combined: -12.3340\n",
      "  these        | LM: -10.3618 | Error:  -1.0986 | Combined:  -9.8986\n",
      "  those        | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  too          | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  t.           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  to           | LM:  -9.0398 | Error:  -1.0986 | Combined:  -8.6428\n",
      "  test         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  the          | LM:  -7.6988 | Error:  -0.6931 | Combined:  -7.3485\n",
      "  's           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  try          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  paths        | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  toes         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tax          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thin         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  she          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tv           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  ten          | LM: -11.9467 | Error:  -1.0986 | Combined: -11.4043\n",
      "  thee         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  oh           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tea          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tap          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  ties         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  task         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  top          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thor         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  yes          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tom          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  as           | LM:  -9.7768 | Error:  -1.0986 | Combined:  -9.3429\n",
      "  tim          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thy          | LM: -12.9467 | Error:  -0.6931 | Combined: -12.3340\n",
      "  h.           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  them         | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  was          | LM:  -9.6248 | Error:  -1.0986 | Combined:  -9.1985\n",
      "  los          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  two          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  he           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  has          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  h            | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  toys         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  is           | LM:  -9.2463 | Error:  -1.0986 | Combined:  -8.8389\n",
      "  tar          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  bus          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  t            | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  shy          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "Token: 'ths' | Context: ('do',)\n",
      "Candidate scores:\n",
      "  why          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  s            | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  his          | LM: -10.3618 | Error:  -1.0986 | Combined:  -9.8986\n",
      "  then         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  that         | LM:  -8.4232 | Error:  -1.0986 | Combined:  -8.0569\n",
      "  this         | LM:  -8.5544 | Error:  -0.6931 | Combined:  -8.1613\n",
      "  us           | LM: -11.9467 | Error:  -1.0986 | Combined: -11.4043\n",
      "  tie          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  ah           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  than         | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  tons         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  gas          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  its          | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  tip          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  they         | LM:  -9.9467 | Error:  -1.0986 | Combined:  -9.5043\n",
      "  who          | LM: -11.9467 | Error:  -1.0986 | Combined: -11.4043\n",
      "  shu          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tops         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thus         | LM: -12.9467 | Error:  -0.6931 | Combined: -12.3340\n",
      "  these        | LM: -10.3618 | Error:  -1.0986 | Combined:  -9.8986\n",
      "  those        | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  too          | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  t.           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  to           | LM:  -9.0398 | Error:  -1.0986 | Combined:  -8.6428\n",
      "  test         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  the          | LM:  -7.6988 | Error:  -0.6931 | Combined:  -7.3485\n",
      "  's           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  try          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  paths        | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  toes         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tax          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thin         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  she          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tv           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  ten          | LM: -11.9467 | Error:  -1.0986 | Combined: -11.4043\n",
      "  thee         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  oh           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tea          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tap          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  ties         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  task         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  top          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thor         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  yes          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tom          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  as           | LM:  -9.7768 | Error:  -1.0986 | Combined:  -9.3429\n",
      "  tim          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thy          | LM: -12.9467 | Error:  -0.6931 | Combined: -12.3340\n",
      "  h.           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  them         | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  was          | LM:  -9.6248 | Error:  -1.0986 | Combined:  -9.1985\n",
      "  los          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  two          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  he           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  has          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  h            | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  toys         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  is           | LM:  -9.2463 | Error:  -1.0986 | Combined:  -8.8389\n",
      "  tar          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  bus          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  t            | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  shy          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "Token: 'ths' | Context: ('do',)\n",
      "Candidate scores:\n",
      "  why          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  s            | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  his          | LM: -10.3618 | Error:  -1.0986 | Combined:  -9.8986\n",
      "  then         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  that         | LM:  -8.4232 | Error:  -1.0986 | Combined:  -8.0569\n",
      "  this         | LM:  -8.5544 | Error:  -0.6931 | Combined:  -8.1613\n",
      "  us           | LM: -11.9467 | Error:  -1.0986 | Combined: -11.4043\n",
      "  tie          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  ah           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  than         | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  tons         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  gas          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  its          | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  tip          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  they         | LM:  -9.9467 | Error:  -1.0986 | Combined:  -9.5043\n",
      "  who          | LM: -11.9467 | Error:  -1.0986 | Combined: -11.4043\n",
      "  shu          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tops         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thus         | LM: -12.9467 | Error:  -0.6931 | Combined: -12.3340\n",
      "  these        | LM: -10.3618 | Error:  -1.0986 | Combined:  -9.8986\n",
      "  those        | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  too          | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  t.           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  to           | LM:  -9.0398 | Error:  -1.0986 | Combined:  -8.6428\n",
      "  test         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  the          | LM:  -7.6988 | Error:  -0.6931 | Combined:  -7.3485\n",
      "  's           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  try          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  paths        | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  toes         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tax          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thin         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  she          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tv           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  ten          | LM: -11.9467 | Error:  -1.0986 | Combined: -11.4043\n",
      "  thee         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  oh           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tea          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tap          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  ties         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  task         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  top          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thor         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  yes          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tom          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  as           | LM:  -9.7768 | Error:  -1.0986 | Combined:  -9.3429\n",
      "  tim          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thy          | LM: -12.9467 | Error:  -0.6931 | Combined: -12.3340\n",
      "  h.           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  them         | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  was          | LM:  -9.6248 | Error:  -1.0986 | Combined:  -9.1985\n",
      "  los          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  two          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  he           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  has          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  h            | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  toys         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  is           | LM:  -9.2463 | Error:  -1.0986 | Combined:  -8.8389\n",
      "  tar          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  bus          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  t            | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  shy          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "Token: 'ths' | Context: ('do',)\n",
      "Candidate scores:\n",
      "  why          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  s            | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  his          | LM: -10.3618 | Error:  -1.0986 | Combined:  -9.8986\n",
      "  then         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  that         | LM:  -8.4232 | Error:  -1.0986 | Combined:  -8.0569\n",
      "  this         | LM:  -8.5544 | Error:  -0.6931 | Combined:  -8.1613\n",
      "  us           | LM: -11.9467 | Error:  -1.0986 | Combined: -11.4043\n",
      "  tie          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  ah           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  than         | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  tons         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  gas          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  its          | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  tip          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  they         | LM:  -9.9467 | Error:  -1.0986 | Combined:  -9.5043\n",
      "  who          | LM: -11.9467 | Error:  -1.0986 | Combined: -11.4043\n",
      "  shu          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tops         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thus         | LM: -12.9467 | Error:  -0.6931 | Combined: -12.3340\n",
      "  these        | LM: -10.3618 | Error:  -1.0986 | Combined:  -9.8986\n",
      "  those        | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  too          | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  t.           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  to           | LM:  -9.0398 | Error:  -1.0986 | Combined:  -8.6428\n",
      "  test         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  the          | LM:  -7.6988 | Error:  -0.6931 | Combined:  -7.3485\n",
      "  's           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  try          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  paths        | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  toes         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tax          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thin         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  she          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tv           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  ten          | LM: -11.9467 | Error:  -1.0986 | Combined: -11.4043\n",
      "  thee         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  oh           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tea          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tap          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  ties         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  task         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  top          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thor         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  yes          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  tom          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  as           | LM:  -9.7768 | Error:  -1.0986 | Combined:  -9.3429\n",
      "  tim          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  thy          | LM: -12.9467 | Error:  -0.6931 | Combined: -12.3340\n",
      "  h.           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  them         | LM: -11.3618 | Error:  -1.0986 | Combined: -10.8486\n",
      "  was          | LM:  -9.6248 | Error:  -1.0986 | Combined:  -9.1985\n",
      "  los          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  two          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  he           | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  has          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  h            | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  toys         | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  is           | LM:  -9.2463 | Error:  -1.0986 | Combined:  -8.8389\n",
      "  tar          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  bus          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  t            | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "  shy          | LM: -12.9467 | Error:  -1.0986 | Combined: -12.3543\n",
      "Top selected tokens: ['the', 'the', 'that', 'this', 'that']\n",
      "\n",
      "Token: 'agan' | Context: ('the',)\n",
      "Candidate scores:\n",
      "  ann          | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  dan          | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  japan        | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  gon          | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  agent        | LM: -14.1695 | Error:  -1.0986 | Combined: -13.5160\n",
      "  dean         | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  than         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  wagon        | LM: -11.9471 | Error:  -1.0986 | Combined: -11.4047\n",
      "  loan         | LM: -12.7545 | Error:  -1.0986 | Combined: -12.1717\n",
      "  mean         | LM: -12.0540 | Error:  -1.0986 | Combined: -11.5063\n",
      "  ran          | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  span         | LM: -14.1695 | Error:  -1.0986 | Combined: -13.5160\n",
      "  gun          | LM: -11.4325 | Error:  -1.0986 | Combined: -10.9158\n",
      "  gas          | LM: -12.0540 | Error:  -1.0986 | Combined: -11.5063\n",
      "  gang         | LM: -13.7545 | Error:  -1.0986 | Combined: -13.1217\n",
      "  aegean       | LM: -12.1695 | Error:  -1.0986 | Combined: -11.6160\n",
      "  jean         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  van          | LM: -14.1695 | Error:  -1.0986 | Combined: -13.5160\n",
      "  an           | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  san          | LM: -12.5845 | Error:  -1.0986 | Combined: -12.0102\n",
      "  gain         | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  hogan        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  adam         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  fan          | LM: -13.7545 | Error:  -1.0986 | Combined: -13.1217\n",
      "  ada          | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  joan         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  again        | LM: -15.7545 | Error:  -0.6931 | Combined: -15.0014\n",
      "  began        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  man          | LM:  -8.4416 | Error:  -1.0986 | Combined:  -8.0744\n",
      "  aged         | LM: -12.9471 | Error:  -1.0986 | Combined: -12.3547\n",
      "  lean         | LM: -14.1695 | Error:  -1.0986 | Combined: -13.5160\n",
      "  can          | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  ages         | LM: -12.5845 | Error:  -1.0986 | Combined: -12.0102\n",
      "  amen         | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  gay          | LM: -14.1695 | Error:  -1.0986 | Combined: -13.5160\n",
      "  plan         | LM: -10.8003 | Error:  -1.0986 | Combined: -10.3152\n",
      "  ago          | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  gap          | LM: -12.5845 | Error:  -1.0986 | Combined: -12.0102\n",
      "  gin          | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  age          | LM: -11.2309 | Error:  -1.0986 | Combined: -10.7243\n",
      "  away         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "Token: 'agan' | Context: ('the',)\n",
      "Candidate scores:\n",
      "  ann          | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  dan          | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  japan        | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  gon          | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  agent        | LM: -14.1695 | Error:  -1.0986 | Combined: -13.5160\n",
      "  dean         | LM: -14.7545 | Error:  -1.0986 | Combined: -14.0717\n",
      "  than         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  wagon        | LM: -11.9471 | Error:  -1.0986 | Combined: -11.4047\n",
      "  loan         | LM: -12.7545 | Error:  -1.0986 | Combined: -12.1717\n",
      "  mean         | LM: -12.0540 | Error:  -1.0986 | Combined: -11.5063\n",
      "  ran          | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  span         | LM: -14.1695 | Error:  -1.0986 | Combined: -13.5160\n",
      "  gun          | LM: -11.4325 | Error:  -1.0986 | Combined: -10.9158\n",
      "  gas          | LM: -12.0540 | Error:  -1.0986 | Combined: -11.5063\n",
      "  gang         | LM: -13.7545 | Error:  -1.0986 | Combined: -13.1217\n",
      "  aegean       | LM: -12.1695 | Error:  -1.0986 | Combined: -11.6160\n",
      "  jean         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  van          | LM: -14.1695 | Error:  -1.0986 | Combined: -13.5160\n",
      "  an           | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  san          | LM: -12.5845 | Error:  -1.0986 | Combined: -12.0102\n",
      "  gain         | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  hogan        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  adam         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  fan          | LM: -13.7545 | Error:  -1.0986 | Combined: -13.1217\n",
      "  ada          | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  joan         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  again        | LM: -15.7545 | Error:  -0.6931 | Combined: -15.0014\n",
      "  began        | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  man          | LM:  -8.4416 | Error:  -1.0986 | Combined:  -8.0744\n",
      "  aged         | LM: -12.9471 | Error:  -1.0986 | Combined: -12.3547\n",
      "  lean         | LM: -14.1695 | Error:  -1.0986 | Combined: -13.5160\n",
      "  can          | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  ages         | LM: -12.5845 | Error:  -1.0986 | Combined: -12.0102\n",
      "  amen         | LM: -13.4325 | Error:  -1.0986 | Combined: -12.8158\n",
      "  gay          | LM: -14.1695 | Error:  -1.0986 | Combined: -13.5160\n",
      "  plan         | LM: -10.8003 | Error:  -1.0986 | Combined: -10.3152\n",
      "  ago          | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  gap          | LM: -12.5845 | Error:  -1.0986 | Combined: -12.0102\n",
      "  gin          | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "  age          | LM: -11.2309 | Error:  -1.0986 | Combined: -10.7243\n",
      "  away         | LM: -15.7545 | Error:  -1.0986 | Combined: -15.0217\n",
      "Token: 'agan' | Context: ('that',)\n",
      "Candidate scores:\n",
      "  ann          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  dan          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  japan        | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  gon          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  agent        | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  dean         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  than         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  wagon        | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  loan         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  mean         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  ran          | LM: -12.2054 | Error:  -1.0986 | Combined: -11.6500\n",
      "  span         | LM: -12.7903 | Error:  -1.0986 | Combined: -12.2058\n",
      "  gun          | LM: -11.7903 | Error:  -1.0986 | Combined: -11.2558\n",
      "  gas          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  gang         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  aegean       | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  jean         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  van          | LM: -12.7903 | Error:  -1.0986 | Combined: -12.2058\n",
      "  an           | LM:  -8.9830 | Error:  -1.0986 | Combined:  -8.5888\n",
      "  san          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  gain         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  hogan        | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  adam         | LM: -11.7903 | Error:  -1.0986 | Combined: -11.2558\n",
      "  fan          | LM: -12.7903 | Error:  -1.0986 | Combined: -12.2058\n",
      "  ada          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  joan         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  again        | LM: -12.7903 | Error:  -0.6931 | Combined: -12.1855\n",
      "  began        | LM: -11.4684 | Error:  -1.0986 | Combined: -10.9499\n",
      "  man          | LM: -10.9830 | Error:  -1.0986 | Combined: -10.4888\n",
      "  aged         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  lean         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  can          | LM:  -8.7029 | Error:  -1.0986 | Combined:  -8.3227\n",
      "  ages         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  amen         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  gay          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  plan         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  ago          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  gap          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  gin          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  age          | LM: -11.7903 | Error:  -1.0986 | Combined: -11.2558\n",
      "  away         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "Token: 'agan' | Context: ('this',)\n",
      "Candidate scores:\n",
      "  ann          | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  dan          | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  japan        | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  gon          | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  agent        | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  dean         | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  than         | LM: -11.7432 | Error:  -1.0986 | Combined: -11.2109\n",
      "  wagon        | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  loan         | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  mean         | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  ran          | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  span         | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  gun          | LM: -12.3281 | Error:  -1.0986 | Combined: -11.7666\n",
      "  gas          | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  gang         | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  aegean       | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  jean         | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  van          | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  an           | LM: -12.3281 | Error:  -1.0986 | Combined: -11.7666\n",
      "  san          | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  gain         | LM: -12.3281 | Error:  -1.0986 | Combined: -11.7666\n",
      "  hogan        | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  adam         | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  fan          | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  ada          | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  joan         | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  again        | LM: -13.3281 | Error:  -0.6931 | Combined: -12.6964\n",
      "  began        | LM: -12.3281 | Error:  -1.0986 | Combined: -11.7666\n",
      "  man          | LM:  -9.6277 | Error:  -1.0986 | Combined:  -9.2012\n",
      "  aged         | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  lean         | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  can          | LM:  -9.4212 | Error:  -1.0986 | Combined:  -9.0051\n",
      "  ages         | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  amen         | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  gay          | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  plan         | LM: -10.7432 | Error:  -1.0986 | Combined: -10.2609\n",
      "  ago          | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  gap          | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  gin          | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "  age          | LM: -11.3281 | Error:  -1.0986 | Combined: -10.8166\n",
      "  away         | LM: -13.3281 | Error:  -1.0986 | Combined: -12.7166\n",
      "Token: 'agan' | Context: ('that',)\n",
      "Candidate scores:\n",
      "  ann          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  dan          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  japan        | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  gon          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  agent        | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  dean         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  than         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  wagon        | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  loan         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  mean         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  ran          | LM: -12.2054 | Error:  -1.0986 | Combined: -11.6500\n",
      "  span         | LM: -12.7903 | Error:  -1.0986 | Combined: -12.2058\n",
      "  gun          | LM: -11.7903 | Error:  -1.0986 | Combined: -11.2558\n",
      "  gas          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  gang         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  aegean       | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  jean         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  van          | LM: -12.7903 | Error:  -1.0986 | Combined: -12.2058\n",
      "  an           | LM:  -8.9830 | Error:  -1.0986 | Combined:  -8.5888\n",
      "  san          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  gain         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  hogan        | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  adam         | LM: -11.7903 | Error:  -1.0986 | Combined: -11.2558\n",
      "  fan          | LM: -12.7903 | Error:  -1.0986 | Combined: -12.2058\n",
      "  ada          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  joan         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  again        | LM: -12.7903 | Error:  -0.6931 | Combined: -12.1855\n",
      "  began        | LM: -11.4684 | Error:  -1.0986 | Combined: -10.9499\n",
      "  man          | LM: -10.9830 | Error:  -1.0986 | Combined: -10.4888\n",
      "  aged         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  lean         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  can          | LM:  -8.7029 | Error:  -1.0986 | Combined:  -8.3227\n",
      "  ages         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  amen         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  gay          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  plan         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  ago          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  gap          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  gin          | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "  age          | LM: -11.7903 | Error:  -1.0986 | Combined: -11.2558\n",
      "  away         | LM: -13.7903 | Error:  -1.0986 | Combined: -13.1558\n",
      "Top selected tokens: ['man', 'man', 'can', 'can', 'an']\n",
      "\n",
      "Token: 'some' | Context: ('man',)\n",
      "Candidate scores:\n",
      "  some         | LM: -12.8853 | Error:  +0.0000 | Combined: -12.2410\n",
      "Token: 'some' | Context: ('man',)\n",
      "Candidate scores:\n",
      "  some         | LM: -12.8853 | Error:  +0.0000 | Combined: -12.2410\n",
      "Token: 'some' | Context: ('can',)\n",
      "Candidate scores:\n",
      "  some         | LM: -12.9753 | Error:  +0.0000 | Combined: -12.3265\n",
      "Token: 'some' | Context: ('can',)\n",
      "Candidate scores:\n",
      "  some         | LM: -12.9753 | Error:  +0.0000 | Combined: -12.3265\n",
      "Token: 'some' | Context: ('an',)\n",
      "Candidate scores:\n",
      "  some         | LM: -13.1749 | Error:  +0.0000 | Combined: -12.5162\n",
      "Top selected tokens: ['some', 'some', 'some', 'some', 'some']\n",
      "\n",
      "Token: 'day' | Context: ('some',)\n",
      "Candidate scores:\n",
      "  day          | LM: -10.1188 | Error:  +0.0000 | Combined:  -9.6128\n",
      "Token: 'day' | Context: ('some',)\n",
      "Candidate scores:\n",
      "  day          | LM: -10.1188 | Error:  +0.0000 | Combined:  -9.6128\n",
      "Token: 'day' | Context: ('some',)\n",
      "Candidate scores:\n",
      "  day          | LM: -10.1188 | Error:  +0.0000 | Combined:  -9.6128\n",
      "Token: 'day' | Context: ('some',)\n",
      "Candidate scores:\n",
      "  day          | LM: -10.1188 | Error:  +0.0000 | Combined:  -9.6128\n",
      "Token: 'day' | Context: ('some',)\n",
      "Candidate scores:\n",
      "  day          | LM: -10.1188 | Error:  +0.0000 | Combined:  -9.6128\n",
      "Top selected tokens: ['day', 'day', 'day', 'day', 'day']\n",
      "\n",
      "Token: '.' | Context: ('day',)\n",
      "Candidate scores:\n",
      "  .            | LM:  -6.5692 | Error:  +0.0000 | Combined:  -6.2408\n",
      "Token: '.' | Context: ('day',)\n",
      "Candidate scores:\n",
      "  .            | LM:  -6.5692 | Error:  +0.0000 | Combined:  -6.2408\n",
      "Token: '.' | Context: ('day',)\n",
      "Candidate scores:\n",
      "  .            | LM:  -6.5692 | Error:  +0.0000 | Combined:  -6.2408\n",
      "Token: '.' | Context: ('day',)\n",
      "Candidate scores:\n",
      "  .            | LM:  -6.5692 | Error:  +0.0000 | Combined:  -6.2408\n",
      "Token: '.' | Context: ('day',)\n",
      "Candidate scores:\n",
      "  .            | LM:  -6.5692 | Error:  +0.0000 | Combined:  -6.2408\n",
      "Top selected tokens: ['.', '.', '.', '.', '.']\n",
      "\n",
      "Final corrected sentence: he could definitely do the man some day .\n",
      "Bigram model produced:\n",
      "  he could definitely do the man some day .\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"let us sey we are friendz\",\n",
    "    \"in consequencaae of her sistero's marriange, been moistress of hois house from a vry early period\",\n",
    "    \"Tomorrrow well bring somethiing new, so leav today as a memoory.\",\n",
    "    \"He wento too the storr to by some bred and mlik.\",\n",
    "    \"Ths is an exampel of a sentense with severl erors.\",\n",
    "    \"Wee shuld definately do ths agan some day.\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    print(f'\\nTesting with sentence: \"{sentence}\"')\n",
    "    corrected = context_aware_spelling_corrector(\n",
    "        bigram_model,\n",
    "        nltk.word_tokenize(sentence),\n",
    "        beam_width=5,\n",
    "        lambda_lm=0.95,\n",
    "        lambda_err=0.05,\n",
    "        skip_oov=True\n",
    "    )\n",
    "    print(\"Bigram model produced:\")\n",
    "    print(\" \", \" \".join(corrected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with sentence: \"let us sey we are friendz\"\n",
      "Bigram model produced:\n",
      "  let us sey we are friend\n",
      "\n",
      "Testing with sentence: \"in consequencaae of her sistero's marriange, been moistress of hois house from a vry early period\"\n",
      "Bigram model produced:\n",
      "  in consequence of her sister , marianne , been mistress of his house from a very early period\n",
      "\n",
      "Testing with sentence: \"Tomorrrow well bring somethiing new, so leav today as a memoory.\"\n",
      "Bigram model produced:\n",
      "  tomorrow well bring something new , so let today as a memory .\n",
      "\n",
      "Testing with sentence: \"He wento too the storr to by some bred and mlik.\"\n",
      "Bigram model produced:\n",
      "  he went too the store to by some bred and mink .\n",
      "\n",
      "Testing with sentence: \"Ths is an exampel of a sentense with severl erors.\"\n",
      "Bigram model produced:\n",
      "  he is an example of a sentence with severe errors .\n",
      "\n",
      "Testing with sentence: \"Wee shuld definately do ths agan some day.\"\n",
      "Bigram model produced:\n",
      "  he could definately do the aged some day .\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"let us sey we are friendz\",\n",
    "    \"in consequencaae of her sistero's marriange, been moistress of hois house from a vry early period\",\n",
    "    \"Tomorrrow well bring somethiing new, so leav today as a memoory.\",\n",
    "    \"He wento too the storr to by some bred and mlik.\",\n",
    "    \"Ths is an exampel of a sentense with severl erors.\",\n",
    "    \"Wee shuld definately do ths agan some day.\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    print(f'\\nTesting with sentence: \"{sentence}\"')\n",
    "    corrected = context_aware_spelling_corrector(\n",
    "        trigram_model,\n",
    "        nltk.word_tokenize(sentence),\n",
    "        beam_width=5,\n",
    "        lambda_lm=0.9,\n",
    "        lambda_err=0.1,\n",
    "        skip_oov=True\n",
    "    )\n",
    "    print(\"Bigram model produced:\")\n",
    "    print(\" \", \" \".join(corrected))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5: Artificial Test Dataset (class + usage example)\n",
    "# ------------------------------------------------------------------\n",
    "# Before running this cell, make sure you have already defined `test_corpus` \n",
    "# (e.g., via:\n",
    "#    train_corpus, val_corpus, test_corpus = load_and_split_corpus(\n",
    "#        corpus_name='reuters', min_sentences=90000)\n",
    "# ) so that `test_corpus` is a List[str] of clean sentences.\n",
    "class ArtificialTestDataset:\n",
    "    def __init__(self, sentences, error_prob=0.05, seed=None):\n",
    "        \"\"\"\n",
    "        Initialize the artificial test dataset generator.\n",
    "\n",
    "        Args:\n",
    "            sentences (List[str]): List of clean sentences to corrupt.\n",
    "            error_prob (float): Probability of replacing each non-space character.\n",
    "            seed (int, optional): Random seed for reproducibility.\n",
    "        \"\"\"\n",
    "        self.sentences = sentences\n",
    "        self.error_prob = error_prob\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        # Character set for random replacements (excluding space)\n",
    "        self.chars = list(string.ascii_letters + string.digits + string.punctuation)\n",
    "\n",
    "    def _corrupt_char(self, c):\n",
    "        # Do not corrupt whitespace; apply corruption with given probability\n",
    "        if c.isspace() or random.random() > self.error_prob:\n",
    "            return c\n",
    "        # Choose a random replacement different from the original\n",
    "        replacement = random.choice(self.chars)\n",
    "        while replacement == c:\n",
    "            replacement = random.choice(self.chars)\n",
    "        return replacement\n",
    "\n",
    "    def generate(self):\n",
    "        \"\"\"\n",
    "        Generate the corrupted dataset.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: Corrupted sentences.\n",
    "        \"\"\"\n",
    "        corrupted = []\n",
    "        for sentence in self.sentences:\n",
    "            corrupted_sentence = ''.join(self._corrupt_char(c) for c in sentence)\n",
    "            corrupted.append(corrupted_sentence)\n",
    "        return corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing original vs. corrupted for first 5 sentences:\n",
      "============================================================\n",
      "Original:  O beautiful for patriot dream that sees beyond the years thine alabaster cities gleam undimmed by human tears .\n",
      "Corrupted: O Jeautifll fzr patriot dream that 6ees beyond Dhe years thine alabaster cities gleam undimmed by human tears .\n",
      "------------------------------------------------------------\n",
      "Original:  ( cf.\n",
      "Corrupted: ( cf.\n",
      "------------------------------------------------------------\n",
      "Original:  The Village office of Western Union with George Towsley as manager and telegrapher continued in Hard's drugstore until 1905 .\n",
      "Corrupted: The Villag} office of WesterP Union with George Towsley as manager )nd telegrapher continued in Hard's drugstore until 1905 .\n",
      "------------------------------------------------------------\n",
      "Original:  As if this was a signal , Poet abruptly began to thrash the water and the quick movement slowly made them sink through the water .\n",
      "Corrupted: As if this was a signal , Poet abruptly began to thrash the water and the quic) movement slowly made tqem sinj thrVugh the water .\n",
      "------------------------------------------------------------\n",
      "Original:  Routine determinations were made for dissolved oxygen in the mixed liquor and for oxygen uptake rates .\n",
      "Corrupted: Routine deQerminati8ns were yade for disHolved oxygen in 'he mixed liquor and for oxygen uptake rates .\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now, with test_corpus loaded, generate the corrupted dataset and display samples:\n",
    "generator = ArtificialTestDataset(test_corpus, error_prob=0.05, seed=42)\n",
    "corrupted_test_corpus = generator.generate()\n",
    "\n",
    "print(\"Showing original vs. corrupted for first 5 sentences:\")\n",
    "print(\"=\" * 60)\n",
    "for orig, corrupt in zip(test_corpus[:5], corrupted_test_corpus[:5]):\n",
    "    print(f\"Original:  {orig}\")\n",
    "    print(f\"Corrupted: {corrupt}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHCBQPgXKFKd"
   },
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "Gn8Ddtv2KB0j"
   },
   "outputs": [],
   "source": [
    "def load_and_split_corpus(corpus_name='reuters', min_sentences=-1):\n",
    "    \"\"\"\n",
    "    Load and split a corpus from NLTK into train, validation, and test sets.\n",
    "\n",
    "    Args:\n",
    "        corpus_name: Name of the corpus to load\n",
    "        min_sentences: Minimum number of sentences to include\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_corpus, val_corpus, test_corpus)\n",
    "    \"\"\"\n",
    "    print(f\"Loading {corpus_name} corpus...\")\n",
    "\n",
    "    if corpus_name == 'reuters':\n",
    "        from nltk.corpus import reuters\n",
    "        sentences = [\" \".join(reuters.words(fileid)) for fileid in reuters.fileids()]\n",
    "\n",
    "    elif corpus_name == 'brown':\n",
    "        from nltk.corpus import brown\n",
    "        sentences = [\" \".join(brown.words(fileid)) for fileid in brown.fileids()]\n",
    "\n",
    "    elif corpus_name == 'gutenberg':\n",
    "        from nltk.corpus import gutenberg\n",
    "        sentences = [\" \".join(gutenberg.words(fileid)) for fileid in gutenberg.fileids()]\n",
    "\n",
    "    elif corpus_name == 'all':\n",
    "        from nltk.corpus import reuters, brown, gutenberg\n",
    "        sentences = []\n",
    "\n",
    "        # Combine texts from all three corpora\n",
    "        sentences += [\" \".join(reuters.words(fileid)) for fileid in reuters.fileids()]\n",
    "        sentences += [\" \".join(brown.words(fileid)) for fileid in brown.fileids()]\n",
    "        sentences += [\" \".join(gutenberg.words(fileid)) for fileid in gutenberg.fileids()]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown corpus: {corpus_name}\")\n",
    "\n",
    "    # Break into actual sentences\n",
    "    all_sentences = []\n",
    "    for text in sentences:\n",
    "        all_sentences.extend(nltk.sent_tokenize(text))\n",
    "\n",
    "\n",
    "    # Ensure we have enough sentences\n",
    "    if len(all_sentences) < min_sentences:\n",
    "        raise ValueError(f\"Corpus {corpus_name} has only {len(all_sentences)} sentences, \"\n",
    "                         f\"which is less than the required {min_sentences}.\")\n",
    "\n",
    "    # Shuffle sentences\n",
    "    random.seed(42)\n",
    "    random.shuffle(all_sentences)\n",
    "\n",
    "    # Take a subset for faster processing if needed\n",
    "    sentences_subset = all_sentences[:min_sentences]\n",
    "\n",
    "    # Split into train, validation, and test sets (70%, 15%, 15%)\n",
    "    train_size = int(0.7 * len(sentences_subset))\n",
    "    val_size = int(0.15 * len(sentences_subset))\n",
    "\n",
    "    train_corpus = sentences_subset[:train_size]\n",
    "    val_corpus = sentences_subset[train_size:train_size + val_size]\n",
    "    test_corpus = sentences_subset[train_size + val_size:]\n",
    "\n",
    "    print(f\"Corpus split: {len(train_corpus)} train, {len(val_corpus)} validation, {len(test_corpus)} test sentences\")\n",
    "\n",
    "    return train_corpus, val_corpus, test_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33519,
     "status": "ok",
     "timestamp": 1744699158573,
     "user": {
      "displayName": "Marios Mantzaris",
      "userId": "03416491895175165913"
     },
     "user_tz": -180
    },
    "id": "QfpHHVESKDsL",
    "outputId": "fc8abfce-738f-4520-b577-a6380d171f67"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run the full language modeling experiment.\n",
    "\"\"\"\n",
    "# Part 1\n",
    "# Load and split corpus\n",
    "train_corpus, val_corpus, test_corpus = load_and_split_corpus(corpus_name='reuters', min_sentences=90000)\n",
    "\n",
    "# Initialize and train models\n",
    "bigram_model = NGramLanguageModel(n=2, min_freq=10)\n",
    "bigram_model.train(train_corpus)\n",
    "\n",
    "trigram_model = NGramLanguageModel(n=3, min_freq=10)\n",
    "trigram_model.train(train_corpus)\n",
    "\n",
    "# Ensure both models use the same vocabulary\n",
    "common_vocab = bigram_model.vocabulary.intersection(trigram_model.vocabulary)\n",
    "bigram_model.vocabulary = common_vocab\n",
    "trigram_model.vocabulary = common_vocab\n",
    "bigram_model.vocabulary_size = len(common_vocab)\n",
    "trigram_model.vocabulary_size = len(common_vocab)\n",
    "\n",
    "print(f\"Common vocabulary size: {len(common_vocab)}\")\n",
    "\n",
    "# Part 2\n",
    "# Calculate cross-entropy and perplexity on validation set\n",
    "print(\"\\nEvaluating on validation set...\")\n",
    "\n",
    "bigram_ce_val = calculate_cross_entropy(bigram_model, val_corpus)\n",
    "bigram_ppl_val = calculate_perplexity(bigram_ce_val)\n",
    "\n",
    "trigram_ce_val = calculate_cross_entropy(trigram_model, val_corpus)\n",
    "trigram_ppl_val = calculate_perplexity(trigram_ce_val)\n",
    "\n",
    "print(f\"Bigram model - Cross-entropy: {bigram_ce_val:.4f}, Perplexity: {bigram_ppl_val:.4f}\")\n",
    "print(f\"Trigram model - Cross-entropy: {trigram_ce_val:.4f}, Perplexity: {trigram_ppl_val:.4f}\")\n",
    "\n",
    "# Calculate cross-entropy and perplexity on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "\n",
    "bigram_ce_test = calculate_cross_entropy(bigram_model, test_corpus)\n",
    "bigram_ppl_test = calculate_perplexity(bigram_ce_test)\n",
    "\n",
    "trigram_ce_test = calculate_cross_entropy(trigram_model, test_corpus)\n",
    "trigram_ppl_test = calculate_perplexity(trigram_ce_test)\n",
    "\n",
    "print(f\"Bigram model - Cross-entropy: {bigram_ce_test:.4f}, Perplexity: {bigram_ppl_test:.4f}\")\n",
    "print(f\"Trigram model - Cross-entropy: {trigram_ce_test:.4f}, Perplexity: {trigram_ppl_test:.4f}\")\n",
    "\n",
    "# Part 3\n",
    "# Generate text completions\n",
    "print(\"\\nGenerating text completions:\")\n",
    "\n",
    "prompts = [\n",
    "\"I would like to\",\n",
    "\"The president of\",\n",
    "\"According to recent\",\n",
    "\"In the last few\",\n",
    "\"Experts say that\"\n",
    "]\n",
    "\n",
    "print(\"\\nBigram model completions:\")\n",
    "for prompt in prompts:\n",
    "  prompt_tokens = nltk.word_tokenize(prompt.lower())\n",
    "\n",
    "  # Generate with greedy decoding\n",
    "  completion_greedy = generate_text(bigram_model, prompt_tokens, method=\"greedy\")\n",
    "  completion_text_greedy = prompt + \" \" + \" \".join([w for w in completion_greedy if w != bigram_model.END])\n",
    "  print(f\"[Greedy] {completion_text_greedy}\")\n",
    "\n",
    "  # Generate with top-k sampling\n",
    "  completion_topk = generate_text(bigram_model, prompt_tokens, method=\"topk\", top_k=5, temperature=0.7)\n",
    "  completion_text_topk = prompt + \" \" + \" \".join([w for w in completion_topk if w != bigram_model.END])\n",
    "  print(f\"[Top-K] {completion_text_topk}\")\n",
    "\n",
    "  # Generate with beam search\n",
    "  beam_completions = beam_search(bigram_model, prompt_tokens, beam_width=3)\n",
    "  top_beam = beam_completions[0]\n",
    "  completion_text_beam = prompt + \" \" + \" \".join([w for w in top_beam if w != bigram_model.END])\n",
    "  print(f\"[Beam] {completion_text_beam}\")\n",
    "  print()\n",
    "\n",
    "print(\"\\nTrigram model completions:\")\n",
    "for prompt in prompts:\n",
    "  prompt_tokens = nltk.word_tokenize(prompt.lower())\n",
    "\n",
    "  # Generate with greedy decoding\n",
    "  completion_greedy = generate_text(trigram_model, prompt_tokens, method=\"greedy\")\n",
    "  completion_text_greedy = prompt + \" \" + \" \".join([w for w in completion_greedy if w != trigram_model.END])\n",
    "  print(f\"[Greedy] {completion_text_greedy}\")\n",
    "\n",
    "  # Generate with top-k sampling\n",
    "  completion_topk = generate_text(trigram_model, prompt_tokens, method=\"topk\", top_k=5, temperature=0.7)\n",
    "  completion_text_topk = prompt + \" \" + \" \".join([w for w in completion_topk if w != trigram_model.END])\n",
    "  print(f\"[Top-K] {completion_text_topk}\")\n",
    "\n",
    "  # Generate with beam search\n",
    "  beam_completions = beam_search(trigram_model, prompt_tokens, beam_width=3)\n",
    "  top_beam = beam_completions[0]\n",
    "  completion_text_beam = prompt + \" \" + \" \".join([w for w in top_beam if w != trigram_model.END])\n",
    "  print(f\"[Beam] {completion_text_beam}\")\n",
    "  print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
